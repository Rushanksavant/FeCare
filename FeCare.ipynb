{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pandas_profiling as pp\nimport sklearn\n\nimport torch                                       #Pytorch pkg & tensor library\nimport torchvision          \n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport joblib","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_mix_out= pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv')\ndata_mix_out.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Seperating 1s and 0s outputs from data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Seperating 1s and 0s outputs from data\nones=[]\nzeros=[]\nfor i in range(len(data_mix_out)):\n    if data_mix_out[\"Outcome\"][i]==1:\n        ones.append(i) #(i) because builtin_function_or_method' object is not subscriptable\n        \n    elif data_mix_out[\"Outcome\"][i]==0:\n        zeros.append(i) #(i) because builtin_function_or_method' object is not subscriptable\n        \n# Defining a function to make dataframe with speific index of data        \ndef sep_data(data_list):\n    combined_csv = pd.concat([pd.read_csv('../input/pima-indians-diabetes-database/diabetes.csv', skiprows= i+1, nrows=1, header=None) for i in data_list])\n    combined_csv= combined_csv.set_index(i for i in range(len(data_list)))\n    combined_csv.columns = data_mix_out.columns\n    return combined_csv\n\n# Data containing only 1s output\ndata_1s= sep_data(ones)\n\n# Data containing only 0s output\ndata_0s= sep_data(zeros)\n\n# Displaying datas\nprint(\"Data with only 1s outcome:\")\ndisplay(data_1s)\n\nprint(\"Data with only 0s outcome:\")\ndisplay(data_0s)","execution_count":3,"outputs":[{"output_type":"stream","text":"Data with only 1s outcome:\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0              6      148             72             35        0  33.6   \n1              8      183             64              0        0  23.3   \n2              0      137             40             35      168  43.1   \n3              3       78             50             32       88  31.0   \n4              2      197             70             45      543  30.5   \n..           ...      ...            ...            ...      ...   ...   \n263            1      128             88             39      110  36.5   \n264            0      123             72              0        0  36.3   \n265            6      190             92              0        0  35.5   \n266            9      170             74             31        0  44.0   \n267            1      126             60              0        0  30.1   \n\n     DiabetesPedigreeFunction  Age  Outcome  \n0                       0.627   50        1  \n1                       0.672   32        1  \n2                       2.288   33        1  \n3                       0.248   26        1  \n4                       0.158   53        1  \n..                        ...  ...      ...  \n263                     1.057   37        1  \n264                     0.258   52        1  \n265                     0.278   66        1  \n266                     0.403   43        1  \n267                     0.349   47        1  \n\n[268 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>78</td>\n      <td>50</td>\n      <td>32</td>\n      <td>88</td>\n      <td>31.0</td>\n      <td>0.248</td>\n      <td>26</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>197</td>\n      <td>70</td>\n      <td>45</td>\n      <td>543</td>\n      <td>30.5</td>\n      <td>0.158</td>\n      <td>53</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>263</th>\n      <td>1</td>\n      <td>128</td>\n      <td>88</td>\n      <td>39</td>\n      <td>110</td>\n      <td>36.5</td>\n      <td>1.057</td>\n      <td>37</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>0</td>\n      <td>123</td>\n      <td>72</td>\n      <td>0</td>\n      <td>0</td>\n      <td>36.3</td>\n      <td>0.258</td>\n      <td>52</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>265</th>\n      <td>6</td>\n      <td>190</td>\n      <td>92</td>\n      <td>0</td>\n      <td>0</td>\n      <td>35.5</td>\n      <td>0.278</td>\n      <td>66</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>266</th>\n      <td>9</td>\n      <td>170</td>\n      <td>74</td>\n      <td>31</td>\n      <td>0</td>\n      <td>44.0</td>\n      <td>0.403</td>\n      <td>43</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>267</th>\n      <td>1</td>\n      <td>126</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.1</td>\n      <td>0.349</td>\n      <td>47</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>268 rows Ã— 9 columns</p>\n</div>"},"metadata":{}},{"output_type":"stream","text":"Data with only 0s outcome:\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0              1       85             66             29        0  26.6   \n1              1       89             66             23       94  28.1   \n2              5      116             74              0        0  25.6   \n3             10      115              0              0        0  35.3   \n4              4      110             92              0        0  37.6   \n..           ...      ...            ...            ...      ...   ...   \n495            9       89             62              0        0  22.5   \n496           10      101             76             48      180  32.9   \n497            2      122             70             27        0  36.8   \n498            5      121             72             23      112  26.2   \n499            1       93             70             31        0  30.4   \n\n     DiabetesPedigreeFunction  Age  Outcome  \n0                       0.351   31        0  \n1                       0.167   21        0  \n2                       0.201   30        0  \n3                       0.134   29        0  \n4                       0.191   30        0  \n..                        ...  ...      ...  \n495                     0.142   33        0  \n496                     0.171   63        0  \n497                     0.340   27        0  \n498                     0.245   30        0  \n499                     0.315   23        0  \n\n[500 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>116</td>\n      <td>74</td>\n      <td>0</td>\n      <td>0</td>\n      <td>25.6</td>\n      <td>0.201</td>\n      <td>30</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10</td>\n      <td>115</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>35.3</td>\n      <td>0.134</td>\n      <td>29</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>110</td>\n      <td>92</td>\n      <td>0</td>\n      <td>0</td>\n      <td>37.6</td>\n      <td>0.191</td>\n      <td>30</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>9</td>\n      <td>89</td>\n      <td>62</td>\n      <td>0</td>\n      <td>0</td>\n      <td>22.5</td>\n      <td>0.142</td>\n      <td>33</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>10</td>\n      <td>101</td>\n      <td>76</td>\n      <td>48</td>\n      <td>180</td>\n      <td>32.9</td>\n      <td>0.171</td>\n      <td>63</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>2</td>\n      <td>122</td>\n      <td>70</td>\n      <td>27</td>\n      <td>0</td>\n      <td>36.8</td>\n      <td>0.340</td>\n      <td>27</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>5</td>\n      <td>121</td>\n      <td>72</td>\n      <td>23</td>\n      <td>112</td>\n      <td>26.2</td>\n      <td>0.245</td>\n      <td>30</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>1</td>\n      <td>93</td>\n      <td>70</td>\n      <td>31</td>\n      <td>0</td>\n      <td>30.4</td>\n      <td>0.315</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows Ã— 9 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Joining the above dataframes "},{"metadata":{"trusted":true},"cell_type":"code","source":"data= pd.concat([data_0s, data_1s])\ndata= data.set_index(i for i in range(len(data_0s) + len(data_1s)))\ndisplay(data.head())\ndata.tail()","execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            1       85             66             29        0  26.6   \n1            1       89             66             23       94  28.1   \n2            5      116             74              0        0  25.6   \n3           10      115              0              0        0  35.3   \n4            4      110             92              0        0  37.6   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.351   31        0  \n1                     0.167   21        0  \n2                     0.201   30        0  \n3                     0.134   29        0  \n4                     0.191   30        0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>116</td>\n      <td>74</td>\n      <td>0</td>\n      <td>0</td>\n      <td>25.6</td>\n      <td>0.201</td>\n      <td>30</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10</td>\n      <td>115</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>35.3</td>\n      <td>0.134</td>\n      <td>29</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>110</td>\n      <td>92</td>\n      <td>0</td>\n      <td>0</td>\n      <td>37.6</td>\n      <td>0.191</td>\n      <td>30</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n763            1      128             88             39      110  36.5   \n764            0      123             72              0        0  36.3   \n765            6      190             92              0        0  35.5   \n766            9      170             74             31        0  44.0   \n767            1      126             60              0        0  30.1   \n\n     DiabetesPedigreeFunction  Age  Outcome  \n763                     1.057   37        1  \n764                     0.258   52        1  \n765                     0.278   66        1  \n766                     0.403   43        1  \n767                     0.349   47        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>763</th>\n      <td>1</td>\n      <td>128</td>\n      <td>88</td>\n      <td>39</td>\n      <td>110</td>\n      <td>36.5</td>\n      <td>1.057</td>\n      <td>37</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>0</td>\n      <td>123</td>\n      <td>72</td>\n      <td>0</td>\n      <td>0</td>\n      <td>36.3</td>\n      <td>0.258</td>\n      <td>52</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>6</td>\n      <td>190</td>\n      <td>92</td>\n      <td>0</td>\n      <td>0</td>\n      <td>35.5</td>\n      <td>0.278</td>\n      <td>66</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>766</th>\n      <td>9</td>\n      <td>170</td>\n      <td>74</td>\n      <td>31</td>\n      <td>0</td>\n      <td>44.0</td>\n      <td>0.403</td>\n      <td>43</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>1</td>\n      <td>126</td>\n      <td>60</td>\n      <td>0</td>\n      <td>0</td>\n      <td>30.1</td>\n      <td>0.349</td>\n      <td>47</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### In the above data, first 500 rows are with outcome '0' and last 268 are with outcome '1'   "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# pp.ProfileReport(data)","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Zero values in \t[Glucose, BloodPressure, SkinThickness, Insulin, BMI] can be due to missing data because its impossible to have those values '0' practically"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Not including pregnancies\ncols= [\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\",\"DiabetesPedigreeFunction\",\"Age\"]\nk=0\n\nfor j in range(len(cols)-1):\n    for i in range(len(data)):\n        if data[cols[j+1]][i]==0:\n            k=k+1\n    print('Missing values in  ' + cols[j+1]+'='+ str(k))\n    k=0","execution_count":6,"outputs":[{"output_type":"stream","text":"Missing values in  Glucose=5\nMissing values in  BloodPressure=35\nMissing values in  SkinThickness=227\nMissing values in  Insulin=374\nMissing values in  BMI=11\nMissing values in  DiabetesPedigreeFunction=0\nMissing values in  Age=0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Fixing Missing values:\n\n* Glucose values from similar Age and Outcome values\n* BloodPressure values from similar Age, Glucose and Outcome values average\n* BMI values from similar Age and Glucose values average\n* SkinThickness values from similar Age, BMI, Glucose and Outcome values average"},{"metadata":{"trusted":true},"cell_type":"code","source":"def fix_miss_value(dataset, tar_col, need_col):\n    #tar_col= str(name of column you want to fix missing values of)\n    #need_col= list of columns for which values are to be compared\n    l=[]\n    pos_val=[]\n    dataset[tar_col]= np.array(dataset[tar_col], dtype= 'float32')\n    for i in range(len(dataset)):\n        if dataset[tar_col][i]==0:\n            for k in range(len(need_col)):\n                for j in range(len(data)):\n                    if dataset[need_col[k]][i]==dataset[need_col[k]][j]:\n                        l.append(dataset[tar_col][j])\n            avg= sum(l) / len(l)\n            pos_val.append([i, avg])\n            \n    \n    for i in range(len(pos_val)):\n        k= pos_val[i][1] - int(pos_val[i][1])\n        dataset[tar_col][pos_val[i][0]]= pos_val[i][1] ","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replacing values as decided\n\nfix_miss_value(data, \"Glucose\", [\"Age\", \"Outcome\"])\n\nfix_miss_value(data, \"BloodPressure\", [\"Age\", \"Glucose\"])\n\nfix_miss_value(data, \"BMI\", [\"Age\", \"Glucose\", \"BloodPressure\"])\n\nfix_miss_value(data, \"SkinThickness\", [\"BMI\", \"Age\", \"Glucose\", \"Outcome\"])","execution_count":8,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Not including Pregnencies\ncols= [\"Pregnancies\",\"Glucose\",\"BloodPressure\",\"SkinThickness\",\"Insulin\",\"BMI\",\"DiabetesPedigreeFunction\",\"Age\"]\nk=0\n\nfor j in range(len(cols)-1):\n    for i in range(len(data)):\n        if data[cols[j+1]][i]==0:\n            k=k+1\n    print('Missing values in  ' + cols[j+1]+'='+ str(k))\n    k=0","execution_count":9,"outputs":[{"output_type":"stream","text":"Missing values in  Glucose=0\nMissing values in  BloodPressure=0\nMissing values in  SkinThickness=0\nMissing values in  Insulin=374\nMissing values in  BMI=0\nMissing values in  DiabetesPedigreeFunction=0\nMissing values in  Age=0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Scaling up Diabetes Pedigree Function entries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Getting Diabetes Pedigree Function to same scale by multiplying it with a scaler(k= 100)\nfor i in range(len(data[\"DiabetesPedigreeFunction\"])):\n    data[\"DiabetesPedigreeFunction\"][i]= data[\"DiabetesPedigreeFunction\"][i]*100\ndata.head()","execution_count":10,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n","name":"stderr"},{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin        BMI  \\\n0            1     85.0      66.000000      29.000000        0  26.600000   \n1            1     89.0      66.000000      23.000000       94  28.100000   \n2            5    116.0      74.000000      19.473783        0  25.600000   \n3           10    115.0      66.230766      19.545033        0  35.299999   \n4            4    110.0      92.000000      19.550032        0  37.599998   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                      35.1   31        0  \n1                      16.7   21        0  \n2                      20.1   30        0  \n3                      13.4   29        0  \n4                      19.1   30        0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>85.0</td>\n      <td>66.000000</td>\n      <td>29.000000</td>\n      <td>0</td>\n      <td>26.600000</td>\n      <td>35.1</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>89.0</td>\n      <td>66.000000</td>\n      <td>23.000000</td>\n      <td>94</td>\n      <td>28.100000</td>\n      <td>16.7</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>116.0</td>\n      <td>74.000000</td>\n      <td>19.473783</td>\n      <td>0</td>\n      <td>25.600000</td>\n      <td>20.1</td>\n      <td>30</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10</td>\n      <td>115.0</td>\n      <td>66.230766</td>\n      <td>19.545033</td>\n      <td>0</td>\n      <td>35.299999</td>\n      <td>13.4</td>\n      <td>29</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>110.0</td>\n      <td>92.000000</td>\n      <td>19.550032</td>\n      <td>0</td>\n      <td>37.599998</td>\n      <td>19.1</td>\n      <td>30</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Feature Selection and splitting training-testing data\n\n* Data contain more entries with 0 outcome(500 entries) in comparison to 1 outcome(268 entries). \n* And hence while training we will take 300 entries with 0 outcome and 250 entries with 1 outcome in training set.\n* This leads to a split of 71:29 % for train:test  "},{"metadata":{"trusted":true},"cell_type":"code","source":"train= pd.concat([data.iloc[0: 300], data.iloc[500: 750]]) # 300 values with 0 outcomes, and 250 values with 1 outcomes \ntest=  pd.concat([data.iloc[300: 500], data.iloc[750: 768]]) # 300 values with 200 outcomes, and 18 values with 1 outcomes\n\ntrain= train.set_index(i for i in range(len(train)))\ntest= test.set_index(i for i in range(len(test)))","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Note: we wont be including Insulint and Glucose readings as it requires skills and instruments to perform test which a normal user may not be have\nX_train= train.drop(columns= [\"Outcome\", \"Insulin\", \"Glucose\"])\nX_test= test.drop(columns= [\"Outcome\", \"Insulin\", \"Glucose\"])\n\nY_train= train[\"Outcome\"]\nY_test= test[\"Outcome\"]","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Testing and Validation Split\nfrom sklearn.model_selection import train_test_split\n\nX_test, X_val, Y_test, Y_val = train_test_split(X_test, Y_test, test_size=0.50)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting \nX_train = np.array(X_train, dtype = 'float32')\nY_train = np.array(Y_train, dtype = 'float32')\n\nX_test = np.array(X_test, dtype = 'float32')\nY_test = np.array(Y_test, dtype = 'float32')\n\nX_val = np.array(X_val, dtype = 'float32')\nY_val = np.array(Y_val, dtype = 'float32')","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)\ntorch_y_train = torch.from_numpy(Y_train).type(torch.LongTensor) # data type is long\n\ntorch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)\ntorch_y_test = torch.from_numpy(Y_test).type(torch.LongTensor) # data type is long\n\ntorch_X_val = torch.from_numpy(X_val).type(torch.LongTensor)\ntorch_y_val = torch.from_numpy(Y_val).type(torch.LongTensor) # data type is long\n\n# Pytorch train and test sets\ntrain = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\ntest = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\nval = torch.utils.data.TensorDataset(torch_X_val,torch_y_val)\n\n# data loader\ntrain_loader = torch.utils.data.DataLoader(train, batch_size = 10, shuffle = False)\ntest_loader = torch.utils.data.DataLoader(test, batch_size = 5, shuffle = False)\nval_loader = torch.utils.data.DataLoader(val, batch_size = 5, shuffle = False)","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Defining Neural Network"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Network(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.fc1 = nn.Linear(in_features=6, out_features=40) # Linear layer 1 \n        self.fc2 = nn.Linear(in_features=40, out_features=81) # Linear layer 2\n        self.fc3 = nn.Linear(in_features=81, out_features=36) # Linear layer 3\n        self.fc4 = nn.Linear(in_features=36, out_features=19) # Linear layer 4\n        self.out = nn.Linear(in_features=19, out_features=2) # Linear layer 5 (output layer)\n        \n    def forward(self, t):\n        # input layer\n        t=t\n        # (1) hidden conv layer\n        t = self.fc1(t)\n        t = F.relu(t)\n\n        # (2) hidden linear layer\n        t = self.fc2(t)\n        t = F.relu(t)\n        \n        # (3) hidden linear layer\n        t = self.fc3(t)\n        t = F.relu(t)\n        \n        # (4) hidden linear layer\n        t = self.fc4(t)\n        t = F.relu(t)\n        \n        # (5) output layer\n        t = self.out(t)\n        #t = F.softmax(t, dim=1)\n        \n        return t","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function for calculating correct predictions\ndef get_num_correct(preds, labels):\n    return preds.argmax(dim= 1).eq(labels).sum().item()","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network= Network()\nnetwork","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"Network(\n  (fc1): Linear(in_features=6, out_features=40, bias=True)\n  (fc2): Linear(in_features=40, out_features=81, bias=True)\n  (fc3): Linear(in_features=81, out_features=36, bias=True)\n  (fc4): Linear(in_features=36, out_features=19, bias=True)\n  (out): Linear(in_features=19, out_features=2, bias=True)\n)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"network = Network()\n\noptimizer = optim.SGD(network.parameters(), lr=0.001)\n\nvalid_loss_min = np.Inf\n\nfor epoch in range(1250):\n    \n    train_loss = 0\n    train_correct = 0\n    \n    val_loss = 0\n    val_correct = 0\n    \n    \n    for batch in train_loader: # Get Batch\n        paras, out = batch \n\n        preds = network(paras.float()) # Pass Batch\n        loss = F.cross_entropy(preds, out.long()) # Calculate Loss\n\n        optimizer.zero_grad()\n        loss.backward() # Calculate Gradients\n        optimizer.step() # Update Weights\n\n        train_loss += loss.item()\n        train_correct += get_num_correct(preds, out)\n        \n        \n        \n    # For Validation\n    \n    for batch in val_loader: # Get Batch\n        paras, out = batch \n\n        preds = network(paras.float()) # Pass Batch\n        loss = F.cross_entropy(preds, out.long()) # Calculate Loss\n\n        optimizer.zero_grad()\n        loss.backward() # Calculate Gradients\n        optimizer.step() # Update Weights\n\n        val_loss += loss.item()\n        val_correct += get_num_correct(preds, out)\n\n#     print(\"epoch\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n    print(\"Epoch\", epoch, \" ;Total Train correct:\", train_correct, \" ;Train loss:\", train_loss)\n    print(\"Total Validation correct:\", val_correct ,\" ;Validation Loss:\", val_loss)\n    \n    \n    # save model if validation loss has decreased\n    if val_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        val_loss))\n        checkpoint = {'model': network,\n              'state_dict': network.state_dict(),\n              'optimizer' : optimizer.state_dict(),\n              'train_loss': train_loss}\n\n        torch.save(checkpoint, 'checkpoint.pth')\n        valid_loss_min = val_loss\n        \n    print('\\n')","execution_count":25,"outputs":[{"output_type":"stream","text":"Epoch 0  ;Total Train correct: 470  ;Train loss: 23.561714719980955\nTotal Validation correct: 63  ;Validation Loss: 17.155063211917877\nValidation loss decreased (inf --> 17.155063).  Saving model ...\n\n\nEpoch 1  ;Total Train correct: 482  ;Train loss: 20.940006010234356\nTotal Validation correct: 64  ;Validation Loss: 16.610895425081253\nValidation loss decreased (17.155063 --> 16.610895).  Saving model ...\n\n\nEpoch 2  ;Total Train correct: 478  ;Train loss: 21.427192263305187\nTotal Validation correct: 67  ;Validation Loss: 16.292696326971054\nValidation loss decreased (16.610895 --> 16.292696).  Saving model ...\n\n\nEpoch 3  ;Total Train correct: 474  ;Train loss: 21.862691070884466\nTotal Validation correct: 67  ;Validation Loss: 16.296582281589508\n\n\nEpoch 4  ;Total Train correct: 474  ;Train loss: 22.333627838641405\nTotal Validation correct: 67  ;Validation Loss: 16.237347811460495\nValidation loss decreased (16.292696 --> 16.237348).  Saving model ...\n\n\nEpoch 5  ;Total Train correct: 471  ;Train loss: 22.772390518337488\nTotal Validation correct: 67  ;Validation Loss: 16.15838783979416\nValidation loss decreased (16.237348 --> 16.158388).  Saving model ...\n\n\nEpoch 6  ;Total Train correct: 466  ;Train loss: 23.138269908726215\nTotal Validation correct: 68  ;Validation Loss: 16.044359803199768\nValidation loss decreased (16.158388 --> 16.044360).  Saving model ...\n\n\nEpoch 7  ;Total Train correct: 466  ;Train loss: 23.383943412452936\nTotal Validation correct: 68  ;Validation Loss: 16.063668876886368\n\n\nEpoch 8  ;Total Train correct: 463  ;Train loss: 23.689395673573017\nTotal Validation correct: 69  ;Validation Loss: 16.0242241024971\nValidation loss decreased (16.044360 --> 16.024224).  Saving model ...\n\n\nEpoch 9  ;Total Train correct: 462  ;Train loss: 23.967203602194786\nTotal Validation correct: 69  ;Validation Loss: 15.96589344739914\nValidation loss decreased (16.024224 --> 15.965893).  Saving model ...\n\n\nEpoch 10  ;Total Train correct: 461  ;Train loss: 24.183769926428795\nTotal Validation correct: 69  ;Validation Loss: 15.925894737243652\nValidation loss decreased (15.965893 --> 15.925895).  Saving model ...\n\n\nEpoch 11  ;Total Train correct: 460  ;Train loss: 24.416398994624615\nTotal Validation correct: 69  ;Validation Loss: 15.88345006108284\nValidation loss decreased (15.925895 --> 15.883450).  Saving model ...\n\n\nEpoch 12  ;Total Train correct: 457  ;Train loss: 24.633502304553986\nTotal Validation correct: 69  ;Validation Loss: 15.832601189613342\nValidation loss decreased (15.883450 --> 15.832601).  Saving model ...\n\n\nEpoch 13  ;Total Train correct: 454  ;Train loss: 24.884337440133095\nTotal Validation correct: 69  ;Validation Loss: 15.791402012109756\nValidation loss decreased (15.832601 --> 15.791402).  Saving model ...\n\n\nEpoch 14  ;Total Train correct: 453  ;Train loss: 25.10897794365883\nTotal Validation correct: 68  ;Validation Loss: 15.738764554262161\nValidation loss decreased (15.791402 --> 15.738765).  Saving model ...\n\n\nEpoch 15  ;Total Train correct: 451  ;Train loss: 25.255454421043396\nTotal Validation correct: 69  ;Validation Loss: 15.708766460418701\nValidation loss decreased (15.738765 --> 15.708766).  Saving model ...\n\n\nEpoch 16  ;Total Train correct: 450  ;Train loss: 25.40570130199194\nTotal Validation correct: 69  ;Validation Loss: 15.648658812046051\nValidation loss decreased (15.708766 --> 15.648659).  Saving model ...\n\n\nEpoch 17  ;Total Train correct: 450  ;Train loss: 25.52619920670986\nTotal Validation correct: 69  ;Validation Loss: 15.618010133504868\nValidation loss decreased (15.648659 --> 15.618010).  Saving model ...\n\n\nEpoch 18  ;Total Train correct: 449  ;Train loss: 25.61370974779129\nTotal Validation correct: 69  ;Validation Loss: 15.586260825395584\nValidation loss decreased (15.618010 --> 15.586261).  Saving model ...\n\n\nEpoch 19  ;Total Train correct: 449  ;Train loss: 25.700360521674156\nTotal Validation correct: 69  ;Validation Loss: 15.528064340353012\nValidation loss decreased (15.586261 --> 15.528064).  Saving model ...\n\n\nEpoch 20  ;Total Train correct: 448  ;Train loss: 25.791449695825577\nTotal Validation correct: 69  ;Validation Loss: 15.479207038879395\nValidation loss decreased (15.528064 --> 15.479207).  Saving model ...\n\n\nEpoch 21  ;Total Train correct: 446  ;Train loss: 25.81149932742119\nTotal Validation correct: 69  ;Validation Loss: 15.437384366989136\nValidation loss decreased (15.479207 --> 15.437384).  Saving model ...\n\n\nEpoch 22  ;Total Train correct: 446  ;Train loss: 25.81301062554121\nTotal Validation correct: 69  ;Validation Loss: 15.430971533060074\nValidation loss decreased (15.437384 --> 15.430972).  Saving model ...\n\n\nEpoch 23  ;Total Train correct: 446  ;Train loss: 25.826164826750755\nTotal Validation correct: 69  ;Validation Loss: 15.418589621782303\nValidation loss decreased (15.430972 --> 15.418590).  Saving model ...\n\n\nEpoch 24  ;Total Train correct: 445  ;Train loss: 25.833409518003464\nTotal Validation correct: 68  ;Validation Loss: 15.404101520776749\nValidation loss decreased (15.418590 --> 15.404102).  Saving model ...\n\n\nEpoch 25  ;Total Train correct: 445  ;Train loss: 25.85863794386387\nTotal Validation correct: 68  ;Validation Loss: 15.364429324865341\nValidation loss decreased (15.404102 --> 15.364429).  Saving model ...\n\n\nEpoch 26  ;Total Train correct: 446  ;Train loss: 25.852763511240482\nTotal Validation correct: 68  ;Validation Loss: 15.362954795360565\nValidation loss decreased (15.364429 --> 15.362955).  Saving model ...\n\n\nEpoch 27  ;Total Train correct: 446  ;Train loss: 25.816608160734177\nTotal Validation correct: 68  ;Validation Loss: 15.346830546855927\nValidation loss decreased (15.362955 --> 15.346831).  Saving model ...\n\n\nEpoch 28  ;Total Train correct: 446  ;Train loss: 25.849465429782867\nTotal Validation correct: 68  ;Validation Loss: 15.30630898475647\nValidation loss decreased (15.346831 --> 15.306309).  Saving model ...\n\n\nEpoch 29  ;Total Train correct: 447  ;Train loss: 25.760237641632557\nTotal Validation correct: 67  ;Validation Loss: 15.290681958198547\nValidation loss decreased (15.306309 --> 15.290682).  Saving model ...\n\n\nEpoch 30  ;Total Train correct: 447  ;Train loss: 25.74764185398817\nTotal Validation correct: 66  ;Validation Loss: 15.28288722038269\nValidation loss decreased (15.290682 --> 15.282887).  Saving model ...\n\n\nEpoch 31  ;Total Train correct: 447  ;Train loss: 25.69578744471073\nTotal Validation correct: 66  ;Validation Loss: 15.271258383989334\nValidation loss decreased (15.282887 --> 15.271258).  Saving model ...\n\n\nEpoch 32  ;Total Train correct: 447  ;Train loss: 25.66429605334997\nTotal Validation correct: 66  ;Validation Loss: 15.2558713555336\nValidation loss decreased (15.271258 --> 15.255871).  Saving model ...\n\n\nEpoch 33  ;Total Train correct: 447  ;Train loss: 25.63404781371355\nTotal Validation correct: 66  ;Validation Loss: 15.22703692317009\nValidation loss decreased (15.255871 --> 15.227037).  Saving model ...\n\n\nEpoch 34  ;Total Train correct: 447  ;Train loss: 25.58129382133484\nTotal Validation correct: 66  ;Validation Loss: 15.224645674228668\nValidation loss decreased (15.227037 --> 15.224646).  Saving model ...\n\n\nEpoch 35  ;Total Train correct: 447  ;Train loss: 25.51708820462227\nTotal Validation correct: 66  ;Validation Loss: 15.229368478059769\n\n\nEpoch 36  ;Total Train correct: 447  ;Train loss: 25.511117212474346\nTotal Validation correct: 66  ;Validation Loss: 15.231362968683243\n\n\nEpoch 37  ;Total Train correct: 447  ;Train loss: 25.471464596688747\nTotal Validation correct: 65  ;Validation Loss: 15.21561524271965\nValidation loss decreased (15.224646 --> 15.215615).  Saving model ...\n\n\nEpoch 38  ;Total Train correct: 447  ;Train loss: 25.44245782494545\nTotal Validation correct: 65  ;Validation Loss: 15.220328122377396\n\n\nEpoch 39  ;Total Train correct: 447  ;Train loss: 25.408607825636864\nTotal Validation correct: 65  ;Validation Loss: 15.21780315041542\n\n\nEpoch 40  ;Total Train correct: 448  ;Train loss: 25.364933636039495\nTotal Validation correct: 65  ;Validation Loss: 15.204666674137115\nValidation loss decreased (15.215615 --> 15.204667).  Saving model ...\n\n\nEpoch 41  ;Total Train correct: 448  ;Train loss: 25.33709915354848\nTotal Validation correct: 65  ;Validation Loss: 15.202650725841522\nValidation loss decreased (15.204667 --> 15.202651).  Saving model ...\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 42  ;Total Train correct: 448  ;Train loss: 25.28605354577303\nTotal Validation correct: 66  ;Validation Loss: 15.190860539674759\nValidation loss decreased (15.202651 --> 15.190861).  Saving model ...\n\n\nEpoch 43  ;Total Train correct: 449  ;Train loss: 25.23955962061882\nTotal Validation correct: 66  ;Validation Loss: 15.184149444103241\nValidation loss decreased (15.190861 --> 15.184149).  Saving model ...\n\n\nEpoch 44  ;Total Train correct: 450  ;Train loss: 25.183874670416117\nTotal Validation correct: 66  ;Validation Loss: 15.189861863851547\n\n\nEpoch 45  ;Total Train correct: 450  ;Train loss: 25.142454463988543\nTotal Validation correct: 67  ;Validation Loss: 15.151324689388275\nValidation loss decreased (15.184149 --> 15.151325).  Saving model ...\n\n\nEpoch 46  ;Total Train correct: 450  ;Train loss: 25.048172879964113\nTotal Validation correct: 66  ;Validation Loss: 15.168529689311981\n\n\nEpoch 47  ;Total Train correct: 450  ;Train loss: 25.01036311686039\nTotal Validation correct: 66  ;Validation Loss: 15.190910875797272\n\n\nEpoch 48  ;Total Train correct: 452  ;Train loss: 24.969302974641323\nTotal Validation correct: 66  ;Validation Loss: 15.185466647148132\n\n\nEpoch 49  ;Total Train correct: 452  ;Train loss: 24.94773681461811\nTotal Validation correct: 66  ;Validation Loss: 15.166069567203522\n\n\nEpoch 50  ;Total Train correct: 452  ;Train loss: 24.908147040754557\nTotal Validation correct: 66  ;Validation Loss: 15.179904341697693\n\n\nEpoch 51  ;Total Train correct: 452  ;Train loss: 24.86456499621272\nTotal Validation correct: 66  ;Validation Loss: 15.16071742773056\n\n\nEpoch 52  ;Total Train correct: 452  ;Train loss: 24.849649496376514\nTotal Validation correct: 66  ;Validation Loss: 15.155705451965332\n\n\nEpoch 53  ;Total Train correct: 452  ;Train loss: 24.78867470473051\nTotal Validation correct: 66  ;Validation Loss: 15.157964795827866\n\n\nEpoch 54  ;Total Train correct: 452  ;Train loss: 24.77000307291746\nTotal Validation correct: 66  ;Validation Loss: 15.153791517019272\n\n\nEpoch 55  ;Total Train correct: 453  ;Train loss: 24.72820671275258\nTotal Validation correct: 66  ;Validation Loss: 15.160779774188995\n\n\nEpoch 56  ;Total Train correct: 453  ;Train loss: 24.684317149221897\nTotal Validation correct: 66  ;Validation Loss: 15.17989096045494\n\n\nEpoch 57  ;Total Train correct: 453  ;Train loss: 24.671141386032104\nTotal Validation correct: 66  ;Validation Loss: 15.176455199718475\n\n\nEpoch 58  ;Total Train correct: 453  ;Train loss: 24.664576396346092\nTotal Validation correct: 66  ;Validation Loss: 15.157081961631775\n\n\nEpoch 59  ;Total Train correct: 453  ;Train loss: 24.638297490775585\nTotal Validation correct: 68  ;Validation Loss: 15.164903938770294\n\n\nEpoch 60  ;Total Train correct: 453  ;Train loss: 24.60559207946062\nTotal Validation correct: 68  ;Validation Loss: 15.140550523996353\nValidation loss decreased (15.151325 --> 15.140551).  Saving model ...\n\n\nEpoch 61  ;Total Train correct: 453  ;Train loss: 24.58939764276147\nTotal Validation correct: 68  ;Validation Loss: 15.118153929710388\nValidation loss decreased (15.140551 --> 15.118154).  Saving model ...\n\n\nEpoch 62  ;Total Train correct: 453  ;Train loss: 24.5330839343369\nTotal Validation correct: 67  ;Validation Loss: 15.138376146554947\n\n\nEpoch 63  ;Total Train correct: 453  ;Train loss: 24.511272702366114\nTotal Validation correct: 67  ;Validation Loss: 15.109295159578323\nValidation loss decreased (15.118154 --> 15.109295).  Saving model ...\n\n\nEpoch 64  ;Total Train correct: 453  ;Train loss: 24.49583636969328\nTotal Validation correct: 67  ;Validation Loss: 15.10542806982994\nValidation loss decreased (15.109295 --> 15.105428).  Saving model ...\n\n\nEpoch 65  ;Total Train correct: 453  ;Train loss: 24.452606953680515\nTotal Validation correct: 66  ;Validation Loss: 15.114508032798767\n\n\nEpoch 66  ;Total Train correct: 453  ;Train loss: 24.442151840776205\nTotal Validation correct: 66  ;Validation Loss: 15.107165426015854\n\n\nEpoch 67  ;Total Train correct: 453  ;Train loss: 24.4270854331553\nTotal Validation correct: 66  ;Validation Loss: 15.086892634630203\nValidation loss decreased (15.105428 --> 15.086893).  Saving model ...\n\n\nEpoch 68  ;Total Train correct: 453  ;Train loss: 24.411877673119307\nTotal Validation correct: 66  ;Validation Loss: 15.085465997457504\nValidation loss decreased (15.086893 --> 15.085466).  Saving model ...\n\n\nEpoch 69  ;Total Train correct: 453  ;Train loss: 24.36215114593506\nTotal Validation correct: 66  ;Validation Loss: 15.093969315290451\n\n\nEpoch 70  ;Total Train correct: 453  ;Train loss: 24.35319098085165\nTotal Validation correct: 66  ;Validation Loss: 15.071106106042862\nValidation loss decreased (15.085466 --> 15.071106).  Saving model ...\n\n\nEpoch 71  ;Total Train correct: 453  ;Train loss: 24.34115558490157\nTotal Validation correct: 67  ;Validation Loss: 15.06267762184143\nValidation loss decreased (15.071106 --> 15.062678).  Saving model ...\n\n\nEpoch 72  ;Total Train correct: 453  ;Train loss: 24.338337771594524\nTotal Validation correct: 67  ;Validation Loss: 15.051601558923721\nValidation loss decreased (15.062678 --> 15.051602).  Saving model ...\n\n\nEpoch 73  ;Total Train correct: 453  ;Train loss: 24.25975350290537\nTotal Validation correct: 67  ;Validation Loss: 15.05567580461502\n\n\nEpoch 74  ;Total Train correct: 453  ;Train loss: 24.237833838909864\nTotal Validation correct: 67  ;Validation Loss: 15.037160247564316\nValidation loss decreased (15.051602 --> 15.037160).  Saving model ...\n\n\nEpoch 75  ;Total Train correct: 453  ;Train loss: 24.232612684369087\nTotal Validation correct: 67  ;Validation Loss: 15.021584749221802\nValidation loss decreased (15.037160 --> 15.021585).  Saving model ...\n\n\nEpoch 76  ;Total Train correct: 453  ;Train loss: 24.208251554518938\nTotal Validation correct: 67  ;Validation Loss: 15.016754120588303\nValidation loss decreased (15.021585 --> 15.016754).  Saving model ...\n\n\nEpoch 77  ;Total Train correct: 453  ;Train loss: 24.15230905264616\nTotal Validation correct: 67  ;Validation Loss: 15.009594798088074\nValidation loss decreased (15.016754 --> 15.009595).  Saving model ...\n\n\nEpoch 78  ;Total Train correct: 453  ;Train loss: 24.138888888061047\nTotal Validation correct: 67  ;Validation Loss: 15.000815898180008\nValidation loss decreased (15.009595 --> 15.000816).  Saving model ...\n\n\nEpoch 79  ;Total Train correct: 453  ;Train loss: 24.09506492316723\nTotal Validation correct: 67  ;Validation Loss: 15.000330418348312\nValidation loss decreased (15.000816 --> 15.000330).  Saving model ...\n\n\nEpoch 80  ;Total Train correct: 453  ;Train loss: 24.055362045764923\nTotal Validation correct: 67  ;Validation Loss: 15.004427880048752\n\n\nEpoch 81  ;Total Train correct: 453  ;Train loss: 24.021542329341173\nTotal Validation correct: 68  ;Validation Loss: 14.994408428668976\nValidation loss decreased (15.000330 --> 14.994408).  Saving model ...\n\n\nEpoch 82  ;Total Train correct: 453  ;Train loss: 23.989251770079136\nTotal Validation correct: 68  ;Validation Loss: 14.986350119113922\nValidation loss decreased (14.994408 --> 14.986350).  Saving model ...\n\n\nEpoch 83  ;Total Train correct: 453  ;Train loss: 23.962082244455814\nTotal Validation correct: 68  ;Validation Loss: 14.978320062160492\nValidation loss decreased (14.986350 --> 14.978320).  Saving model ...\n\n\nEpoch 84  ;Total Train correct: 453  ;Train loss: 23.9305137693882\nTotal Validation correct: 68  ;Validation Loss: 14.96454194188118\nValidation loss decreased (14.978320 --> 14.964542).  Saving model ...\n\n\nEpoch 85  ;Total Train correct: 454  ;Train loss: 23.861531279981136\nTotal Validation correct: 68  ;Validation Loss: 14.96126613020897\nValidation loss decreased (14.964542 --> 14.961266).  Saving model ...\n\n\nEpoch 86  ;Total Train correct: 454  ;Train loss: 23.86244673281908\nTotal Validation correct: 68  ;Validation Loss: 14.95895466208458\nValidation loss decreased (14.961266 --> 14.958955).  Saving model ...\n\n\nEpoch 87  ;Total Train correct: 454  ;Train loss: 23.856567833572626\nTotal Validation correct: 68  ;Validation Loss: 14.954619228839874\nValidation loss decreased (14.958955 --> 14.954619).  Saving model ...\n\n\nEpoch 88  ;Total Train correct: 454  ;Train loss: 23.766162760555744\nTotal Validation correct: 68  ;Validation Loss: 14.955310434103012\n\n\nEpoch 89  ;Total Train correct: 454  ;Train loss: 23.771079190075397\nTotal Validation correct: 68  ;Validation Loss: 14.938251256942749\nValidation loss decreased (14.954619 --> 14.938251).  Saving model ...\n\n\nEpoch 90  ;Total Train correct: 455  ;Train loss: 23.72950218617916\nTotal Validation correct: 67  ;Validation Loss: 14.927012026309967\nValidation loss decreased (14.938251 --> 14.927012).  Saving model ...\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 91  ;Total Train correct: 454  ;Train loss: 23.72417489439249\nTotal Validation correct: 68  ;Validation Loss: 14.907868891954422\nValidation loss decreased (14.927012 --> 14.907869).  Saving model ...\n\n\nEpoch 92  ;Total Train correct: 455  ;Train loss: 23.68083792924881\nTotal Validation correct: 67  ;Validation Loss: 14.929080128669739\n\n\nEpoch 93  ;Total Train correct: 456  ;Train loss: 23.643877122551203\nTotal Validation correct: 67  ;Validation Loss: 14.90528815984726\nValidation loss decreased (14.907869 --> 14.905288).  Saving model ...\n\n\nEpoch 94  ;Total Train correct: 457  ;Train loss: 23.620949275791645\nTotal Validation correct: 67  ;Validation Loss: 14.919493556022644\n\n\nEpoch 95  ;Total Train correct: 458  ;Train loss: 23.571504343301058\nTotal Validation correct: 67  ;Validation Loss: 14.952932596206665\n\n\nEpoch 96  ;Total Train correct: 457  ;Train loss: 23.58255412429571\nTotal Validation correct: 67  ;Validation Loss: 14.915206789970398\n\n\nEpoch 97  ;Total Train correct: 457  ;Train loss: 23.566853020340204\nTotal Validation correct: 67  ;Validation Loss: 14.922859519720078\n\n\nEpoch 98  ;Total Train correct: 457  ;Train loss: 23.53540539368987\nTotal Validation correct: 67  ;Validation Loss: 14.937124490737915\n\n\nEpoch 99  ;Total Train correct: 457  ;Train loss: 23.56270109117031\nTotal Validation correct: 67  ;Validation Loss: 14.913515388965607\n\n\nEpoch 100  ;Total Train correct: 457  ;Train loss: 23.567045263946056\nTotal Validation correct: 67  ;Validation Loss: 14.901507526636124\nValidation loss decreased (14.905288 --> 14.901508).  Saving model ...\n\n\nEpoch 101  ;Total Train correct: 458  ;Train loss: 23.602095615118742\nTotal Validation correct: 67  ;Validation Loss: 14.868656009435654\nValidation loss decreased (14.901508 --> 14.868656).  Saving model ...\n\n\nEpoch 102  ;Total Train correct: 458  ;Train loss: 23.543980568647385\nTotal Validation correct: 67  ;Validation Loss: 14.863861471414566\nValidation loss decreased (14.868656 --> 14.863861).  Saving model ...\n\n\nEpoch 103  ;Total Train correct: 457  ;Train loss: 23.58037020266056\nTotal Validation correct: 67  ;Validation Loss: 14.8356374502182\nValidation loss decreased (14.863861 --> 14.835637).  Saving model ...\n\n\nEpoch 104  ;Total Train correct: 457  ;Train loss: 23.521728079766035\nTotal Validation correct: 67  ;Validation Loss: 14.849547117948532\n\n\nEpoch 105  ;Total Train correct: 457  ;Train loss: 23.537573792040348\nTotal Validation correct: 67  ;Validation Loss: 14.80820420384407\nValidation loss decreased (14.835637 --> 14.808204).  Saving model ...\n\n\nEpoch 106  ;Total Train correct: 457  ;Train loss: 23.488446969538927\nTotal Validation correct: 67  ;Validation Loss: 14.800419747829437\nValidation loss decreased (14.808204 --> 14.800420).  Saving model ...\n\n\nEpoch 107  ;Total Train correct: 457  ;Train loss: 23.476539202034473\nTotal Validation correct: 67  ;Validation Loss: 14.8003289103508\nValidation loss decreased (14.800420 --> 14.800329).  Saving model ...\n\n\nEpoch 108  ;Total Train correct: 457  ;Train loss: 23.440939038991928\nTotal Validation correct: 67  ;Validation Loss: 14.796911239624023\nValidation loss decreased (14.800329 --> 14.796911).  Saving model ...\n\n\nEpoch 109  ;Total Train correct: 457  ;Train loss: 23.419533345848322\nTotal Validation correct: 67  ;Validation Loss: 14.79642990231514\nValidation loss decreased (14.796911 --> 14.796430).  Saving model ...\n\n\nEpoch 110  ;Total Train correct: 458  ;Train loss: 23.449487663805485\nTotal Validation correct: 67  ;Validation Loss: 14.783117324113846\nValidation loss decreased (14.796430 --> 14.783117).  Saving model ...\n\n\nEpoch 111  ;Total Train correct: 459  ;Train loss: 23.389368675649166\nTotal Validation correct: 67  ;Validation Loss: 14.80984941124916\n\n\nEpoch 112  ;Total Train correct: 458  ;Train loss: 23.404083635658026\nTotal Validation correct: 67  ;Validation Loss: 14.777241170406342\nValidation loss decreased (14.783117 --> 14.777241).  Saving model ...\n\n\nEpoch 113  ;Total Train correct: 458  ;Train loss: 23.416461426764727\nTotal Validation correct: 67  ;Validation Loss: 14.774263262748718\nValidation loss decreased (14.777241 --> 14.774263).  Saving model ...\n\n\nEpoch 114  ;Total Train correct: 458  ;Train loss: 23.424306958913803\nTotal Validation correct: 67  ;Validation Loss: 14.768365889787674\nValidation loss decreased (14.774263 --> 14.768366).  Saving model ...\n\n\nEpoch 115  ;Total Train correct: 458  ;Train loss: 23.36143997311592\nTotal Validation correct: 67  ;Validation Loss: 14.7701977789402\n\n\nEpoch 116  ;Total Train correct: 458  ;Train loss: 23.36054938286543\nTotal Validation correct: 67  ;Validation Loss: 14.790765553712845\n\n\nEpoch 117  ;Total Train correct: 458  ;Train loss: 23.38075692206621\nTotal Validation correct: 67  ;Validation Loss: 14.772798657417297\n\n\nEpoch 118  ;Total Train correct: 459  ;Train loss: 23.332665219902992\nTotal Validation correct: 67  ;Validation Loss: 14.774108320474625\n\n\nEpoch 119  ;Total Train correct: 458  ;Train loss: 23.365681752562523\nTotal Validation correct: 67  ;Validation Loss: 14.781221866607666\n\n\nEpoch 120  ;Total Train correct: 457  ;Train loss: 23.400227680802345\nTotal Validation correct: 67  ;Validation Loss: 14.742193788290024\nValidation loss decreased (14.768366 --> 14.742194).  Saving model ...\n\n\nEpoch 121  ;Total Train correct: 457  ;Train loss: 23.34497657418251\nTotal Validation correct: 67  ;Validation Loss: 14.776748061180115\n\n\nEpoch 122  ;Total Train correct: 457  ;Train loss: 23.398275408893824\nTotal Validation correct: 67  ;Validation Loss: 14.750856816768646\n\n\nEpoch 123  ;Total Train correct: 457  ;Train loss: 23.456523336470127\nTotal Validation correct: 67  ;Validation Loss: 14.735278278589249\nValidation loss decreased (14.742194 --> 14.735278).  Saving model ...\n\n\nEpoch 124  ;Total Train correct: 457  ;Train loss: 23.447283666580915\nTotal Validation correct: 68  ;Validation Loss: 14.734257638454437\nValidation loss decreased (14.735278 --> 14.734258).  Saving model ...\n\n\nEpoch 125  ;Total Train correct: 456  ;Train loss: 23.445010036230087\nTotal Validation correct: 69  ;Validation Loss: 14.743314564228058\n\n\nEpoch 126  ;Total Train correct: 456  ;Train loss: 23.487738244235516\nTotal Validation correct: 69  ;Validation Loss: 14.725752741098404\nValidation loss decreased (14.734258 --> 14.725753).  Saving model ...\n\n\nEpoch 127  ;Total Train correct: 456  ;Train loss: 23.53167414665222\nTotal Validation correct: 69  ;Validation Loss: 14.729608863592148\n\n\nEpoch 128  ;Total Train correct: 456  ;Train loss: 23.478373490273952\nTotal Validation correct: 69  ;Validation Loss: 14.712101966142654\nValidation loss decreased (14.725753 --> 14.712102).  Saving model ...\n\n\nEpoch 129  ;Total Train correct: 456  ;Train loss: 23.522388570010662\nTotal Validation correct: 69  ;Validation Loss: 14.689396172761917\nValidation loss decreased (14.712102 --> 14.689396).  Saving model ...\n\n\nEpoch 130  ;Total Train correct: 456  ;Train loss: 23.553443145006895\nTotal Validation correct: 70  ;Validation Loss: 14.672255903482437\nValidation loss decreased (14.689396 --> 14.672256).  Saving model ...\n\n\nEpoch 131  ;Total Train correct: 456  ;Train loss: 23.531378716230392\nTotal Validation correct: 70  ;Validation Loss: 14.66214194893837\nValidation loss decreased (14.672256 --> 14.662142).  Saving model ...\n\n\nEpoch 132  ;Total Train correct: 456  ;Train loss: 23.498101223260164\nTotal Validation correct: 70  ;Validation Loss: 14.663436084985733\n\n\nEpoch 133  ;Total Train correct: 456  ;Train loss: 23.478341057896614\nTotal Validation correct: 70  ;Validation Loss: 14.654798090457916\nValidation loss decreased (14.662142 --> 14.654798).  Saving model ...\n\n\nEpoch 134  ;Total Train correct: 456  ;Train loss: 23.470952160656452\nTotal Validation correct: 70  ;Validation Loss: 14.641439110040665\nValidation loss decreased (14.654798 --> 14.641439).  Saving model ...\n\n\nEpoch 135  ;Total Train correct: 456  ;Train loss: 23.505997724831104\nTotal Validation correct: 70  ;Validation Loss: 14.630972921848297\nValidation loss decreased (14.641439 --> 14.630973).  Saving model ...\n\n\nEpoch 136  ;Total Train correct: 456  ;Train loss: 23.481175400316715\nTotal Validation correct: 70  ;Validation Loss: 14.62385618686676\nValidation loss decreased (14.630973 --> 14.623856).  Saving model ...\n\n\nEpoch 137  ;Total Train correct: 456  ;Train loss: 23.387960873544216\nTotal Validation correct: 70  ;Validation Loss: 14.604096412658691\nValidation loss decreased (14.623856 --> 14.604096).  Saving model ...\n\n\nEpoch 138  ;Total Train correct: 456  ;Train loss: 23.417347941547632\nTotal Validation correct: 70  ;Validation Loss: 14.600390017032623\nValidation loss decreased (14.604096 --> 14.600390).  Saving model ...\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 139  ;Total Train correct: 456  ;Train loss: 23.416419811546803\nTotal Validation correct: 70  ;Validation Loss: 14.584253877401352\nValidation loss decreased (14.600390 --> 14.584254).  Saving model ...\n\n\nEpoch 140  ;Total Train correct: 456  ;Train loss: 23.38976164162159\nTotal Validation correct: 70  ;Validation Loss: 14.575179159641266\nValidation loss decreased (14.584254 --> 14.575179).  Saving model ...\n\n\nEpoch 141  ;Total Train correct: 456  ;Train loss: 23.356734309345484\nTotal Validation correct: 70  ;Validation Loss: 14.577549755573273\n\n\nEpoch 142  ;Total Train correct: 456  ;Train loss: 23.38244415447116\nTotal Validation correct: 71  ;Validation Loss: 14.587228953838348\n\n\nEpoch 143  ;Total Train correct: 456  ;Train loss: 23.340107310563326\nTotal Validation correct: 71  ;Validation Loss: 14.59669703245163\n\n\nEpoch 144  ;Total Train correct: 456  ;Train loss: 23.365270987153053\nTotal Validation correct: 71  ;Validation Loss: 14.58700281381607\n\n\nEpoch 145  ;Total Train correct: 456  ;Train loss: 23.34361633658409\nTotal Validation correct: 71  ;Validation Loss: 14.572031915187836\nValidation loss decreased (14.575179 --> 14.572032).  Saving model ...\n\n\nEpoch 146  ;Total Train correct: 456  ;Train loss: 23.38920471817255\nTotal Validation correct: 71  ;Validation Loss: 14.568923205137253\nValidation loss decreased (14.572032 --> 14.568923).  Saving model ...\n\n\nEpoch 147  ;Total Train correct: 456  ;Train loss: 23.386011764407158\nTotal Validation correct: 71  ;Validation Loss: 14.536769688129425\nValidation loss decreased (14.568923 --> 14.536770).  Saving model ...\n\n\nEpoch 148  ;Total Train correct: 455  ;Train loss: 23.393980905413628\nTotal Validation correct: 71  ;Validation Loss: 14.541092097759247\n\n\nEpoch 149  ;Total Train correct: 455  ;Train loss: 23.374760411679745\nTotal Validation correct: 71  ;Validation Loss: 14.509380251169205\nValidation loss decreased (14.536770 --> 14.509380).  Saving model ...\n\n\nEpoch 150  ;Total Train correct: 455  ;Train loss: 23.300936833024025\nTotal Validation correct: 71  ;Validation Loss: 14.511721283197403\n\n\nEpoch 151  ;Total Train correct: 455  ;Train loss: 23.3651567324996\nTotal Validation correct: 71  ;Validation Loss: 14.489975094795227\nValidation loss decreased (14.509380 --> 14.489975).  Saving model ...\n\n\nEpoch 152  ;Total Train correct: 455  ;Train loss: 23.36370849236846\nTotal Validation correct: 71  ;Validation Loss: 14.483285814523697\nValidation loss decreased (14.489975 --> 14.483286).  Saving model ...\n\n\nEpoch 153  ;Total Train correct: 455  ;Train loss: 23.369416795670986\nTotal Validation correct: 71  ;Validation Loss: 14.47405394911766\nValidation loss decreased (14.483286 --> 14.474054).  Saving model ...\n\n\nEpoch 154  ;Total Train correct: 455  ;Train loss: 23.37897577509284\nTotal Validation correct: 71  ;Validation Loss: 14.460921198129654\nValidation loss decreased (14.474054 --> 14.460921).  Saving model ...\n\n\nEpoch 155  ;Total Train correct: 455  ;Train loss: 23.329819545149803\nTotal Validation correct: 71  ;Validation Loss: 14.465630263090134\n\n\nEpoch 156  ;Total Train correct: 455  ;Train loss: 23.276424571871758\nTotal Validation correct: 71  ;Validation Loss: 14.44260948896408\nValidation loss decreased (14.460921 --> 14.442609).  Saving model ...\n\n\nEpoch 157  ;Total Train correct: 455  ;Train loss: 23.278322853147984\nTotal Validation correct: 71  ;Validation Loss: 14.434358209371567\nValidation loss decreased (14.442609 --> 14.434358).  Saving model ...\n\n\nEpoch 158  ;Total Train correct: 455  ;Train loss: 23.24260648712516\nTotal Validation correct: 71  ;Validation Loss: 14.445580780506134\n\n\nEpoch 159  ;Total Train correct: 455  ;Train loss: 23.227386713027954\nTotal Validation correct: 71  ;Validation Loss: 14.443352907896042\n\n\nEpoch 160  ;Total Train correct: 455  ;Train loss: 23.21364066377282\nTotal Validation correct: 71  ;Validation Loss: 14.437240183353424\n\n\nEpoch 161  ;Total Train correct: 455  ;Train loss: 23.21200779825449\nTotal Validation correct: 71  ;Validation Loss: 14.427922397851944\nValidation loss decreased (14.434358 --> 14.427922).  Saving model ...\n\n\nEpoch 162  ;Total Train correct: 455  ;Train loss: 23.201492115855217\nTotal Validation correct: 71  ;Validation Loss: 14.426262140274048\nValidation loss decreased (14.427922 --> 14.426262).  Saving model ...\n\n\nEpoch 163  ;Total Train correct: 455  ;Train loss: 23.184562098234892\nTotal Validation correct: 71  ;Validation Loss: 14.423269987106323\nValidation loss decreased (14.426262 --> 14.423270).  Saving model ...\n\n\nEpoch 164  ;Total Train correct: 455  ;Train loss: 23.169424019753933\nTotal Validation correct: 71  ;Validation Loss: 14.404151260852814\nValidation loss decreased (14.423270 --> 14.404151).  Saving model ...\n\n\nEpoch 165  ;Total Train correct: 455  ;Train loss: 23.15548913180828\nTotal Validation correct: 71  ;Validation Loss: 14.400275528430939\nValidation loss decreased (14.404151 --> 14.400276).  Saving model ...\n\n\nEpoch 166  ;Total Train correct: 455  ;Train loss: 23.138601649552584\nTotal Validation correct: 71  ;Validation Loss: 14.399529606103897\nValidation loss decreased (14.400276 --> 14.399530).  Saving model ...\n\n\nEpoch 167  ;Total Train correct: 455  ;Train loss: 23.10950879752636\nTotal Validation correct: 72  ;Validation Loss: 14.382726579904556\nValidation loss decreased (14.399530 --> 14.382727).  Saving model ...\n\n\nEpoch 168  ;Total Train correct: 455  ;Train loss: 23.111646428704262\nTotal Validation correct: 72  ;Validation Loss: 14.391198754310608\n\n\nEpoch 169  ;Total Train correct: 455  ;Train loss: 23.108565598726273\nTotal Validation correct: 72  ;Validation Loss: 14.382183939218521\nValidation loss decreased (14.382727 --> 14.382184).  Saving model ...\n\n\nEpoch 170  ;Total Train correct: 455  ;Train loss: 23.11469016596675\nTotal Validation correct: 72  ;Validation Loss: 14.367706269025803\nValidation loss decreased (14.382184 --> 14.367706).  Saving model ...\n\n\nEpoch 171  ;Total Train correct: 456  ;Train loss: 23.0750839561224\nTotal Validation correct: 73  ;Validation Loss: 14.358535796403885\nValidation loss decreased (14.367706 --> 14.358536).  Saving model ...\n\n\nEpoch 172  ;Total Train correct: 455  ;Train loss: 23.09865903109312\nTotal Validation correct: 72  ;Validation Loss: 14.376790434122086\n\n\nEpoch 173  ;Total Train correct: 455  ;Train loss: 23.07687722146511\nTotal Validation correct: 73  ;Validation Loss: 14.353328078985214\nValidation loss decreased (14.358536 --> 14.353328).  Saving model ...\n\n\nEpoch 174  ;Total Train correct: 455  ;Train loss: 23.11895416676998\nTotal Validation correct: 72  ;Validation Loss: 14.341640681028366\nValidation loss decreased (14.353328 --> 14.341641).  Saving model ...\n\n\nEpoch 175  ;Total Train correct: 455  ;Train loss: 23.13140692561865\nTotal Validation correct: 73  ;Validation Loss: 14.330816000699997\nValidation loss decreased (14.341641 --> 14.330816).  Saving model ...\n\n\nEpoch 176  ;Total Train correct: 455  ;Train loss: 23.13061438128352\nTotal Validation correct: 73  ;Validation Loss: 14.325335949659348\nValidation loss decreased (14.330816 --> 14.325336).  Saving model ...\n\n\nEpoch 177  ;Total Train correct: 454  ;Train loss: 23.155573546886444\nTotal Validation correct: 73  ;Validation Loss: 14.3246431350708\nValidation loss decreased (14.325336 --> 14.324643).  Saving model ...\n\n\nEpoch 178  ;Total Train correct: 454  ;Train loss: 23.140435565263033\nTotal Validation correct: 73  ;Validation Loss: 14.294515907764435\nValidation loss decreased (14.324643 --> 14.294516).  Saving model ...\n\n\nEpoch 179  ;Total Train correct: 454  ;Train loss: 23.13469198346138\nTotal Validation correct: 73  ;Validation Loss: 14.287073105573654\nValidation loss decreased (14.294516 --> 14.287073).  Saving model ...\n\n\nEpoch 180  ;Total Train correct: 454  ;Train loss: 23.151013154536486\nTotal Validation correct: 73  ;Validation Loss: 14.28665816783905\nValidation loss decreased (14.287073 --> 14.286658).  Saving model ...\n\n\nEpoch 181  ;Total Train correct: 454  ;Train loss: 23.137839555740356\nTotal Validation correct: 73  ;Validation Loss: 14.295765727758408\n\n\nEpoch 182  ;Total Train correct: 454  ;Train loss: 23.130540318787098\nTotal Validation correct: 73  ;Validation Loss: 14.262794196605682\nValidation loss decreased (14.286658 --> 14.262794).  Saving model ...\n\n\nEpoch 183  ;Total Train correct: 454  ;Train loss: 23.142788246273994\nTotal Validation correct: 73  ;Validation Loss: 14.257311671972275\nValidation loss decreased (14.262794 --> 14.257312).  Saving model ...\n\n\nEpoch 184  ;Total Train correct: 454  ;Train loss: 23.08367609232664\nTotal Validation correct: 74  ;Validation Loss: 14.273495614528656\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 185  ;Total Train correct: 454  ;Train loss: 23.10309987515211\nTotal Validation correct: 74  ;Validation Loss: 14.270674228668213\n\n\nEpoch 186  ;Total Train correct: 454  ;Train loss: 23.100283335894346\nTotal Validation correct: 74  ;Validation Loss: 14.243684947490692\nValidation loss decreased (14.257312 --> 14.243685).  Saving model ...\n\n\nEpoch 187  ;Total Train correct: 455  ;Train loss: 23.092385038733482\nTotal Validation correct: 74  ;Validation Loss: 14.248592466115952\n\n\nEpoch 188  ;Total Train correct: 455  ;Train loss: 23.085548050701618\nTotal Validation correct: 74  ;Validation Loss: 14.243350088596344\nValidation loss decreased (14.243685 --> 14.243350).  Saving model ...\n\n\nEpoch 189  ;Total Train correct: 455  ;Train loss: 23.091964453458786\nTotal Validation correct: 74  ;Validation Loss: 14.228776812553406\nValidation loss decreased (14.243350 --> 14.228777).  Saving model ...\n\n\nEpoch 190  ;Total Train correct: 455  ;Train loss: 23.083244644105434\nTotal Validation correct: 74  ;Validation Loss: 14.226024150848389\nValidation loss decreased (14.228777 --> 14.226024).  Saving model ...\n\n\nEpoch 191  ;Total Train correct: 454  ;Train loss: 23.09549755975604\nTotal Validation correct: 74  ;Validation Loss: 14.200608044862747\nValidation loss decreased (14.226024 --> 14.200608).  Saving model ...\n\n\nEpoch 192  ;Total Train correct: 455  ;Train loss: 23.049744073301554\nTotal Validation correct: 74  ;Validation Loss: 14.202185243368149\n\n\nEpoch 193  ;Total Train correct: 455  ;Train loss: 23.02125472947955\nTotal Validation correct: 74  ;Validation Loss: 14.181327104568481\nValidation loss decreased (14.200608 --> 14.181327).  Saving model ...\n\n\nEpoch 194  ;Total Train correct: 456  ;Train loss: 23.027874402701855\nTotal Validation correct: 74  ;Validation Loss: 14.175847202539444\nValidation loss decreased (14.181327 --> 14.175847).  Saving model ...\n\n\nEpoch 195  ;Total Train correct: 458  ;Train loss: 22.97231139242649\nTotal Validation correct: 74  ;Validation Loss: 14.195019006729126\n\n\nEpoch 196  ;Total Train correct: 457  ;Train loss: 23.013200975954533\nTotal Validation correct: 74  ;Validation Loss: 14.164045542478561\nValidation loss decreased (14.175847 --> 14.164046).  Saving model ...\n\n\nEpoch 197  ;Total Train correct: 456  ;Train loss: 22.991562880575657\nTotal Validation correct: 74  ;Validation Loss: 14.166002750396729\n\n\nEpoch 198  ;Total Train correct: 458  ;Train loss: 22.989988535642624\nTotal Validation correct: 74  ;Validation Loss: 14.162625551223755\nValidation loss decreased (14.164046 --> 14.162626).  Saving model ...\n\n\nEpoch 199  ;Total Train correct: 456  ;Train loss: 23.007768467068672\nTotal Validation correct: 75  ;Validation Loss: 14.146651804447174\nValidation loss decreased (14.162626 --> 14.146652).  Saving model ...\n\n\nEpoch 200  ;Total Train correct: 456  ;Train loss: 22.98206126317382\nTotal Validation correct: 75  ;Validation Loss: 14.163972228765488\n\n\nEpoch 201  ;Total Train correct: 456  ;Train loss: 22.99708755686879\nTotal Validation correct: 75  ;Validation Loss: 14.121914267539978\nValidation loss decreased (14.146652 --> 14.121914).  Saving model ...\n\n\nEpoch 202  ;Total Train correct: 457  ;Train loss: 22.93801946565509\nTotal Validation correct: 75  ;Validation Loss: 14.13858500123024\n\n\nEpoch 203  ;Total Train correct: 456  ;Train loss: 22.966269701719284\nTotal Validation correct: 75  ;Validation Loss: 14.12950998544693\n\n\nEpoch 204  ;Total Train correct: 458  ;Train loss: 22.928770761936903\nTotal Validation correct: 75  ;Validation Loss: 14.14366129040718\n\n\nEpoch 205  ;Total Train correct: 456  ;Train loss: 22.970328237861395\nTotal Validation correct: 75  ;Validation Loss: 14.13218092918396\n\n\nEpoch 206  ;Total Train correct: 457  ;Train loss: 22.978409752249718\nTotal Validation correct: 75  ;Validation Loss: 14.116031736135483\nValidation loss decreased (14.121914 --> 14.116032).  Saving model ...\n\n\nEpoch 207  ;Total Train correct: 457  ;Train loss: 22.949272878468037\nTotal Validation correct: 75  ;Validation Loss: 14.107827812433243\nValidation loss decreased (14.116032 --> 14.107828).  Saving model ...\n\n\nEpoch 208  ;Total Train correct: 456  ;Train loss: 22.97774327918887\nTotal Validation correct: 75  ;Validation Loss: 14.106001853942871\nValidation loss decreased (14.107828 --> 14.106002).  Saving model ...\n\n\nEpoch 209  ;Total Train correct: 456  ;Train loss: 23.03446387499571\nTotal Validation correct: 75  ;Validation Loss: 14.105712860822678\nValidation loss decreased (14.106002 --> 14.105713).  Saving model ...\n\n\nEpoch 210  ;Total Train correct: 454  ;Train loss: 23.025217924267054\nTotal Validation correct: 75  ;Validation Loss: 14.100871205329895\nValidation loss decreased (14.105713 --> 14.100871).  Saving model ...\n\n\nEpoch 211  ;Total Train correct: 454  ;Train loss: 23.04904568940401\nTotal Validation correct: 75  ;Validation Loss: 14.091226756572723\nValidation loss decreased (14.100871 --> 14.091227).  Saving model ...\n\n\nEpoch 212  ;Total Train correct: 453  ;Train loss: 23.043984837830067\nTotal Validation correct: 75  ;Validation Loss: 14.075270265340805\nValidation loss decreased (14.091227 --> 14.075270).  Saving model ...\n\n\nEpoch 213  ;Total Train correct: 454  ;Train loss: 23.00364777073264\nTotal Validation correct: 75  ;Validation Loss: 14.089206755161285\n\n\nEpoch 214  ;Total Train correct: 454  ;Train loss: 23.033872291445732\nTotal Validation correct: 75  ;Validation Loss: 14.074840515851974\nValidation loss decreased (14.075270 --> 14.074841).  Saving model ...\n\n\nEpoch 215  ;Total Train correct: 454  ;Train loss: 23.04684893041849\nTotal Validation correct: 75  ;Validation Loss: 14.06528690457344\nValidation loss decreased (14.074841 --> 14.065287).  Saving model ...\n\n\nEpoch 216  ;Total Train correct: 454  ;Train loss: 23.05032317340374\nTotal Validation correct: 75  ;Validation Loss: 14.051899790763855\nValidation loss decreased (14.065287 --> 14.051900).  Saving model ...\n\n\nEpoch 217  ;Total Train correct: 454  ;Train loss: 23.01392900943756\nTotal Validation correct: 75  ;Validation Loss: 14.058772504329681\n\n\nEpoch 218  ;Total Train correct: 454  ;Train loss: 23.0046034604311\nTotal Validation correct: 75  ;Validation Loss: 14.043735384941101\nValidation loss decreased (14.051900 --> 14.043735).  Saving model ...\n\n\nEpoch 219  ;Total Train correct: 454  ;Train loss: 23.044152110815048\nTotal Validation correct: 75  ;Validation Loss: 14.041811168193817\nValidation loss decreased (14.043735 --> 14.041811).  Saving model ...\n\n\nEpoch 220  ;Total Train correct: 456  ;Train loss: 22.978546228259802\nTotal Validation correct: 75  ;Validation Loss: 14.042954921722412\n\n\nEpoch 221  ;Total Train correct: 454  ;Train loss: 23.036115542054176\nTotal Validation correct: 75  ;Validation Loss: 14.036151081323624\nValidation loss decreased (14.041811 --> 14.036151).  Saving model ...\n\n\nEpoch 222  ;Total Train correct: 453  ;Train loss: 23.03524360433221\nTotal Validation correct: 75  ;Validation Loss: 14.028147548437119\nValidation loss decreased (14.036151 --> 14.028148).  Saving model ...\n\n\nEpoch 223  ;Total Train correct: 454  ;Train loss: 22.992619171738625\nTotal Validation correct: 75  ;Validation Loss: 14.028122395277023\nValidation loss decreased (14.028148 --> 14.028122).  Saving model ...\n\n\nEpoch 224  ;Total Train correct: 453  ;Train loss: 23.024468459188938\nTotal Validation correct: 75  ;Validation Loss: 14.02416443824768\nValidation loss decreased (14.028122 --> 14.024164).  Saving model ...\n\n\nEpoch 225  ;Total Train correct: 453  ;Train loss: 22.99283606186509\nTotal Validation correct: 75  ;Validation Loss: 14.020037204027176\nValidation loss decreased (14.024164 --> 14.020037).  Saving model ...\n\n\nEpoch 226  ;Total Train correct: 453  ;Train loss: 23.028193272650242\nTotal Validation correct: 75  ;Validation Loss: 14.009011059999466\nValidation loss decreased (14.020037 --> 14.009011).  Saving model ...\n\n\nEpoch 227  ;Total Train correct: 453  ;Train loss: 23.01181698963046\nTotal Validation correct: 75  ;Validation Loss: 14.004638433456421\nValidation loss decreased (14.009011 --> 14.004638).  Saving model ...\n\n\nEpoch 228  ;Total Train correct: 453  ;Train loss: 23.034596223384142\nTotal Validation correct: 75  ;Validation Loss: 13.987366676330566\nValidation loss decreased (14.004638 --> 13.987367).  Saving model ...\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 229  ;Total Train correct: 454  ;Train loss: 23.005395829677582\nTotal Validation correct: 75  ;Validation Loss: 13.999133616685867\n\n\nEpoch 230  ;Total Train correct: 453  ;Train loss: 23.017466865479946\nTotal Validation correct: 75  ;Validation Loss: 13.981471359729767\nValidation loss decreased (13.987367 --> 13.981471).  Saving model ...\n\n\nEpoch 231  ;Total Train correct: 453  ;Train loss: 23.04854939505458\nTotal Validation correct: 75  ;Validation Loss: 13.970197528600693\nValidation loss decreased (13.981471 --> 13.970198).  Saving model ...\n\n\nEpoch 232  ;Total Train correct: 454  ;Train loss: 22.98422046750784\nTotal Validation correct: 75  ;Validation Loss: 13.98110944032669\n\n\nEpoch 233  ;Total Train correct: 454  ;Train loss: 23.004358306527138\nTotal Validation correct: 75  ;Validation Loss: 13.959146052598953\nValidation loss decreased (13.970198 --> 13.959146).  Saving model ...\n\n\nEpoch 234  ;Total Train correct: 454  ;Train loss: 23.02239653468132\nTotal Validation correct: 75  ;Validation Loss: 13.961081773042679\n\n\nEpoch 235  ;Total Train correct: 454  ;Train loss: 23.044424284249544\nTotal Validation correct: 75  ;Validation Loss: 13.945861577987671\nValidation loss decreased (13.959146 --> 13.945862).  Saving model ...\n\n\nEpoch 236  ;Total Train correct: 454  ;Train loss: 23.01061435416341\nTotal Validation correct: 75  ;Validation Loss: 13.950936704874039\n\n\nEpoch 237  ;Total Train correct: 454  ;Train loss: 23.03099525719881\nTotal Validation correct: 75  ;Validation Loss: 13.933387488126755\nValidation loss decreased (13.945862 --> 13.933387).  Saving model ...\n\n\nEpoch 238  ;Total Train correct: 455  ;Train loss: 23.03178344666958\nTotal Validation correct: 75  ;Validation Loss: 13.931292057037354\nValidation loss decreased (13.933387 --> 13.931292).  Saving model ...\n\n\nEpoch 239  ;Total Train correct: 454  ;Train loss: 23.026052601635456\nTotal Validation correct: 75  ;Validation Loss: 13.941245406866074\n\n\nEpoch 240  ;Total Train correct: 455  ;Train loss: 23.038056310266256\nTotal Validation correct: 75  ;Validation Loss: 13.91477283835411\nValidation loss decreased (13.931292 --> 13.914773).  Saving model ...\n\n\nEpoch 241  ;Total Train correct: 455  ;Train loss: 23.004323787987232\nTotal Validation correct: 75  ;Validation Loss: 13.928613990545273\n\n\nEpoch 242  ;Total Train correct: 455  ;Train loss: 23.020709071308374\nTotal Validation correct: 75  ;Validation Loss: 13.908346116542816\nValidation loss decreased (13.914773 --> 13.908346).  Saving model ...\n\n\nEpoch 243  ;Total Train correct: 455  ;Train loss: 22.977649439126253\nTotal Validation correct: 75  ;Validation Loss: 13.913728505373001\n\n\nEpoch 244  ;Total Train correct: 454  ;Train loss: 23.04378406703472\nTotal Validation correct: 75  ;Validation Loss: 13.907056540250778\nValidation loss decreased (13.908346 --> 13.907057).  Saving model ...\n\n\nEpoch 245  ;Total Train correct: 455  ;Train loss: 22.989633172750473\nTotal Validation correct: 75  ;Validation Loss: 13.900562554597855\nValidation loss decreased (13.907057 --> 13.900563).  Saving model ...\n\n\nEpoch 246  ;Total Train correct: 455  ;Train loss: 23.000038094818592\nTotal Validation correct: 75  ;Validation Loss: 13.906625121831894\n\n\nEpoch 247  ;Total Train correct: 455  ;Train loss: 23.019022844731808\nTotal Validation correct: 75  ;Validation Loss: 13.896884351968765\nValidation loss decreased (13.900563 --> 13.896884).  Saving model ...\n\n\nEpoch 248  ;Total Train correct: 455  ;Train loss: 22.984519738703966\nTotal Validation correct: 75  ;Validation Loss: 13.89048171043396\nValidation loss decreased (13.896884 --> 13.890482).  Saving model ...\n\n\nEpoch 249  ;Total Train correct: 455  ;Train loss: 23.03357319533825\nTotal Validation correct: 75  ;Validation Loss: 13.885365277528763\nValidation loss decreased (13.890482 --> 13.885365).  Saving model ...\n\n\nEpoch 250  ;Total Train correct: 455  ;Train loss: 23.03155744075775\nTotal Validation correct: 75  ;Validation Loss: 13.895684719085693\n\n\nEpoch 251  ;Total Train correct: 455  ;Train loss: 22.988433372229338\nTotal Validation correct: 75  ;Validation Loss: 13.876763999462128\nValidation loss decreased (13.885365 --> 13.876764).  Saving model ...\n\n\nEpoch 252  ;Total Train correct: 455  ;Train loss: 22.993934638798237\nTotal Validation correct: 75  ;Validation Loss: 13.879595279693604\n\n\nEpoch 253  ;Total Train correct: 455  ;Train loss: 23.029614627361298\nTotal Validation correct: 75  ;Validation Loss: 13.875189870595932\nValidation loss decreased (13.876764 --> 13.875190).  Saving model ...\n\n\nEpoch 254  ;Total Train correct: 455  ;Train loss: 23.03814484551549\nTotal Validation correct: 75  ;Validation Loss: 13.851088404655457\nValidation loss decreased (13.875190 --> 13.851088).  Saving model ...\n\n\nEpoch 255  ;Total Train correct: 455  ;Train loss: 22.990924429148436\nTotal Validation correct: 75  ;Validation Loss: 13.876644939184189\n\n\nEpoch 256  ;Total Train correct: 455  ;Train loss: 23.042411737143993\nTotal Validation correct: 75  ;Validation Loss: 13.841936618089676\nValidation loss decreased (13.851088 --> 13.841937).  Saving model ...\n\n\nEpoch 257  ;Total Train correct: 455  ;Train loss: 23.020197831094265\nTotal Validation correct: 75  ;Validation Loss: 13.843255430459976\n\n\nEpoch 258  ;Total Train correct: 455  ;Train loss: 22.982070568948984\nTotal Validation correct: 75  ;Validation Loss: 13.843946039676666\n\n\nEpoch 259  ;Total Train correct: 455  ;Train loss: 22.98862686008215\nTotal Validation correct: 75  ;Validation Loss: 13.842758446931839\n\n\nEpoch 260  ;Total Train correct: 455  ;Train loss: 23.009249314665794\nTotal Validation correct: 75  ;Validation Loss: 13.835948795080185\nValidation loss decreased (13.841937 --> 13.835949).  Saving model ...\n\n\nEpoch 261  ;Total Train correct: 455  ;Train loss: 22.985032688826323\nTotal Validation correct: 75  ;Validation Loss: 13.836075872182846\n\n\nEpoch 262  ;Total Train correct: 455  ;Train loss: 23.018617920577526\nTotal Validation correct: 75  ;Validation Loss: 13.82032498717308\nValidation loss decreased (13.835949 --> 13.820325).  Saving model ...\n\n\nEpoch 263  ;Total Train correct: 455  ;Train loss: 23.012720488011837\nTotal Validation correct: 75  ;Validation Loss: 13.818598419427872\nValidation loss decreased (13.820325 --> 13.818598).  Saving model ...\n\n\nEpoch 264  ;Total Train correct: 455  ;Train loss: 22.965694591403008\nTotal Validation correct: 75  ;Validation Loss: 13.82018369436264\n\n\nEpoch 265  ;Total Train correct: 455  ;Train loss: 22.97604414448142\nTotal Validation correct: 75  ;Validation Loss: 13.815856784582138\nValidation loss decreased (13.818598 --> 13.815857).  Saving model ...\n\n\nEpoch 266  ;Total Train correct: 455  ;Train loss: 23.014910962432623\nTotal Validation correct: 75  ;Validation Loss: 13.801465719938278\nValidation loss decreased (13.815857 --> 13.801466).  Saving model ...\n\n\nEpoch 267  ;Total Train correct: 455  ;Train loss: 23.0142465159297\nTotal Validation correct: 75  ;Validation Loss: 13.787043660879135\nValidation loss decreased (13.801466 --> 13.787044).  Saving model ...\n\n\nEpoch 268  ;Total Train correct: 455  ;Train loss: 23.022858928889036\nTotal Validation correct: 75  ;Validation Loss: 13.786951184272766\nValidation loss decreased (13.787044 --> 13.786951).  Saving model ...\n\n\nEpoch 269  ;Total Train correct: 455  ;Train loss: 23.012566152960062\nTotal Validation correct: 75  ;Validation Loss: 13.783004820346832\nValidation loss decreased (13.786951 --> 13.783005).  Saving model ...\n\n\nEpoch 270  ;Total Train correct: 455  ;Train loss: 23.00948964431882\nTotal Validation correct: 75  ;Validation Loss: 13.781444013118744\nValidation loss decreased (13.783005 --> 13.781444).  Saving model ...\n\n\nEpoch 271  ;Total Train correct: 455  ;Train loss: 22.98240389674902\nTotal Validation correct: 75  ;Validation Loss: 13.775139272212982\nValidation loss decreased (13.781444 --> 13.775139).  Saving model ...\n\n\nEpoch 272  ;Total Train correct: 455  ;Train loss: 22.984354086220264\nTotal Validation correct: 75  ;Validation Loss: 13.769810110330582\nValidation loss decreased (13.775139 --> 13.769810).  Saving model ...\n\n\nEpoch 273  ;Total Train correct: 455  ;Train loss: 22.986754175275564\nTotal Validation correct: 75  ;Validation Loss: 13.761245548725128\nValidation loss decreased (13.769810 --> 13.761246).  Saving model ...\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 274  ;Total Train correct: 455  ;Train loss: 23.030916646122932\nTotal Validation correct: 75  ;Validation Loss: 13.764854282140732\n\n\nEpoch 275  ;Total Train correct: 455  ;Train loss: 22.935524329543114\nTotal Validation correct: 75  ;Validation Loss: 13.767287462949753\n\n\nEpoch 276  ;Total Train correct: 455  ;Train loss: 23.038013719022274\nTotal Validation correct: 75  ;Validation Loss: 13.757654577493668\nValidation loss decreased (13.761246 --> 13.757655).  Saving model ...\n\n\nEpoch 277  ;Total Train correct: 455  ;Train loss: 23.02219806611538\nTotal Validation correct: 75  ;Validation Loss: 13.74483072757721\nValidation loss decreased (13.757655 --> 13.744831).  Saving model ...\n\n\nEpoch 278  ;Total Train correct: 455  ;Train loss: 23.03283414617181\nTotal Validation correct: 75  ;Validation Loss: 13.750160783529282\n\n\nEpoch 279  ;Total Train correct: 455  ;Train loss: 23.019212186336517\nTotal Validation correct: 75  ;Validation Loss: 13.712413281202316\nValidation loss decreased (13.744831 --> 13.712413).  Saving model ...\n\n\nEpoch 280  ;Total Train correct: 455  ;Train loss: 23.026393987238407\nTotal Validation correct: 75  ;Validation Loss: 13.726154327392578\n\n\nEpoch 281  ;Total Train correct: 455  ;Train loss: 23.0059572160244\nTotal Validation correct: 75  ;Validation Loss: 13.718286991119385\n\n\nEpoch 282  ;Total Train correct: 455  ;Train loss: 23.001320872455835\nTotal Validation correct: 75  ;Validation Loss: 13.732075303792953\n\n\nEpoch 283  ;Total Train correct: 455  ;Train loss: 23.012654285877943\nTotal Validation correct: 75  ;Validation Loss: 13.710752487182617\nValidation loss decreased (13.712413 --> 13.710752).  Saving model ...\n\n\nEpoch 284  ;Total Train correct: 455  ;Train loss: 23.03294849768281\nTotal Validation correct: 75  ;Validation Loss: 13.709960043430328\nValidation loss decreased (13.710752 --> 13.709960).  Saving model ...\n\n\nEpoch 285  ;Total Train correct: 455  ;Train loss: 22.964655626565218\nTotal Validation correct: 75  ;Validation Loss: 13.711014032363892\n\n\nEpoch 286  ;Total Train correct: 455  ;Train loss: 23.00091528892517\nTotal Validation correct: 75  ;Validation Loss: 13.697550415992737\nValidation loss decreased (13.709960 --> 13.697550).  Saving model ...\n\n\nEpoch 287  ;Total Train correct: 456  ;Train loss: 22.94663342088461\nTotal Validation correct: 75  ;Validation Loss: 13.716546386480331\n\n\nEpoch 288  ;Total Train correct: 455  ;Train loss: 22.985169183462858\nTotal Validation correct: 75  ;Validation Loss: 13.693279087543488\nValidation loss decreased (13.697550 --> 13.693279).  Saving model ...\n\n\nEpoch 289  ;Total Train correct: 455  ;Train loss: 22.983678579330444\nTotal Validation correct: 75  ;Validation Loss: 13.683956116437912\nValidation loss decreased (13.693279 --> 13.683956).  Saving model ...\n\n\nEpoch 290  ;Total Train correct: 455  ;Train loss: 22.973695416003466\nTotal Validation correct: 75  ;Validation Loss: 13.675477355718613\nValidation loss decreased (13.683956 --> 13.675477).  Saving model ...\n\n\nEpoch 291  ;Total Train correct: 456  ;Train loss: 22.943969577550888\nTotal Validation correct: 75  ;Validation Loss: 13.683671534061432\n\n\nEpoch 292  ;Total Train correct: 455  ;Train loss: 22.932814124971628\nTotal Validation correct: 75  ;Validation Loss: 13.677108645439148\n\n\nEpoch 293  ;Total Train correct: 455  ;Train loss: 22.963396295905113\nTotal Validation correct: 75  ;Validation Loss: 13.679682224988937\n\n\nEpoch 294  ;Total Train correct: 456  ;Train loss: 22.91502197086811\nTotal Validation correct: 75  ;Validation Loss: 13.667647570371628\nValidation loss decreased (13.675477 --> 13.667648).  Saving model ...\n\n\nEpoch 295  ;Total Train correct: 455  ;Train loss: 22.9644571878016\nTotal Validation correct: 75  ;Validation Loss: 13.665061891078949\nValidation loss decreased (13.667648 --> 13.665062).  Saving model ...\n\n\nEpoch 296  ;Total Train correct: 456  ;Train loss: 22.911415111273527\nTotal Validation correct: 75  ;Validation Loss: 13.650330692529678\nValidation loss decreased (13.665062 --> 13.650331).  Saving model ...\n\n\nEpoch 297  ;Total Train correct: 455  ;Train loss: 22.941263508051634\nTotal Validation correct: 75  ;Validation Loss: 13.661231577396393\n\n\nEpoch 298  ;Total Train correct: 455  ;Train loss: 22.930954933166504\nTotal Validation correct: 75  ;Validation Loss: 13.644163072109222\nValidation loss decreased (13.650331 --> 13.644163).  Saving model ...\n\n\nEpoch 299  ;Total Train correct: 456  ;Train loss: 22.903213683515787\nTotal Validation correct: 75  ;Validation Loss: 13.649438127875328\n\n\nEpoch 300  ;Total Train correct: 456  ;Train loss: 22.898745272308588\nTotal Validation correct: 75  ;Validation Loss: 13.640744119882584\nValidation loss decreased (13.644163 --> 13.640744).  Saving model ...\n\n\nEpoch 301  ;Total Train correct: 455  ;Train loss: 22.89400963112712\nTotal Validation correct: 75  ;Validation Loss: 13.626230478286743\nValidation loss decreased (13.640744 --> 13.626230).  Saving model ...\n\n\nEpoch 302  ;Total Train correct: 456  ;Train loss: 22.868300899863243\nTotal Validation correct: 75  ;Validation Loss: 13.618055626749992\nValidation loss decreased (13.626230 --> 13.618056).  Saving model ...\n\n\nEpoch 303  ;Total Train correct: 455  ;Train loss: 22.85945273935795\nTotal Validation correct: 75  ;Validation Loss: 13.64222526550293\n\n\nEpoch 304  ;Total Train correct: 456  ;Train loss: 22.862710259854794\nTotal Validation correct: 75  ;Validation Loss: 13.629655867815018\n\n\nEpoch 305  ;Total Train correct: 455  ;Train loss: 22.853544276207685\nTotal Validation correct: 75  ;Validation Loss: 13.613656252622604\nValidation loss decreased (13.618056 --> 13.613656).  Saving model ...\n\n\nEpoch 306  ;Total Train correct: 456  ;Train loss: 22.853341575711966\nTotal Validation correct: 75  ;Validation Loss: 13.616427287459373\n\n\nEpoch 307  ;Total Train correct: 454  ;Train loss: 22.805783540010452\nTotal Validation correct: 75  ;Validation Loss: 13.614371791481972\n\n\nEpoch 308  ;Total Train correct: 455  ;Train loss: 22.825662180781364\nTotal Validation correct: 75  ;Validation Loss: 13.596096605062485\nValidation loss decreased (13.613656 --> 13.596097).  Saving model ...\n\n\nEpoch 309  ;Total Train correct: 454  ;Train loss: 22.822522148489952\nTotal Validation correct: 75  ;Validation Loss: 13.601911589503288\n\n\nEpoch 310  ;Total Train correct: 454  ;Train loss: 22.814874090254307\nTotal Validation correct: 75  ;Validation Loss: 13.588949203491211\nValidation loss decreased (13.596097 --> 13.588949).  Saving model ...\n\n\nEpoch 311  ;Total Train correct: 454  ;Train loss: 22.78839708864689\nTotal Validation correct: 75  ;Validation Loss: 13.588675498962402\nValidation loss decreased (13.588949 --> 13.588675).  Saving model ...\n\n\nEpoch 312  ;Total Train correct: 454  ;Train loss: 22.83783033490181\nTotal Validation correct: 75  ;Validation Loss: 13.563417434692383\nValidation loss decreased (13.588675 --> 13.563417).  Saving model ...\n\n\nEpoch 313  ;Total Train correct: 454  ;Train loss: 22.74276015534997\nTotal Validation correct: 75  ;Validation Loss: 13.591415703296661\n\n\nEpoch 314  ;Total Train correct: 454  ;Train loss: 22.821177057921886\nTotal Validation correct: 75  ;Validation Loss: 13.564370512962341\n\n\nEpoch 315  ;Total Train correct: 454  ;Train loss: 22.760119523853064\nTotal Validation correct: 75  ;Validation Loss: 13.57144258916378\n\n\nEpoch 316  ;Total Train correct: 454  ;Train loss: 22.789751201868057\nTotal Validation correct: 75  ;Validation Loss: 13.535173997282982\nValidation loss decreased (13.563417 --> 13.535174).  Saving model ...\n\n\nEpoch 317  ;Total Train correct: 454  ;Train loss: 22.691715396940708\nTotal Validation correct: 75  ;Validation Loss: 13.570808500051498\n\n\nEpoch 318  ;Total Train correct: 454  ;Train loss: 22.765929892659187\nTotal Validation correct: 75  ;Validation Loss: 13.530167266726494\nValidation loss decreased (13.535174 --> 13.530167).  Saving model ...\n\n\nEpoch 319  ;Total Train correct: 454  ;Train loss: 22.770154863595963\nTotal Validation correct: 75  ;Validation Loss: 13.534171044826508\n\n\nEpoch 320  ;Total Train correct: 454  ;Train loss: 22.706378892064095\nTotal Validation correct: 75  ;Validation Loss: 13.53807157278061\n\n\nEpoch 321  ;Total Train correct: 454  ;Train loss: 22.715436514467\nTotal Validation correct: 75  ;Validation Loss: 13.529687359929085\nValidation loss decreased (13.530167 --> 13.529687).  Saving model ...\n\n\nEpoch 322  ;Total Train correct: 454  ;Train loss: 22.706120017915964\nTotal Validation correct: 75  ;Validation Loss: 13.51350574195385\nValidation loss decreased (13.529687 --> 13.513506).  Saving model ...\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 323  ;Total Train correct: 454  ;Train loss: 22.68618816882372\nTotal Validation correct: 75  ;Validation Loss: 13.51804043352604\n\n\nEpoch 324  ;Total Train correct: 454  ;Train loss: 22.661747746169567\nTotal Validation correct: 75  ;Validation Loss: 13.484272629022598\nValidation loss decreased (13.513506 --> 13.484273).  Saving model ...\n\n\nEpoch 325  ;Total Train correct: 454  ;Train loss: 22.554262828081846\nTotal Validation correct: 75  ;Validation Loss: 13.530603140592575\n\n\nEpoch 326  ;Total Train correct: 454  ;Train loss: 22.659601770341396\nTotal Validation correct: 75  ;Validation Loss: 13.4898302257061\n\n\nEpoch 327  ;Total Train correct: 454  ;Train loss: 22.592165678739548\nTotal Validation correct: 75  ;Validation Loss: 13.50356873869896\n\n\nEpoch 328  ;Total Train correct: 454  ;Train loss: 22.53946739435196\nTotal Validation correct: 75  ;Validation Loss: 13.503372207283974\n\n\nEpoch 329  ;Total Train correct: 454  ;Train loss: 22.56651909276843\nTotal Validation correct: 75  ;Validation Loss: 13.498208031058311\n\n\nEpoch 330  ;Total Train correct: 454  ;Train loss: 22.540603537112474\nTotal Validation correct: 75  ;Validation Loss: 13.488635629415512\n\n\nEpoch 331  ;Total Train correct: 454  ;Train loss: 22.532963197678328\nTotal Validation correct: 75  ;Validation Loss: 13.483774319291115\nValidation loss decreased (13.484273 --> 13.483774).  Saving model ...\n\n\nEpoch 332  ;Total Train correct: 454  ;Train loss: 22.521743584424257\nTotal Validation correct: 75  ;Validation Loss: 13.455474227666855\nValidation loss decreased (13.483774 --> 13.455474).  Saving model ...\n\n\nEpoch 333  ;Total Train correct: 454  ;Train loss: 22.482598394155502\nTotal Validation correct: 75  ;Validation Loss: 13.47223074734211\n\n\nEpoch 334  ;Total Train correct: 454  ;Train loss: 22.541232109069824\nTotal Validation correct: 75  ;Validation Loss: 13.460808396339417\n\n\nEpoch 335  ;Total Train correct: 454  ;Train loss: 22.41049712151289\nTotal Validation correct: 75  ;Validation Loss: 13.478458628058434\n\n\nEpoch 336  ;Total Train correct: 454  ;Train loss: 22.48516308516264\nTotal Validation correct: 75  ;Validation Loss: 13.46625754237175\n\n\nEpoch 337  ;Total Train correct: 454  ;Train loss: 22.450201276689768\nTotal Validation correct: 75  ;Validation Loss: 13.46897578239441\n\n\nEpoch 338  ;Total Train correct: 454  ;Train loss: 22.42847727611661\nTotal Validation correct: 75  ;Validation Loss: 13.438801601529121\nValidation loss decreased (13.455474 --> 13.438802).  Saving model ...\n\n\nEpoch 339  ;Total Train correct: 454  ;Train loss: 22.49097666889429\nTotal Validation correct: 75  ;Validation Loss: 13.427007958292961\nValidation loss decreased (13.438802 --> 13.427008).  Saving model ...\n\n\nEpoch 340  ;Total Train correct: 454  ;Train loss: 22.40568843483925\nTotal Validation correct: 75  ;Validation Loss: 13.46547544002533\n\n\nEpoch 341  ;Total Train correct: 454  ;Train loss: 22.434280171990395\nTotal Validation correct: 75  ;Validation Loss: 13.437871932983398\n\n\nEpoch 342  ;Total Train correct: 454  ;Train loss: 22.35239404067397\nTotal Validation correct: 75  ;Validation Loss: 13.438959419727325\n\n\nEpoch 343  ;Total Train correct: 454  ;Train loss: 22.423499636352062\nTotal Validation correct: 75  ;Validation Loss: 13.428817063570023\n\n\nEpoch 344  ;Total Train correct: 454  ;Train loss: 22.387600909918547\nTotal Validation correct: 75  ;Validation Loss: 13.436121046543121\n\n\nEpoch 345  ;Total Train correct: 454  ;Train loss: 22.36653707548976\nTotal Validation correct: 75  ;Validation Loss: 13.395198240876198\nValidation loss decreased (13.427008 --> 13.395198).  Saving model ...\n\n\nEpoch 346  ;Total Train correct: 454  ;Train loss: 22.30777657404542\nTotal Validation correct: 75  ;Validation Loss: 13.429132416844368\n\n\nEpoch 347  ;Total Train correct: 454  ;Train loss: 22.42012156918645\nTotal Validation correct: 75  ;Validation Loss: 13.404075384140015\n\n\nEpoch 348  ;Total Train correct: 454  ;Train loss: 22.29581803828478\nTotal Validation correct: 75  ;Validation Loss: 13.420563966035843\n\n\nEpoch 349  ;Total Train correct: 454  ;Train loss: 22.379498653113842\nTotal Validation correct: 75  ;Validation Loss: 13.386644423007965\nValidation loss decreased (13.395198 --> 13.386644).  Saving model ...\n\n\nEpoch 350  ;Total Train correct: 455  ;Train loss: 22.255366783589125\nTotal Validation correct: 75  ;Validation Loss: 13.402071759104729\n\n\nEpoch 351  ;Total Train correct: 454  ;Train loss: 22.314571753144264\nTotal Validation correct: 75  ;Validation Loss: 13.384846672415733\nValidation loss decreased (13.386644 --> 13.384847).  Saving model ...\n\n\nEpoch 352  ;Total Train correct: 454  ;Train loss: 22.3655596524477\nTotal Validation correct: 75  ;Validation Loss: 13.372291058301926\nValidation loss decreased (13.384847 --> 13.372291).  Saving model ...\n\n\nEpoch 353  ;Total Train correct: 455  ;Train loss: 22.24326341599226\nTotal Validation correct: 75  ;Validation Loss: 13.378926292061806\n\n\nEpoch 354  ;Total Train correct: 454  ;Train loss: 22.29822911322117\nTotal Validation correct: 75  ;Validation Loss: 13.350148737430573\nValidation loss decreased (13.372291 --> 13.350149).  Saving model ...\n\n\nEpoch 355  ;Total Train correct: 454  ;Train loss: 22.28367706388235\nTotal Validation correct: 75  ;Validation Loss: 13.359357550740242\n\n\nEpoch 356  ;Total Train correct: 455  ;Train loss: 22.240021135658026\nTotal Validation correct: 75  ;Validation Loss: 13.358783304691315\n\n\nEpoch 357  ;Total Train correct: 455  ;Train loss: 22.26851324364543\nTotal Validation correct: 75  ;Validation Loss: 13.34052874147892\nValidation loss decreased (13.350149 --> 13.340529).  Saving model ...\n\n\nEpoch 358  ;Total Train correct: 456  ;Train loss: 22.176353752613068\nTotal Validation correct: 74  ;Validation Loss: 13.359352111816406\n\n\nEpoch 359  ;Total Train correct: 456  ;Train loss: 22.235446080565453\nTotal Validation correct: 75  ;Validation Loss: 13.34207433462143\n\n\nEpoch 360  ;Total Train correct: 457  ;Train loss: 22.18500605970621\nTotal Validation correct: 74  ;Validation Loss: 13.354461014270782\n\n\nEpoch 361  ;Total Train correct: 456  ;Train loss: 22.22471970692277\nTotal Validation correct: 75  ;Validation Loss: 13.316382065415382\nValidation loss decreased (13.340529 --> 13.316382).  Saving model ...\n\n\nEpoch 362  ;Total Train correct: 457  ;Train loss: 22.16103431582451\nTotal Validation correct: 75  ;Validation Loss: 13.340253338217735\n\n\nEpoch 363  ;Total Train correct: 456  ;Train loss: 22.220291629433632\nTotal Validation correct: 75  ;Validation Loss: 13.28855112195015\nValidation loss decreased (13.316382 --> 13.288551).  Saving model ...\n\n\nEpoch 364  ;Total Train correct: 457  ;Train loss: 22.119000010192394\nTotal Validation correct: 74  ;Validation Loss: 13.323531046509743\n\n\nEpoch 365  ;Total Train correct: 456  ;Train loss: 22.182562235742807\nTotal Validation correct: 74  ;Validation Loss: 13.301111191511154\n\n\nEpoch 366  ;Total Train correct: 457  ;Train loss: 22.114162117242813\nTotal Validation correct: 74  ;Validation Loss: 13.29817020893097\n\n\nEpoch 367  ;Total Train correct: 457  ;Train loss: 22.122868608683348\nTotal Validation correct: 74  ;Validation Loss: 13.30447731912136\n\n\nEpoch 368  ;Total Train correct: 456  ;Train loss: 22.12512320280075\nTotal Validation correct: 75  ;Validation Loss: 13.25580409169197\nValidation loss decreased (13.288551 --> 13.255804).  Saving model ...\n\n\nEpoch 369  ;Total Train correct: 457  ;Train loss: 22.040597561746836\nTotal Validation correct: 74  ;Validation Loss: 13.306721538305283\n\n\nEpoch 370  ;Total Train correct: 457  ;Train loss: 22.109751027077436\nTotal Validation correct: 74  ;Validation Loss: 13.278813615441322\n\n\nEpoch 371  ;Total Train correct: 457  ;Train loss: 22.05945897102356\nTotal Validation correct: 74  ;Validation Loss: 13.275887787342072\n\n\nEpoch 372  ;Total Train correct: 456  ;Train loss: 22.156735222786665\nTotal Validation correct: 74  ;Validation Loss: 13.23917630314827\nValidation loss decreased (13.255804 --> 13.239176).  Saving model ...\n\n\nEpoch 373  ;Total Train correct: 457  ;Train loss: 22.0518833771348\nTotal Validation correct: 74  ;Validation Loss: 13.26736667752266\n\n\nEpoch 374  ;Total Train correct: 456  ;Train loss: 22.103302486240864\nTotal Validation correct: 74  ;Validation Loss: 13.22466167807579\nValidation loss decreased (13.239176 --> 13.224662).  Saving model ...\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 375  ;Total Train correct: 456  ;Train loss: 22.080227117985487\nTotal Validation correct: 74  ;Validation Loss: 13.230718269944191\n\n\nEpoch 376  ;Total Train correct: 457  ;Train loss: 22.00621835887432\nTotal Validation correct: 74  ;Validation Loss: 13.240302085876465\n\n\nEpoch 377  ;Total Train correct: 457  ;Train loss: 22.055448289960623\nTotal Validation correct: 74  ;Validation Loss: 13.243486687541008\n\n\nEpoch 378  ;Total Train correct: 457  ;Train loss: 22.00359245762229\nTotal Validation correct: 74  ;Validation Loss: 13.23236133158207\n\n\nEpoch 379  ;Total Train correct: 457  ;Train loss: 22.027526073157787\nTotal Validation correct: 74  ;Validation Loss: 13.215838238596916\nValidation loss decreased (13.224662 --> 13.215838).  Saving model ...\n\n\nEpoch 380  ;Total Train correct: 457  ;Train loss: 21.990085899829865\nTotal Validation correct: 74  ;Validation Loss: 13.220676809549332\n\n\nEpoch 381  ;Total Train correct: 457  ;Train loss: 22.044367149472237\nTotal Validation correct: 74  ;Validation Loss: 13.215260550379753\nValidation loss decreased (13.215838 --> 13.215261).  Saving model ...\n\n\nEpoch 382  ;Total Train correct: 457  ;Train loss: 22.025318887084723\nTotal Validation correct: 74  ;Validation Loss: 13.216278165578842\n\n\nEpoch 383  ;Total Train correct: 457  ;Train loss: 21.979236602783203\nTotal Validation correct: 74  ;Validation Loss: 13.210173264145851\nValidation loss decreased (13.215261 --> 13.210173).  Saving model ...\n\n\nEpoch 384  ;Total Train correct: 457  ;Train loss: 22.021437868475914\nTotal Validation correct: 74  ;Validation Loss: 13.18525955080986\nValidation loss decreased (13.210173 --> 13.185260).  Saving model ...\n\n\nEpoch 385  ;Total Train correct: 457  ;Train loss: 21.939918406307697\nTotal Validation correct: 74  ;Validation Loss: 13.197205185890198\n\n\nEpoch 386  ;Total Train correct: 457  ;Train loss: 21.980912666767836\nTotal Validation correct: 74  ;Validation Loss: 13.168769434094429\nValidation loss decreased (13.185260 --> 13.168769).  Saving model ...\n\n\nEpoch 387  ;Total Train correct: 457  ;Train loss: 21.89066069200635\nTotal Validation correct: 75  ;Validation Loss: 13.175121113657951\n\n\nEpoch 388  ;Total Train correct: 457  ;Train loss: 21.956270955502987\nTotal Validation correct: 75  ;Validation Loss: 13.14250610768795\nValidation loss decreased (13.168769 --> 13.142506).  Saving model ...\n\n\nEpoch 389  ;Total Train correct: 458  ;Train loss: 21.85611717775464\nTotal Validation correct: 75  ;Validation Loss: 13.181323170661926\n\n\nEpoch 390  ;Total Train correct: 458  ;Train loss: 21.858061157166958\nTotal Validation correct: 75  ;Validation Loss: 13.162469580769539\n\n\nEpoch 391  ;Total Train correct: 458  ;Train loss: 21.901261530816555\nTotal Validation correct: 75  ;Validation Loss: 13.151137232780457\n\n\nEpoch 392  ;Total Train correct: 458  ;Train loss: 21.829550467431545\nTotal Validation correct: 75  ;Validation Loss: 13.154890030622482\n\n\nEpoch 393  ;Total Train correct: 458  ;Train loss: 21.874935299158096\nTotal Validation correct: 75  ;Validation Loss: 13.121230721473694\nValidation loss decreased (13.142506 --> 13.121231).  Saving model ...\n\n\nEpoch 394  ;Total Train correct: 458  ;Train loss: 21.81113500520587\nTotal Validation correct: 75  ;Validation Loss: 13.133645325899124\n\n\nEpoch 395  ;Total Train correct: 459  ;Train loss: 21.819130666553974\nTotal Validation correct: 75  ;Validation Loss: 13.09983478486538\nValidation loss decreased (13.121231 --> 13.099835).  Saving model ...\n\n\nEpoch 396  ;Total Train correct: 459  ;Train loss: 21.78988915681839\nTotal Validation correct: 75  ;Validation Loss: 13.126403570175171\n\n\nEpoch 397  ;Total Train correct: 459  ;Train loss: 21.766595367342234\nTotal Validation correct: 75  ;Validation Loss: 13.101323664188385\n\n\nEpoch 398  ;Total Train correct: 459  ;Train loss: 21.816603258252144\nTotal Validation correct: 75  ;Validation Loss: 13.103200674057007\n\n\nEpoch 399  ;Total Train correct: 459  ;Train loss: 21.704958826303482\nTotal Validation correct: 75  ;Validation Loss: 13.120722025632858\n\n\nEpoch 400  ;Total Train correct: 459  ;Train loss: 21.739771500229836\nTotal Validation correct: 75  ;Validation Loss: 13.103226408362389\n\n\nEpoch 401  ;Total Train correct: 459  ;Train loss: 21.660880610346794\nTotal Validation correct: 75  ;Validation Loss: 13.091771334409714\nValidation loss decreased (13.099835 --> 13.091771).  Saving model ...\n\n\nEpoch 402  ;Total Train correct: 459  ;Train loss: 21.666731998324394\nTotal Validation correct: 75  ;Validation Loss: 13.097259193658829\n\n\nEpoch 403  ;Total Train correct: 459  ;Train loss: 21.69678057730198\nTotal Validation correct: 75  ;Validation Loss: 13.074422806501389\nValidation loss decreased (13.091771 --> 13.074423).  Saving model ...\n\n\nEpoch 404  ;Total Train correct: 459  ;Train loss: 21.605625059455633\nTotal Validation correct: 75  ;Validation Loss: 13.07873611152172\n\n\nEpoch 405  ;Total Train correct: 460  ;Train loss: 21.57386029884219\nTotal Validation correct: 75  ;Validation Loss: 13.07228797674179\nValidation loss decreased (13.074423 --> 13.072288).  Saving model ...\n\n\nEpoch 406  ;Total Train correct: 460  ;Train loss: 21.554622072726488\nTotal Validation correct: 75  ;Validation Loss: 13.061597406864166\nValidation loss decreased (13.072288 --> 13.061597).  Saving model ...\n\n\nEpoch 407  ;Total Train correct: 459  ;Train loss: 21.64013262093067\nTotal Validation correct: 75  ;Validation Loss: 13.046171084046364\nValidation loss decreased (13.061597 --> 13.046171).  Saving model ...\n\n\nEpoch 408  ;Total Train correct: 460  ;Train loss: 21.558389857411385\nTotal Validation correct: 75  ;Validation Loss: 13.068197339773178\n\n\nEpoch 409  ;Total Train correct: 460  ;Train loss: 21.51879531890154\nTotal Validation correct: 75  ;Validation Loss: 13.039464086294174\nValidation loss decreased (13.046171 --> 13.039464).  Saving model ...\n\n\nEpoch 410  ;Total Train correct: 460  ;Train loss: 21.606617141515017\nTotal Validation correct: 75  ;Validation Loss: 13.03256618976593\nValidation loss decreased (13.039464 --> 13.032566).  Saving model ...\n\n\nEpoch 411  ;Total Train correct: 460  ;Train loss: 21.531757213175297\nTotal Validation correct: 75  ;Validation Loss: 13.030550569295883\nValidation loss decreased (13.032566 --> 13.030551).  Saving model ...\n\n\nEpoch 412  ;Total Train correct: 460  ;Train loss: 21.542711913585663\nTotal Validation correct: 75  ;Validation Loss: 13.041758939623833\n\n\nEpoch 413  ;Total Train correct: 460  ;Train loss: 21.514573123306036\nTotal Validation correct: 75  ;Validation Loss: 13.001320198178291\nValidation loss decreased (13.030551 --> 13.001320).  Saving model ...\n\n\nEpoch 414  ;Total Train correct: 460  ;Train loss: 21.436561793088913\nTotal Validation correct: 75  ;Validation Loss: 13.021106734871864\n\n\nEpoch 415  ;Total Train correct: 460  ;Train loss: 21.42233856394887\nTotal Validation correct: 75  ;Validation Loss: 13.011332303285599\n\n\nEpoch 416  ;Total Train correct: 460  ;Train loss: 21.424939047545195\nTotal Validation correct: 75  ;Validation Loss: 13.000929027795792\nValidation loss decreased (13.001320 --> 13.000929).  Saving model ...\n\n\nEpoch 417  ;Total Train correct: 460  ;Train loss: 21.480320259928703\nTotal Validation correct: 76  ;Validation Loss: 12.983559653162956\nValidation loss decreased (13.000929 --> 12.983560).  Saving model ...\n\n\nEpoch 418  ;Total Train correct: 460  ;Train loss: 21.384108126163483\nTotal Validation correct: 75  ;Validation Loss: 12.991877019405365\n\n\nEpoch 419  ;Total Train correct: 460  ;Train loss: 21.3744686357677\nTotal Validation correct: 76  ;Validation Loss: 12.982669934630394\nValidation loss decreased (12.983560 --> 12.982670).  Saving model ...\n\n\nEpoch 420  ;Total Train correct: 459  ;Train loss: 21.350750017911196\nTotal Validation correct: 75  ;Validation Loss: 13.016164481639862\n\n\nEpoch 421  ;Total Train correct: 459  ;Train loss: 21.45591789856553\nTotal Validation correct: 76  ;Validation Loss: 12.956597670912743\nValidation loss decreased (12.982670 --> 12.956598).  Saving model ...\n\n\nEpoch 422  ;Total Train correct: 459  ;Train loss: 21.348610684275627\nTotal Validation correct: 75  ;Validation Loss: 12.975556313991547\n\n\nEpoch 423  ;Total Train correct: 459  ;Train loss: 21.37544048950076\nTotal Validation correct: 76  ;Validation Loss: 12.986027032136917\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 424  ;Total Train correct: 459  ;Train loss: 21.3675602003932\nTotal Validation correct: 76  ;Validation Loss: 12.954761490225792\nValidation loss decreased (12.956598 --> 12.954761).  Saving model ...\n\n\nEpoch 425  ;Total Train correct: 459  ;Train loss: 21.327306851744652\nTotal Validation correct: 75  ;Validation Loss: 12.963248118758202\n\n\nEpoch 426  ;Total Train correct: 459  ;Train loss: 21.34058468043804\nTotal Validation correct: 76  ;Validation Loss: 12.959210097789764\n\n\nEpoch 427  ;Total Train correct: 460  ;Train loss: 21.26605922728777\nTotal Validation correct: 76  ;Validation Loss: 12.944630101323128\nValidation loss decreased (12.954761 --> 12.944630).  Saving model ...\n\n\nEpoch 428  ;Total Train correct: 460  ;Train loss: 21.26693696156144\nTotal Validation correct: 76  ;Validation Loss: 12.962899208068848\n\n\nEpoch 429  ;Total Train correct: 460  ;Train loss: 21.3090733140707\nTotal Validation correct: 76  ;Validation Loss: 12.973962113261223\n\n\nEpoch 430  ;Total Train correct: 460  ;Train loss: 21.24430426955223\nTotal Validation correct: 76  ;Validation Loss: 12.943926095962524\nValidation loss decreased (12.944630 --> 12.943926).  Saving model ...\n\n\nEpoch 431  ;Total Train correct: 460  ;Train loss: 21.216687113046646\nTotal Validation correct: 76  ;Validation Loss: 12.9201899766922\nValidation loss decreased (12.943926 --> 12.920190).  Saving model ...\n\n\nEpoch 432  ;Total Train correct: 460  ;Train loss: 21.255635119974613\nTotal Validation correct: 76  ;Validation Loss: 12.921213001012802\n\n\nEpoch 433  ;Total Train correct: 460  ;Train loss: 21.179799865931273\nTotal Validation correct: 76  ;Validation Loss: 12.925747975707054\n\n\nEpoch 434  ;Total Train correct: 460  ;Train loss: 21.143465168774128\nTotal Validation correct: 76  ;Validation Loss: 12.911752700805664\nValidation loss decreased (12.920190 --> 12.911753).  Saving model ...\n\n\nEpoch 435  ;Total Train correct: 460  ;Train loss: 21.151147063821554\nTotal Validation correct: 76  ;Validation Loss: 12.902287125587463\nValidation loss decreased (12.911753 --> 12.902287).  Saving model ...\n\n\nEpoch 436  ;Total Train correct: 460  ;Train loss: 21.133944615721703\nTotal Validation correct: 76  ;Validation Loss: 12.911402732133865\n\n\nEpoch 437  ;Total Train correct: 460  ;Train loss: 21.16342695057392\nTotal Validation correct: 76  ;Validation Loss: 12.862420156598091\nValidation loss decreased (12.902287 --> 12.862420).  Saving model ...\n\n\nEpoch 438  ;Total Train correct: 460  ;Train loss: 21.172471519559622\nTotal Validation correct: 76  ;Validation Loss: 12.901700094342232\n\n\nEpoch 439  ;Total Train correct: 460  ;Train loss: 21.21847962588072\nTotal Validation correct: 76  ;Validation Loss: 12.893683314323425\n\n\nEpoch 440  ;Total Train correct: 461  ;Train loss: 21.109792929142714\nTotal Validation correct: 76  ;Validation Loss: 12.876348719000816\n\n\nEpoch 441  ;Total Train correct: 461  ;Train loss: 21.1091446056962\nTotal Validation correct: 76  ;Validation Loss: 12.882257357239723\n\n\nEpoch 442  ;Total Train correct: 462  ;Train loss: 21.044612288475037\nTotal Validation correct: 76  ;Validation Loss: 12.89738716185093\n\n\nEpoch 443  ;Total Train correct: 463  ;Train loss: 21.003107640892267\nTotal Validation correct: 76  ;Validation Loss: 12.864736467599869\n\n\nEpoch 444  ;Total Train correct: 462  ;Train loss: 21.030378103256226\nTotal Validation correct: 76  ;Validation Loss: 12.867491483688354\n\n\nEpoch 445  ;Total Train correct: 462  ;Train loss: 21.005184173583984\nTotal Validation correct: 76  ;Validation Loss: 12.87288023531437\n\n\nEpoch 446  ;Total Train correct: 463  ;Train loss: 20.98432068526745\nTotal Validation correct: 76  ;Validation Loss: 12.851752921938896\nValidation loss decreased (12.862420 --> 12.851753).  Saving model ...\n\n\nEpoch 447  ;Total Train correct: 463  ;Train loss: 21.006824478507042\nTotal Validation correct: 76  ;Validation Loss: 12.851193279027939\nValidation loss decreased (12.851753 --> 12.851193).  Saving model ...\n\n\nEpoch 448  ;Total Train correct: 463  ;Train loss: 21.032449666410685\nTotal Validation correct: 76  ;Validation Loss: 12.870007902383804\n\n\nEpoch 449  ;Total Train correct: 463  ;Train loss: 20.95403452962637\nTotal Validation correct: 76  ;Validation Loss: 12.842177525162697\nValidation loss decreased (12.851193 --> 12.842178).  Saving model ...\n\n\nEpoch 450  ;Total Train correct: 463  ;Train loss: 20.926954731345177\nTotal Validation correct: 76  ;Validation Loss: 12.85841192305088\n\n\nEpoch 451  ;Total Train correct: 463  ;Train loss: 20.91305658966303\nTotal Validation correct: 76  ;Validation Loss: 12.841903299093246\nValidation loss decreased (12.842178 --> 12.841903).  Saving model ...\n\n\nEpoch 452  ;Total Train correct: 463  ;Train loss: 20.9199158847332\nTotal Validation correct: 76  ;Validation Loss: 12.863564819097519\n\n\nEpoch 453  ;Total Train correct: 463  ;Train loss: 20.91541288048029\nTotal Validation correct: 76  ;Validation Loss: 12.852645993232727\n\n\nEpoch 454  ;Total Train correct: 463  ;Train loss: 20.913858857005835\nTotal Validation correct: 76  ;Validation Loss: 12.824021086096764\nValidation loss decreased (12.841903 --> 12.824021).  Saving model ...\n\n\nEpoch 455  ;Total Train correct: 463  ;Train loss: 20.880068611353636\nTotal Validation correct: 76  ;Validation Loss: 12.831992775201797\n\n\nEpoch 456  ;Total Train correct: 463  ;Train loss: 20.894826285541058\nTotal Validation correct: 76  ;Validation Loss: 12.833386480808258\n\n\nEpoch 457  ;Total Train correct: 463  ;Train loss: 20.85024692490697\nTotal Validation correct: 76  ;Validation Loss: 12.81224139034748\nValidation loss decreased (12.824021 --> 12.812241).  Saving model ...\n\n\nEpoch 458  ;Total Train correct: 463  ;Train loss: 20.886276073753834\nTotal Validation correct: 76  ;Validation Loss: 12.80643017590046\nValidation loss decreased (12.812241 --> 12.806430).  Saving model ...\n\n\nEpoch 459  ;Total Train correct: 463  ;Train loss: 20.86232490092516\nTotal Validation correct: 76  ;Validation Loss: 12.817265376448631\n\n\nEpoch 460  ;Total Train correct: 463  ;Train loss: 20.807793773710728\nTotal Validation correct: 76  ;Validation Loss: 12.813425183296204\n\n\nEpoch 461  ;Total Train correct: 463  ;Train loss: 20.815489269793034\nTotal Validation correct: 77  ;Validation Loss: 12.786940231919289\nValidation loss decreased (12.806430 --> 12.786940).  Saving model ...\n\n\nEpoch 462  ;Total Train correct: 463  ;Train loss: 20.796120207756758\nTotal Validation correct: 77  ;Validation Loss: 12.764159306883812\nValidation loss decreased (12.786940 --> 12.764159).  Saving model ...\n\n\nEpoch 463  ;Total Train correct: 463  ;Train loss: 20.81012426316738\nTotal Validation correct: 77  ;Validation Loss: 12.824948027729988\n\n\nEpoch 464  ;Total Train correct: 463  ;Train loss: 20.80410796403885\nTotal Validation correct: 77  ;Validation Loss: 12.797996252775192\n\n\nEpoch 465  ;Total Train correct: 463  ;Train loss: 20.80508365109563\nTotal Validation correct: 77  ;Validation Loss: 12.725227802991867\nValidation loss decreased (12.764159 --> 12.725228).  Saving model ...\n\n\nEpoch 466  ;Total Train correct: 463  ;Train loss: 20.78842380270362\nTotal Validation correct: 77  ;Validation Loss: 12.763000264763832\n\n\nEpoch 467  ;Total Train correct: 463  ;Train loss: 20.811298619955778\nTotal Validation correct: 77  ;Validation Loss: 12.7240529358387\nValidation loss decreased (12.725228 --> 12.724053).  Saving model ...\n\n\nEpoch 468  ;Total Train correct: 463  ;Train loss: 20.769271548837423\nTotal Validation correct: 77  ;Validation Loss: 12.713172793388367\nValidation loss decreased (12.724053 --> 12.713173).  Saving model ...\n\n\nEpoch 469  ;Total Train correct: 463  ;Train loss: 20.74230021238327\nTotal Validation correct: 77  ;Validation Loss: 12.720913887023926\n\n\nEpoch 470  ;Total Train correct: 463  ;Train loss: 20.683014687150717\nTotal Validation correct: 77  ;Validation Loss: 12.704446345567703\nValidation loss decreased (12.713173 --> 12.704446).  Saving model ...\n\n\nEpoch 471  ;Total Train correct: 463  ;Train loss: 20.70615517348051\nTotal Validation correct: 77  ;Validation Loss: 12.693657651543617\nValidation loss decreased (12.704446 --> 12.693658).  Saving model ...\n\n\nEpoch 472  ;Total Train correct: 463  ;Train loss: 20.65058932453394\nTotal Validation correct: 77  ;Validation Loss: 12.730668187141418\n\n\nEpoch 473  ;Total Train correct: 463  ;Train loss: 20.628983419388533\nTotal Validation correct: 77  ;Validation Loss: 12.671950355172157\nValidation loss decreased (12.693658 --> 12.671950).  Saving model ...\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 474  ;Total Train correct: 463  ;Train loss: 20.6249389834702\nTotal Validation correct: 77  ;Validation Loss: 12.679026931524277\n\n\nEpoch 475  ;Total Train correct: 463  ;Train loss: 20.651571854948997\nTotal Validation correct: 77  ;Validation Loss: 12.698907986283302\n\n\nEpoch 476  ;Total Train correct: 463  ;Train loss: 20.596707094460726\nTotal Validation correct: 77  ;Validation Loss: 12.65109270811081\nValidation loss decreased (12.671950 --> 12.651093).  Saving model ...\n\n\nEpoch 477  ;Total Train correct: 463  ;Train loss: 20.54172983393073\nTotal Validation correct: 77  ;Validation Loss: 12.658842906355858\n\n\nEpoch 478  ;Total Train correct: 463  ;Train loss: 20.541330199688673\nTotal Validation correct: 77  ;Validation Loss: 12.663314625620842\n\n\nEpoch 479  ;Total Train correct: 463  ;Train loss: 20.535925928503275\nTotal Validation correct: 77  ;Validation Loss: 12.636309251189232\nValidation loss decreased (12.651093 --> 12.636309).  Saving model ...\n\n\nEpoch 480  ;Total Train correct: 463  ;Train loss: 20.5339141972363\nTotal Validation correct: 77  ;Validation Loss: 12.6367856413126\n\n\nEpoch 481  ;Total Train correct: 464  ;Train loss: 20.4894693903625\nTotal Validation correct: 77  ;Validation Loss: 12.628615111112595\nValidation loss decreased (12.636309 --> 12.628615).  Saving model ...\n\n\nEpoch 482  ;Total Train correct: 464  ;Train loss: 20.489613622426987\nTotal Validation correct: 77  ;Validation Loss: 12.62072941660881\nValidation loss decreased (12.628615 --> 12.620729).  Saving model ...\n\n\nEpoch 483  ;Total Train correct: 463  ;Train loss: 20.463935919106007\nTotal Validation correct: 77  ;Validation Loss: 12.615075886249542\nValidation loss decreased (12.620729 --> 12.615076).  Saving model ...\n\n\nEpoch 484  ;Total Train correct: 463  ;Train loss: 20.458917565643787\nTotal Validation correct: 77  ;Validation Loss: 12.611754521727562\nValidation loss decreased (12.615076 --> 12.611755).  Saving model ...\n\n\nEpoch 485  ;Total Train correct: 463  ;Train loss: 20.443998277187347\nTotal Validation correct: 77  ;Validation Loss: 12.594675362110138\nValidation loss decreased (12.611755 --> 12.594675).  Saving model ...\n\n\nEpoch 486  ;Total Train correct: 463  ;Train loss: 20.433387618511915\nTotal Validation correct: 77  ;Validation Loss: 12.588503047823906\nValidation loss decreased (12.594675 --> 12.588503).  Saving model ...\n\n\nEpoch 487  ;Total Train correct: 464  ;Train loss: 20.389340445399284\nTotal Validation correct: 77  ;Validation Loss: 12.557726413011551\nValidation loss decreased (12.588503 --> 12.557726).  Saving model ...\n\n\nEpoch 488  ;Total Train correct: 464  ;Train loss: 20.35684522986412\nTotal Validation correct: 77  ;Validation Loss: 12.58597645163536\n\n\nEpoch 489  ;Total Train correct: 463  ;Train loss: 20.336514815688133\nTotal Validation correct: 77  ;Validation Loss: 12.567456468939781\n\n\nEpoch 490  ;Total Train correct: 464  ;Train loss: 20.33042973652482\nTotal Validation correct: 77  ;Validation Loss: 12.543843418359756\nValidation loss decreased (12.557726 --> 12.543843).  Saving model ...\n\n\nEpoch 491  ;Total Train correct: 464  ;Train loss: 20.354473277926445\nTotal Validation correct: 77  ;Validation Loss: 12.54556529223919\n\n\nEpoch 492  ;Total Train correct: 464  ;Train loss: 20.314519576728344\nTotal Validation correct: 77  ;Validation Loss: 12.541392117738724\nValidation loss decreased (12.543843 --> 12.541392).  Saving model ...\n\n\nEpoch 493  ;Total Train correct: 464  ;Train loss: 20.291711326688528\nTotal Validation correct: 77  ;Validation Loss: 12.537495285272598\nValidation loss decreased (12.541392 --> 12.537495).  Saving model ...\n\n\nEpoch 494  ;Total Train correct: 464  ;Train loss: 20.27125358954072\nTotal Validation correct: 77  ;Validation Loss: 12.508509933948517\nValidation loss decreased (12.537495 --> 12.508510).  Saving model ...\n\n\nEpoch 495  ;Total Train correct: 464  ;Train loss: 20.232599426060915\nTotal Validation correct: 77  ;Validation Loss: 12.522783264517784\n\n\nEpoch 496  ;Total Train correct: 464  ;Train loss: 20.18220692127943\nTotal Validation correct: 77  ;Validation Loss: 12.479808554053307\nValidation loss decreased (12.508510 --> 12.479809).  Saving model ...\n\n\nEpoch 497  ;Total Train correct: 464  ;Train loss: 20.17584915831685\nTotal Validation correct: 77  ;Validation Loss: 12.487369433045387\n\n\nEpoch 498  ;Total Train correct: 464  ;Train loss: 20.143412109464407\nTotal Validation correct: 77  ;Validation Loss: 12.470492154359818\nValidation loss decreased (12.479809 --> 12.470492).  Saving model ...\n\n\nEpoch 499  ;Total Train correct: 464  ;Train loss: 20.085787441581488\nTotal Validation correct: 77  ;Validation Loss: 12.466427311301231\nValidation loss decreased (12.470492 --> 12.466427).  Saving model ...\n\n\nEpoch 500  ;Total Train correct: 464  ;Train loss: 20.055156111717224\nTotal Validation correct: 77  ;Validation Loss: 12.453451290726662\nValidation loss decreased (12.466427 --> 12.453451).  Saving model ...\n\n\nEpoch 501  ;Total Train correct: 464  ;Train loss: 20.05048582702875\nTotal Validation correct: 77  ;Validation Loss: 12.475970804691315\n\n\nEpoch 502  ;Total Train correct: 464  ;Train loss: 19.991075798869133\nTotal Validation correct: 77  ;Validation Loss: 12.465242177248001\n\n\nEpoch 503  ;Total Train correct: 464  ;Train loss: 19.970562890172005\nTotal Validation correct: 77  ;Validation Loss: 12.445768505334854\nValidation loss decreased (12.453451 --> 12.445769).  Saving model ...\n\n\nEpoch 504  ;Total Train correct: 465  ;Train loss: 19.956940207630396\nTotal Validation correct: 77  ;Validation Loss: 12.421480044722557\nValidation loss decreased (12.445769 --> 12.421480).  Saving model ...\n\n\nEpoch 505  ;Total Train correct: 464  ;Train loss: 19.943632923066616\nTotal Validation correct: 77  ;Validation Loss: 12.444734454154968\n\n\nEpoch 506  ;Total Train correct: 464  ;Train loss: 19.885845225304365\nTotal Validation correct: 76  ;Validation Loss: 12.447481021285057\n\n\nEpoch 507  ;Total Train correct: 464  ;Train loss: 19.86100160703063\nTotal Validation correct: 77  ;Validation Loss: 12.433153688907623\n\n\nEpoch 508  ;Total Train correct: 465  ;Train loss: 19.820977747440338\nTotal Validation correct: 77  ;Validation Loss: 12.41523340344429\nValidation loss decreased (12.421480 --> 12.415233).  Saving model ...\n\n\nEpoch 509  ;Total Train correct: 465  ;Train loss: 19.826741993427277\nTotal Validation correct: 78  ;Validation Loss: 12.399967774748802\nValidation loss decreased (12.415233 --> 12.399968).  Saving model ...\n\n\nEpoch 510  ;Total Train correct: 466  ;Train loss: 19.7775297164917\nTotal Validation correct: 77  ;Validation Loss: 12.415354698896408\n\n\nEpoch 511  ;Total Train correct: 466  ;Train loss: 19.768528819084167\nTotal Validation correct: 77  ;Validation Loss: 12.386481747031212\nValidation loss decreased (12.399968 --> 12.386482).  Saving model ...\n\n\nEpoch 512  ;Total Train correct: 466  ;Train loss: 19.7297504208982\nTotal Validation correct: 78  ;Validation Loss: 12.359552562236786\nValidation loss decreased (12.386482 --> 12.359553).  Saving model ...\n\n\nEpoch 513  ;Total Train correct: 467  ;Train loss: 19.737943772226572\nTotal Validation correct: 77  ;Validation Loss: 12.376408964395523\n\n\nEpoch 514  ;Total Train correct: 465  ;Train loss: 19.703002747148275\nTotal Validation correct: 76  ;Validation Loss: 12.383654683828354\n\n\nEpoch 515  ;Total Train correct: 467  ;Train loss: 19.649065021425486\nTotal Validation correct: 78  ;Validation Loss: 12.346322298049927\nValidation loss decreased (12.359553 --> 12.346322).  Saving model ...\n\n\nEpoch 516  ;Total Train correct: 466  ;Train loss: 19.6423405893147\nTotal Validation correct: 77  ;Validation Loss: 12.336954697966576\nValidation loss decreased (12.346322 --> 12.336955).  Saving model ...\n\n\nEpoch 517  ;Total Train correct: 469  ;Train loss: 19.601532507687807\nTotal Validation correct: 78  ;Validation Loss: 12.331670209765434\nValidation loss decreased (12.336955 --> 12.331670).  Saving model ...\n\n\nEpoch 518  ;Total Train correct: 469  ;Train loss: 19.595088936388493\nTotal Validation correct: 78  ;Validation Loss: 12.341139495372772\n\n\nEpoch 519  ;Total Train correct: 468  ;Train loss: 19.592266011983156\nTotal Validation correct: 77  ;Validation Loss: 12.321294158697128\nValidation loss decreased (12.331670 --> 12.321294).  Saving model ...\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 520  ;Total Train correct: 466  ;Train loss: 19.577593572437763\nTotal Validation correct: 78  ;Validation Loss: 12.313017189502716\nValidation loss decreased (12.321294 --> 12.313017).  Saving model ...\n\n\nEpoch 521  ;Total Train correct: 467  ;Train loss: 19.547026716172695\nTotal Validation correct: 78  ;Validation Loss: 12.290200099349022\nValidation loss decreased (12.313017 --> 12.290200).  Saving model ...\n\n\nEpoch 522  ;Total Train correct: 468  ;Train loss: 19.538953587412834\nTotal Validation correct: 77  ;Validation Loss: 12.306858316063881\n\n\nEpoch 523  ;Total Train correct: 468  ;Train loss: 19.51180137693882\nTotal Validation correct: 77  ;Validation Loss: 12.314469575881958\n\n\nEpoch 524  ;Total Train correct: 468  ;Train loss: 19.534829795360565\nTotal Validation correct: 78  ;Validation Loss: 12.267347902059555\nValidation loss decreased (12.290200 --> 12.267348).  Saving model ...\n\n\nEpoch 525  ;Total Train correct: 468  ;Train loss: 19.458210736513138\nTotal Validation correct: 76  ;Validation Loss: 12.3067597001791\n\n\nEpoch 526  ;Total Train correct: 470  ;Train loss: 19.454456228762865\nTotal Validation correct: 77  ;Validation Loss: 12.273971572518349\n\n\nEpoch 527  ;Total Train correct: 470  ;Train loss: 19.43715452775359\nTotal Validation correct: 77  ;Validation Loss: 12.275571465492249\n\n\nEpoch 528  ;Total Train correct: 469  ;Train loss: 19.40416808053851\nTotal Validation correct: 77  ;Validation Loss: 12.239589482545853\nValidation loss decreased (12.267348 --> 12.239589).  Saving model ...\n\n\nEpoch 529  ;Total Train correct: 469  ;Train loss: 19.376692797988653\nTotal Validation correct: 78  ;Validation Loss: 12.226896420121193\nValidation loss decreased (12.239589 --> 12.226896).  Saving model ...\n\n\nEpoch 530  ;Total Train correct: 470  ;Train loss: 19.37021342292428\nTotal Validation correct: 77  ;Validation Loss: 12.268159717321396\n\n\nEpoch 531  ;Total Train correct: 470  ;Train loss: 19.34785197302699\nTotal Validation correct: 77  ;Validation Loss: 12.231136232614517\n\n\nEpoch 532  ;Total Train correct: 469  ;Train loss: 19.28403988108039\nTotal Validation correct: 77  ;Validation Loss: 12.21221736073494\nValidation loss decreased (12.226896 --> 12.212217).  Saving model ...\n\n\nEpoch 533  ;Total Train correct: 470  ;Train loss: 19.256195340305567\nTotal Validation correct: 77  ;Validation Loss: 12.224749833345413\n\n\nEpoch 534  ;Total Train correct: 470  ;Train loss: 19.27146888896823\nTotal Validation correct: 77  ;Validation Loss: 12.206967651844025\nValidation loss decreased (12.212217 --> 12.206968).  Saving model ...\n\n\nEpoch 535  ;Total Train correct: 470  ;Train loss: 19.189867537468672\nTotal Validation correct: 77  ;Validation Loss: 12.199587523937225\nValidation loss decreased (12.206968 --> 12.199588).  Saving model ...\n\n\nEpoch 536  ;Total Train correct: 470  ;Train loss: 19.140225008130074\nTotal Validation correct: 77  ;Validation Loss: 12.164795994758606\nValidation loss decreased (12.199588 --> 12.164796).  Saving model ...\n\n\nEpoch 537  ;Total Train correct: 470  ;Train loss: 19.13426261767745\nTotal Validation correct: 77  ;Validation Loss: 12.18804968893528\n\n\nEpoch 538  ;Total Train correct: 470  ;Train loss: 19.066546097397804\nTotal Validation correct: 77  ;Validation Loss: 12.136856094002724\nValidation loss decreased (12.164796 --> 12.136856).  Saving model ...\n\n\nEpoch 539  ;Total Train correct: 471  ;Train loss: 19.03497999534011\nTotal Validation correct: 77  ;Validation Loss: 12.15290005505085\n\n\nEpoch 540  ;Total Train correct: 469  ;Train loss: 19.03138380497694\nTotal Validation correct: 77  ;Validation Loss: 12.158270627260208\n\n\nEpoch 541  ;Total Train correct: 470  ;Train loss: 19.034224539995193\nTotal Validation correct: 77  ;Validation Loss: 12.123320132493973\nValidation loss decreased (12.136856 --> 12.123320).  Saving model ...\n\n\nEpoch 542  ;Total Train correct: 471  ;Train loss: 18.97880867496133\nTotal Validation correct: 78  ;Validation Loss: 12.125556141138077\n\n\nEpoch 543  ;Total Train correct: 471  ;Train loss: 18.994344238191843\nTotal Validation correct: 77  ;Validation Loss: 12.091241911053658\nValidation loss decreased (12.123320 --> 12.091242).  Saving model ...\n\n\nEpoch 544  ;Total Train correct: 471  ;Train loss: 18.95462579652667\nTotal Validation correct: 78  ;Validation Loss: 12.095260083675385\n\n\nEpoch 545  ;Total Train correct: 472  ;Train loss: 18.914630442857742\nTotal Validation correct: 78  ;Validation Loss: 12.118777841329575\n\n\nEpoch 546  ;Total Train correct: 471  ;Train loss: 18.870577983558178\nTotal Validation correct: 78  ;Validation Loss: 12.092886179685593\n\n\nEpoch 547  ;Total Train correct: 472  ;Train loss: 18.828172743320465\nTotal Validation correct: 78  ;Validation Loss: 12.06591972708702\nValidation loss decreased (12.091242 --> 12.065920).  Saving model ...\n\n\nEpoch 548  ;Total Train correct: 472  ;Train loss: 18.80805889889598\nTotal Validation correct: 78  ;Validation Loss: 12.066450044512749\n\n\nEpoch 549  ;Total Train correct: 472  ;Train loss: 18.803067348897457\nTotal Validation correct: 78  ;Validation Loss: 12.044359907507896\nValidation loss decreased (12.065920 --> 12.044360).  Saving model ...\n\n\nEpoch 550  ;Total Train correct: 472  ;Train loss: 18.777348216623068\nTotal Validation correct: 78  ;Validation Loss: 12.066660553216934\n\n\nEpoch 551  ;Total Train correct: 472  ;Train loss: 18.723363664001226\nTotal Validation correct: 78  ;Validation Loss: 12.03610135614872\nValidation loss decreased (12.044360 --> 12.036101).  Saving model ...\n\n\nEpoch 552  ;Total Train correct: 473  ;Train loss: 18.661096911877394\nTotal Validation correct: 78  ;Validation Loss: 12.009709820151329\nValidation loss decreased (12.036101 --> 12.009710).  Saving model ...\n\n\nEpoch 553  ;Total Train correct: 473  ;Train loss: 18.644647300243378\nTotal Validation correct: 78  ;Validation Loss: 12.016383036971092\n\n\nEpoch 554  ;Total Train correct: 473  ;Train loss: 18.63516742736101\nTotal Validation correct: 77  ;Validation Loss: 11.949848651885986\nValidation loss decreased (12.009710 --> 11.949849).  Saving model ...\n\n\nEpoch 555  ;Total Train correct: 473  ;Train loss: 18.578683950006962\nTotal Validation correct: 77  ;Validation Loss: 11.976836189627647\n\n\nEpoch 556  ;Total Train correct: 474  ;Train loss: 18.496995478868484\nTotal Validation correct: 77  ;Validation Loss: 11.926483020186424\nValidation loss decreased (11.949849 --> 11.926483).  Saving model ...\n\n\nEpoch 557  ;Total Train correct: 474  ;Train loss: 18.47664410993457\nTotal Validation correct: 78  ;Validation Loss: 11.920109078288078\nValidation loss decreased (11.926483 --> 11.920109).  Saving model ...\n\n\nEpoch 558  ;Total Train correct: 474  ;Train loss: 18.372637003660202\nTotal Validation correct: 78  ;Validation Loss: 11.961616411805153\n\n\nEpoch 559  ;Total Train correct: 474  ;Train loss: 18.38973553851247\nTotal Validation correct: 77  ;Validation Loss: 11.897750571370125\nValidation loss decreased (11.920109 --> 11.897751).  Saving model ...\n\n\nEpoch 560  ;Total Train correct: 474  ;Train loss: 18.30292934924364\nTotal Validation correct: 77  ;Validation Loss: 11.932204008102417\n\n\nEpoch 561  ;Total Train correct: 474  ;Train loss: 18.292386934161186\nTotal Validation correct: 77  ;Validation Loss: 11.892299965023994\nValidation loss decreased (11.897751 --> 11.892300).  Saving model ...\n\n\nEpoch 562  ;Total Train correct: 474  ;Train loss: 18.309689469635487\nTotal Validation correct: 77  ;Validation Loss: 11.926206156611443\n\n\nEpoch 563  ;Total Train correct: 475  ;Train loss: 18.196175053715706\nTotal Validation correct: 77  ;Validation Loss: 11.853317633271217\nValidation loss decreased (11.892300 --> 11.853318).  Saving model ...\n\n\nEpoch 564  ;Total Train correct: 474  ;Train loss: 18.18263177201152\nTotal Validation correct: 77  ;Validation Loss: 11.904812440276146\n\n\nEpoch 565  ;Total Train correct: 475  ;Train loss: 18.179404690861702\nTotal Validation correct: 77  ;Validation Loss: 11.856330141425133\n\n\nEpoch 566  ;Total Train correct: 476  ;Train loss: 18.15079004690051\nTotal Validation correct: 78  ;Validation Loss: 11.870496109127998\n\n\nEpoch 567  ;Total Train correct: 475  ;Train loss: 18.105287540704012\nTotal Validation correct: 77  ;Validation Loss: 11.836336001753807\nValidation loss decreased (11.853318 --> 11.836336).  Saving model ...\n","name":"stdout"},{"output_type":"stream","text":"\n\nEpoch 568  ;Total Train correct: 476  ;Train loss: 18.060626905411482\nTotal Validation correct: 77  ;Validation Loss: 11.86959981918335\n\n\nEpoch 569  ;Total Train correct: 475  ;Train loss: 18.00182955339551\nTotal Validation correct: 77  ;Validation Loss: 11.815662905573845\nValidation loss decreased (11.836336 --> 11.815663).  Saving model ...\n\n\nEpoch 570  ;Total Train correct: 477  ;Train loss: 18.02285735681653\nTotal Validation correct: 77  ;Validation Loss: 11.807664170861244\nValidation loss decreased (11.815663 --> 11.807664).  Saving model ...\n\n\nEpoch 571  ;Total Train correct: 476  ;Train loss: 17.946281779557467\nTotal Validation correct: 77  ;Validation Loss: 11.805589064955711\nValidation loss decreased (11.807664 --> 11.805589).  Saving model ...\n\n\nEpoch 572  ;Total Train correct: 476  ;Train loss: 17.914056833833456\nTotal Validation correct: 77  ;Validation Loss: 11.776795506477356\nValidation loss decreased (11.805589 --> 11.776796).  Saving model ...\n\n\nEpoch 573  ;Total Train correct: 476  ;Train loss: 17.90530565753579\nTotal Validation correct: 77  ;Validation Loss: 11.777159661054611\n\n\nEpoch 574  ;Total Train correct: 476  ;Train loss: 17.897739488631487\nTotal Validation correct: 77  ;Validation Loss: 11.711302429437637\nValidation loss decreased (11.776796 --> 11.711302).  Saving model ...\n\n\nEpoch 575  ;Total Train correct: 476  ;Train loss: 17.873575273901224\nTotal Validation correct: 77  ;Validation Loss: 11.794997096061707\n\n\nEpoch 576  ;Total Train correct: 476  ;Train loss: 17.772514782845974\nTotal Validation correct: 77  ;Validation Loss: 11.760139681398869\n\n\nEpoch 577  ;Total Train correct: 477  ;Train loss: 17.76878636330366\nTotal Validation correct: 77  ;Validation Loss: 11.724140167236328\n\n\nEpoch 578  ;Total Train correct: 476  ;Train loss: 17.729520186781883\nTotal Validation correct: 77  ;Validation Loss: 11.73351189494133\n\n\nEpoch 579  ;Total Train correct: 476  ;Train loss: 17.756829764693975\nTotal Validation correct: 77  ;Validation Loss: 11.681414291262627\nValidation loss decreased (11.711302 --> 11.681414).  Saving model ...\n\n\nEpoch 580  ;Total Train correct: 476  ;Train loss: 17.69169982150197\nTotal Validation correct: 77  ;Validation Loss: 11.710690662264824\n\n\nEpoch 581  ;Total Train correct: 478  ;Train loss: 17.703982826322317\nTotal Validation correct: 78  ;Validation Loss: 11.619700536131859\nValidation loss decreased (11.681414 --> 11.619701).  Saving model ...\n\n\nEpoch 582  ;Total Train correct: 477  ;Train loss: 17.669547729194164\nTotal Validation correct: 77  ;Validation Loss: 11.693051189184189\n\n\nEpoch 583  ;Total Train correct: 479  ;Train loss: 17.639936175197363\nTotal Validation correct: 78  ;Validation Loss: 11.67355016618967\n\n\nEpoch 584  ;Total Train correct: 478  ;Train loss: 17.61860080435872\nTotal Validation correct: 78  ;Validation Loss: 11.633857481181622\n\n\nEpoch 585  ;Total Train correct: 479  ;Train loss: 17.57540798559785\nTotal Validation correct: 78  ;Validation Loss: 11.644783154129982\n\n\nEpoch 586  ;Total Train correct: 479  ;Train loss: 17.551125049591064\nTotal Validation correct: 78  ;Validation Loss: 11.622674562036991\n\n\nEpoch 587  ;Total Train correct: 480  ;Train loss: 17.544203851372004\nTotal Validation correct: 78  ;Validation Loss: 11.626321196556091\n\n\nEpoch 588  ;Total Train correct: 479  ;Train loss: 17.505756981670856\nTotal Validation correct: 79  ;Validation Loss: 11.562387153506279\nValidation loss decreased (11.619701 --> 11.562387).  Saving model ...\n\n\nEpoch 589  ;Total Train correct: 479  ;Train loss: 17.494793992489576\nTotal Validation correct: 78  ;Validation Loss: 11.609351009130478\n\n\nEpoch 590  ;Total Train correct: 479  ;Train loss: 17.4625260271132\nTotal Validation correct: 78  ;Validation Loss: 11.594118542969227\n\n\nEpoch 591  ;Total Train correct: 480  ;Train loss: 17.40507085993886\nTotal Validation correct: 79  ;Validation Loss: 11.542473189532757\nValidation loss decreased (11.562387 --> 11.542473).  Saving model ...\n\n\nEpoch 592  ;Total Train correct: 479  ;Train loss: 17.379524275660515\nTotal Validation correct: 79  ;Validation Loss: 11.515264958143234\nValidation loss decreased (11.542473 --> 11.515265).  Saving model ...\n\n\nEpoch 593  ;Total Train correct: 479  ;Train loss: 17.383590817451477\nTotal Validation correct: 79  ;Validation Loss: 11.53625151515007\n\n\nEpoch 594  ;Total Train correct: 481  ;Train loss: 17.340607274323702\nTotal Validation correct: 79  ;Validation Loss: 11.535144247114658\n\n\nEpoch 595  ;Total Train correct: 481  ;Train loss: 17.312410444021225\nTotal Validation correct: 79  ;Validation Loss: 11.510692611336708\nValidation loss decreased (11.515265 --> 11.510693).  Saving model ...\n\n\nEpoch 596  ;Total Train correct: 482  ;Train loss: 17.297491908073425\nTotal Validation correct: 79  ;Validation Loss: 11.517388880252838\n\n\nEpoch 597  ;Total Train correct: 482  ;Train loss: 17.30882463976741\nTotal Validation correct: 79  ;Validation Loss: 11.474030673503876\nValidation loss decreased (11.510693 --> 11.474031).  Saving model ...\n\n\nEpoch 598  ;Total Train correct: 480  ;Train loss: 17.274519007652998\nTotal Validation correct: 79  ;Validation Loss: 11.498879425227642\n\n\nEpoch 599  ;Total Train correct: 481  ;Train loss: 17.218721948564053\nTotal Validation correct: 79  ;Validation Loss: 11.461901411414146\nValidation loss decreased (11.474031 --> 11.461901).  Saving model ...\n\n\nEpoch 600  ;Total Train correct: 481  ;Train loss: 17.232185412198305\nTotal Validation correct: 79  ;Validation Loss: 11.438854150474072\nValidation loss decreased (11.461901 --> 11.438854).  Saving model ...\n\n\nEpoch 601  ;Total Train correct: 482  ;Train loss: 17.155106533318758\nTotal Validation correct: 79  ;Validation Loss: 11.434806399047375\nValidation loss decreased (11.438854 --> 11.434806).  Saving model ...\n\n\nEpoch 602  ;Total Train correct: 480  ;Train loss: 17.187415298074484\nTotal Validation correct: 79  ;Validation Loss: 11.413788549602032\nValidation loss decreased (11.434806 --> 11.413789).  Saving model ...\n\n\nEpoch 603  ;Total Train correct: 481  ;Train loss: 17.17568802088499\nTotal Validation correct: 79  ;Validation Loss: 11.39551504701376\nValidation loss decreased (11.413789 --> 11.395515).  Saving model ...\n\n\nEpoch 604  ;Total Train correct: 482  ;Train loss: 17.17440326884389\nTotal Validation correct: 79  ;Validation Loss: 11.396302223205566\n\n\nEpoch 605  ;Total Train correct: 482  ;Train loss: 17.15027814731002\nTotal Validation correct: 79  ;Validation Loss: 11.397442996501923\n\n\nEpoch 606  ;Total Train correct: 482  ;Train loss: 17.13894421234727\nTotal Validation correct: 79  ;Validation Loss: 11.39612703025341\n\n\nEpoch 607  ;Total Train correct: 482  ;Train loss: 17.128823086619377\nTotal Validation correct: 79  ;Validation Loss: 11.339354902505875\nValidation loss decreased (11.395515 --> 11.339355).  Saving model ...\n\n\nEpoch 608  ;Total Train correct: 482  ;Train loss: 17.107597921043634\nTotal Validation correct: 79  ;Validation Loss: 11.37950300425291\n\n\nEpoch 609  ;Total Train correct: 482  ;Train loss: 17.115183502435684\nTotal Validation correct: 79  ;Validation Loss: 11.37350395321846\n\n\nEpoch 610  ;Total Train correct: 481  ;Train loss: 17.10211031511426\nTotal Validation correct: 79  ;Validation Loss: 11.2993453592062\nValidation loss decreased (11.339355 --> 11.299345).  Saving model ...\n\n\nEpoch 611  ;Total Train correct: 482  ;Train loss: 17.068229384720325\nTotal Validation correct: 79  ;Validation Loss: 11.331987962126732\n\n\nEpoch 612  ;Total Train correct: 482  ;Train loss: 17.026581846177578\nTotal Validation correct: 79  ;Validation Loss: 11.345666155219078\n\n\nEpoch 613  ;Total Train correct: 482  ;Train loss: 17.016839791089296\nTotal Validation correct: 79  ;Validation Loss: 11.272536545991898\nValidation loss decreased (11.299345 --> 11.272537).  Saving model ...\n\n\nEpoch 614  ;Total Train correct: 483  ;Train loss: 16.968951378017664\nTotal Validation correct: 79  ;Validation Loss: 11.31005696207285\n\n\nEpoch 615  ;Total Train correct: 482  ;Train loss: 16.98074299097061\nTotal Validation correct: 79  ;Validation Loss: 11.321362353861332\n\n\nEpoch 616  ;Total Train correct: 483  ;Train loss: 16.952463652938604\nTotal Validation correct: 79  ;Validation Loss: 11.189428098499775\nValidation loss decreased (11.272537 --> 11.189428).  Saving model ...\n\n\nEpoch 617  ;Total Train correct: 482  ;Train loss: 16.92733597755432\nTotal Validation correct: 79  ;Validation Loss: 11.296155631542206\n\n\nEpoch 618  ;Total Train correct: 482  ;Train loss: 16.92276404798031\nTotal Validation correct: 79  ;Validation Loss: 11.274714171886444\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 619  ;Total Train correct: 483  ;Train loss: 16.816946487873793\nTotal Validation correct: 79  ;Validation Loss: 11.20363099873066\n\n\nEpoch 620  ;Total Train correct: 484  ;Train loss: 16.85091580823064\nTotal Validation correct: 79  ;Validation Loss: 11.247025169432163\n\n\nEpoch 621  ;Total Train correct: 484  ;Train loss: 16.83951484784484\nTotal Validation correct: 79  ;Validation Loss: 11.211079619824886\n\n\nEpoch 622  ;Total Train correct: 484  ;Train loss: 16.781423926353455\nTotal Validation correct: 79  ;Validation Loss: 11.21999379992485\n\n\nEpoch 623  ;Total Train correct: 485  ;Train loss: 16.75200642645359\nTotal Validation correct: 79  ;Validation Loss: 11.247699774801731\n\n\nEpoch 624  ;Total Train correct: 485  ;Train loss: 16.70618410035968\nTotal Validation correct: 79  ;Validation Loss: 11.213664755225182\n\n\nEpoch 625  ;Total Train correct: 484  ;Train loss: 16.70968982577324\nTotal Validation correct: 79  ;Validation Loss: 11.187239535152912\nValidation loss decreased (11.189428 --> 11.187240).  Saving model ...\n\n\nEpoch 626  ;Total Train correct: 485  ;Train loss: 16.657534522935748\nTotal Validation correct: 79  ;Validation Loss: 11.154960326850414\nValidation loss decreased (11.187240 --> 11.154960).  Saving model ...\n\n\nEpoch 627  ;Total Train correct: 485  ;Train loss: 16.597511488944292\nTotal Validation correct: 79  ;Validation Loss: 11.16407461464405\n\n\nEpoch 628  ;Total Train correct: 485  ;Train loss: 16.641127672046423\nTotal Validation correct: 81  ;Validation Loss: 11.036301739513874\nValidation loss decreased (11.154960 --> 11.036302).  Saving model ...\n\n\nEpoch 629  ;Total Train correct: 486  ;Train loss: 16.600465511903167\nTotal Validation correct: 80  ;Validation Loss: 11.166543900966644\n\n\nEpoch 630  ;Total Train correct: 486  ;Train loss: 16.600624138489366\nTotal Validation correct: 79  ;Validation Loss: 11.153318382799625\n\n\nEpoch 631  ;Total Train correct: 485  ;Train loss: 16.603947166353464\nTotal Validation correct: 80  ;Validation Loss: 11.053557924926281\n\n\nEpoch 632  ;Total Train correct: 486  ;Train loss: 16.522134805098176\nTotal Validation correct: 79  ;Validation Loss: 11.134390078485012\n\n\nEpoch 633  ;Total Train correct: 486  ;Train loss: 16.52614733017981\nTotal Validation correct: 80  ;Validation Loss: 11.112961672246456\n\n\nEpoch 634  ;Total Train correct: 486  ;Train loss: 16.50614859163761\nTotal Validation correct: 79  ;Validation Loss: 11.111014574766159\n\n\nEpoch 635  ;Total Train correct: 486  ;Train loss: 16.49687237292528\nTotal Validation correct: 80  ;Validation Loss: 11.08510423451662\n\n\nEpoch 636  ;Total Train correct: 486  ;Train loss: 16.445097154006362\nTotal Validation correct: 81  ;Validation Loss: 11.040404237806797\n\n\nEpoch 637  ;Total Train correct: 485  ;Train loss: 16.49248567223549\nTotal Validation correct: 81  ;Validation Loss: 11.017730847001076\nValidation loss decreased (11.036302 --> 11.017731).  Saving model ...\n\n\nEpoch 638  ;Total Train correct: 485  ;Train loss: 16.360756751149893\nTotal Validation correct: 81  ;Validation Loss: 11.053078703582287\n\n\nEpoch 639  ;Total Train correct: 486  ;Train loss: 16.384154848754406\nTotal Validation correct: 81  ;Validation Loss: 11.048292152583599\n\n\nEpoch 640  ;Total Train correct: 485  ;Train loss: 16.389684757217765\nTotal Validation correct: 80  ;Validation Loss: 11.050876706838608\n\n\nEpoch 641  ;Total Train correct: 485  ;Train loss: 16.361557194963098\nTotal Validation correct: 81  ;Validation Loss: 10.984253644943237\nValidation loss decreased (11.017731 --> 10.984254).  Saving model ...\n\n\nEpoch 642  ;Total Train correct: 485  ;Train loss: 16.37553145363927\nTotal Validation correct: 80  ;Validation Loss: 11.041018053889275\n\n\nEpoch 643  ;Total Train correct: 486  ;Train loss: 16.292696479707956\nTotal Validation correct: 80  ;Validation Loss: 10.997795335948467\n\n\nEpoch 644  ;Total Train correct: 485  ;Train loss: 16.340149752795696\nTotal Validation correct: 81  ;Validation Loss: 10.886528976261616\nValidation loss decreased (10.984254 --> 10.886529).  Saving model ...\n\n\nEpoch 645  ;Total Train correct: 486  ;Train loss: 16.331077840179205\nTotal Validation correct: 81  ;Validation Loss: 10.98861014842987\n\n\nEpoch 646  ;Total Train correct: 487  ;Train loss: 16.25916403159499\nTotal Validation correct: 81  ;Validation Loss: 10.924675710499287\n\n\nEpoch 647  ;Total Train correct: 487  ;Train loss: 16.2442996352911\nTotal Validation correct: 81  ;Validation Loss: 10.954187504947186\n\n\nEpoch 648  ;Total Train correct: 487  ;Train loss: 16.19569238834083\nTotal Validation correct: 81  ;Validation Loss: 10.921882048249245\n\n\nEpoch 649  ;Total Train correct: 487  ;Train loss: 16.172963561490178\nTotal Validation correct: 81  ;Validation Loss: 10.923347145318985\n\n\nEpoch 650  ;Total Train correct: 487  ;Train loss: 16.194805063307285\nTotal Validation correct: 81  ;Validation Loss: 10.823953032493591\nValidation loss decreased (10.886529 --> 10.823953).  Saving model ...\n\n\nEpoch 651  ;Total Train correct: 487  ;Train loss: 16.124813640490174\nTotal Validation correct: 82  ;Validation Loss: 10.906283669173717\n\n\nEpoch 652  ;Total Train correct: 486  ;Train loss: 16.137770503759384\nTotal Validation correct: 81  ;Validation Loss: 10.877387285232544\n\n\nEpoch 653  ;Total Train correct: 487  ;Train loss: 16.097014097496867\nTotal Validation correct: 81  ;Validation Loss: 10.814640410244465\nValidation loss decreased (10.823953 --> 10.814640).  Saving model ...\n\n\nEpoch 654  ;Total Train correct: 486  ;Train loss: 16.120494147762656\nTotal Validation correct: 80  ;Validation Loss: 10.878679990768433\n\n\nEpoch 655  ;Total Train correct: 487  ;Train loss: 16.070628955960274\nTotal Validation correct: 80  ;Validation Loss: 10.870726846158504\n\n\nEpoch 656  ;Total Train correct: 486  ;Train loss: 16.082639127969742\nTotal Validation correct: 80  ;Validation Loss: 10.844911083579063\n\n\nEpoch 657  ;Total Train correct: 486  ;Train loss: 16.064837772399187\nTotal Validation correct: 80  ;Validation Loss: 10.858011469244957\n\n\nEpoch 658  ;Total Train correct: 485  ;Train loss: 16.04138578288257\nTotal Validation correct: 80  ;Validation Loss: 10.805485934019089\nValidation loss decreased (10.814640 --> 10.805486).  Saving model ...\n\n\nEpoch 659  ;Total Train correct: 486  ;Train loss: 16.017508625984192\nTotal Validation correct: 80  ;Validation Loss: 10.832446932792664\n\n\nEpoch 660  ;Total Train correct: 487  ;Train loss: 15.919876025989652\nTotal Validation correct: 80  ;Validation Loss: 10.797400370240211\nValidation loss decreased (10.805486 --> 10.797400).  Saving model ...\n\n\nEpoch 661  ;Total Train correct: 486  ;Train loss: 15.929964311420918\nTotal Validation correct: 80  ;Validation Loss: 10.852234840393066\n\n\nEpoch 662  ;Total Train correct: 487  ;Train loss: 15.9061034694314\nTotal Validation correct: 82  ;Validation Loss: 10.826547309756279\n\n\nEpoch 663  ;Total Train correct: 486  ;Train loss: 15.819437824189663\nTotal Validation correct: 82  ;Validation Loss: 10.735611602663994\nValidation loss decreased (10.797400 --> 10.735612).  Saving model ...\n\n\nEpoch 664  ;Total Train correct: 487  ;Train loss: 15.81980486959219\nTotal Validation correct: 81  ;Validation Loss: 10.803449645638466\n\n\nEpoch 665  ;Total Train correct: 488  ;Train loss: 15.772671462967992\nTotal Validation correct: 82  ;Validation Loss: 10.758818298578262\n\n\nEpoch 666  ;Total Train correct: 488  ;Train loss: 15.76130672171712\nTotal Validation correct: 81  ;Validation Loss: 10.767861150205135\n\n\nEpoch 667  ;Total Train correct: 489  ;Train loss: 15.73673515021801\nTotal Validation correct: 81  ;Validation Loss: 10.720810741186142\nValidation loss decreased (10.735612 --> 10.720811).  Saving model ...\n\n\nEpoch 668  ;Total Train correct: 490  ;Train loss: 15.65315305814147\nTotal Validation correct: 81  ;Validation Loss: 10.751488342881203\n\n\nEpoch 669  ;Total Train correct: 490  ;Train loss: 15.646235577762127\nTotal Validation correct: 83  ;Validation Loss: 10.692991614341736\nValidation loss decreased (10.720811 --> 10.692992).  Saving model ...\n\n\nEpoch 670  ;Total Train correct: 490  ;Train loss: 15.593844342976809\nTotal Validation correct: 84  ;Validation Loss: 10.725209631025791\n\n\nEpoch 671  ;Total Train correct: 490  ;Train loss: 15.614528734236956\nTotal Validation correct: 83  ;Validation Loss: 10.728390529751778\n\n\nEpoch 672  ;Total Train correct: 491  ;Train loss: 15.572947112843394\nTotal Validation correct: 82  ;Validation Loss: 10.726064950227737\n\n\nEpoch 673  ;Total Train correct: 492  ;Train loss: 15.499008418992162\nTotal Validation correct: 82  ;Validation Loss: 10.701087169349194\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 674  ;Total Train correct: 492  ;Train loss: 15.53709152713418\nTotal Validation correct: 83  ;Validation Loss: 10.69933008402586\n\n\nEpoch 675  ;Total Train correct: 493  ;Train loss: 15.437892768532038\nTotal Validation correct: 82  ;Validation Loss: 10.676963731646538\nValidation loss decreased (10.692992 --> 10.676964).  Saving model ...\n\n\nEpoch 676  ;Total Train correct: 493  ;Train loss: 15.42306225374341\nTotal Validation correct: 83  ;Validation Loss: 10.642664104700089\nValidation loss decreased (10.676964 --> 10.642664).  Saving model ...\n\n\nEpoch 677  ;Total Train correct: 492  ;Train loss: 15.405982855707407\nTotal Validation correct: 83  ;Validation Loss: 10.648437097668648\n\n\nEpoch 678  ;Total Train correct: 492  ;Train loss: 15.383164189755917\nTotal Validation correct: 82  ;Validation Loss: 10.671819388866425\n\n\nEpoch 679  ;Total Train correct: 492  ;Train loss: 15.283064490184188\nTotal Validation correct: 82  ;Validation Loss: 10.643376238644123\n\n\nEpoch 680  ;Total Train correct: 492  ;Train loss: 15.192660367116332\nTotal Validation correct: 82  ;Validation Loss: 10.58052434027195\nValidation loss decreased (10.642664 --> 10.580524).  Saving model ...\n\n\nEpoch 681  ;Total Train correct: 492  ;Train loss: 15.290052842348814\nTotal Validation correct: 82  ;Validation Loss: 10.611510038375854\n\n\nEpoch 682  ;Total Train correct: 492  ;Train loss: 15.262486774474382\nTotal Validation correct: 82  ;Validation Loss: 10.598781675100327\n\n\nEpoch 683  ;Total Train correct: 493  ;Train loss: 15.258437659591436\nTotal Validation correct: 83  ;Validation Loss: 10.56699152290821\nValidation loss decreased (10.580524 --> 10.566992).  Saving model ...\n\n\nEpoch 684  ;Total Train correct: 492  ;Train loss: 15.226756256073713\nTotal Validation correct: 83  ;Validation Loss: 10.555375948548317\nValidation loss decreased (10.566992 --> 10.555376).  Saving model ...\n\n\nEpoch 685  ;Total Train correct: 492  ;Train loss: 15.211172947660089\nTotal Validation correct: 83  ;Validation Loss: 10.556281633675098\n\n\nEpoch 686  ;Total Train correct: 492  ;Train loss: 15.075377885252237\nTotal Validation correct: 83  ;Validation Loss: 10.51150967180729\nValidation loss decreased (10.555376 --> 10.511510).  Saving model ...\n\n\nEpoch 687  ;Total Train correct: 493  ;Train loss: 15.142355697229505\nTotal Validation correct: 84  ;Validation Loss: 10.518415451049805\n\n\nEpoch 688  ;Total Train correct: 492  ;Train loss: 15.10654960013926\nTotal Validation correct: 84  ;Validation Loss: 10.488143056631088\nValidation loss decreased (10.511510 --> 10.488143).  Saving model ...\n\n\nEpoch 689  ;Total Train correct: 493  ;Train loss: 15.13216331973672\nTotal Validation correct: 83  ;Validation Loss: 10.503187544643879\n\n\nEpoch 690  ;Total Train correct: 493  ;Train loss: 15.08236907608807\nTotal Validation correct: 84  ;Validation Loss: 10.448348000645638\nValidation loss decreased (10.488143 --> 10.448348).  Saving model ...\n\n\nEpoch 691  ;Total Train correct: 495  ;Train loss: 15.094897588714957\nTotal Validation correct: 84  ;Validation Loss: 10.4761433750391\n\n\nEpoch 692  ;Total Train correct: 494  ;Train loss: 15.037781311199069\nTotal Validation correct: 83  ;Validation Loss: 10.501623541116714\n\n\nEpoch 693  ;Total Train correct: 495  ;Train loss: 15.016661819070578\nTotal Validation correct: 84  ;Validation Loss: 10.442581333220005\nValidation loss decreased (10.448348 --> 10.442581).  Saving model ...\n\n\nEpoch 694  ;Total Train correct: 493  ;Train loss: 15.074833223596215\nTotal Validation correct: 83  ;Validation Loss: 10.452333070337772\n\n\nEpoch 695  ;Total Train correct: 494  ;Train loss: 14.982951708137989\nTotal Validation correct: 84  ;Validation Loss: 10.442915923893452\n\n\nEpoch 696  ;Total Train correct: 494  ;Train loss: 14.99975229986012\nTotal Validation correct: 84  ;Validation Loss: 10.458990104496479\n\n\nEpoch 697  ;Total Train correct: 495  ;Train loss: 14.982557160779834\nTotal Validation correct: 84  ;Validation Loss: 10.387324295938015\nValidation loss decreased (10.442581 --> 10.387324).  Saving model ...\n\n\nEpoch 698  ;Total Train correct: 493  ;Train loss: 15.03606678918004\nTotal Validation correct: 84  ;Validation Loss: 10.432186014950275\n\n\nEpoch 699  ;Total Train correct: 493  ;Train loss: 15.031470596790314\nTotal Validation correct: 84  ;Validation Loss: 10.43367475271225\n\n\nEpoch 700  ;Total Train correct: 493  ;Train loss: 14.998964440077543\nTotal Validation correct: 85  ;Validation Loss: 10.440950095653534\n\n\nEpoch 701  ;Total Train correct: 494  ;Train loss: 15.00882813706994\nTotal Validation correct: 84  ;Validation Loss: 10.438513785600662\n\n\nEpoch 702  ;Total Train correct: 494  ;Train loss: 14.99269687756896\nTotal Validation correct: 84  ;Validation Loss: 10.410039134323597\n\n\nEpoch 703  ;Total Train correct: 494  ;Train loss: 15.03169046714902\nTotal Validation correct: 84  ;Validation Loss: 10.387966208159924\n\n\nEpoch 704  ;Total Train correct: 494  ;Train loss: 15.006960755214095\nTotal Validation correct: 85  ;Validation Loss: 10.412013292312622\n\n\nEpoch 705  ;Total Train correct: 494  ;Train loss: 14.973185611888766\nTotal Validation correct: 85  ;Validation Loss: 10.368064641952515\nValidation loss decreased (10.387324 --> 10.368065).  Saving model ...\n\n\nEpoch 706  ;Total Train correct: 494  ;Train loss: 14.979391008615494\nTotal Validation correct: 85  ;Validation Loss: 10.356329135596752\nValidation loss decreased (10.368065 --> 10.356329).  Saving model ...\n\n\nEpoch 707  ;Total Train correct: 494  ;Train loss: 14.99058492295444\nTotal Validation correct: 86  ;Validation Loss: 10.371674910187721\n\n\nEpoch 708  ;Total Train correct: 494  ;Train loss: 14.933462247252464\nTotal Validation correct: 85  ;Validation Loss: 10.348743416368961\nValidation loss decreased (10.356329 --> 10.348743).  Saving model ...\n\n\nEpoch 709  ;Total Train correct: 494  ;Train loss: 14.980083353817463\nTotal Validation correct: 84  ;Validation Loss: 10.361996330320835\n\n\nEpoch 710  ;Total Train correct: 494  ;Train loss: 15.059416553005576\nTotal Validation correct: 84  ;Validation Loss: 10.383789323270321\n\n\nEpoch 711  ;Total Train correct: 494  ;Train loss: 14.954893771559\nTotal Validation correct: 86  ;Validation Loss: 10.340948589146137\nValidation loss decreased (10.348743 --> 10.340949).  Saving model ...\n\n\nEpoch 712  ;Total Train correct: 494  ;Train loss: 14.977509493008256\nTotal Validation correct: 86  ;Validation Loss: 10.312235280871391\nValidation loss decreased (10.340949 --> 10.312235).  Saving model ...\n\n\nEpoch 713  ;Total Train correct: 494  ;Train loss: 15.001383995637298\nTotal Validation correct: 85  ;Validation Loss: 10.338566705584526\n\n\nEpoch 714  ;Total Train correct: 494  ;Train loss: 14.896724319085479\nTotal Validation correct: 86  ;Validation Loss: 10.29954008758068\nValidation loss decreased (10.312235 --> 10.299540).  Saving model ...\n\n\nEpoch 715  ;Total Train correct: 494  ;Train loss: 14.940366139635444\nTotal Validation correct: 86  ;Validation Loss: 10.346243374049664\n\n\nEpoch 716  ;Total Train correct: 494  ;Train loss: 14.945487845689058\nTotal Validation correct: 88  ;Validation Loss: 10.2733643501997\nValidation loss decreased (10.299540 --> 10.273364).  Saving model ...\n\n\nEpoch 717  ;Total Train correct: 494  ;Train loss: 14.988308960571885\nTotal Validation correct: 88  ;Validation Loss: 10.237196773290634\nValidation loss decreased (10.273364 --> 10.237197).  Saving model ...\n\n\nEpoch 718  ;Total Train correct: 494  ;Train loss: 14.886233875527978\nTotal Validation correct: 88  ;Validation Loss: 10.24366608262062\n\n\nEpoch 719  ;Total Train correct: 494  ;Train loss: 14.938870972022414\nTotal Validation correct: 87  ;Validation Loss: 10.280519731342793\n\n\nEpoch 720  ;Total Train correct: 494  ;Train loss: 14.946975225582719\nTotal Validation correct: 88  ;Validation Loss: 10.258784458041191\n\n\nEpoch 721  ;Total Train correct: 494  ;Train loss: 14.945348562672734\nTotal Validation correct: 88  ;Validation Loss: 10.21221274882555\nValidation loss decreased (10.237197 --> 10.212213).  Saving model ...\n\n\nEpoch 722  ;Total Train correct: 496  ;Train loss: 14.867522235959768\nTotal Validation correct: 87  ;Validation Loss: 10.23360127210617\n\n\nEpoch 723  ;Total Train correct: 495  ;Train loss: 14.920188318938017\nTotal Validation correct: 88  ;Validation Loss: 10.196230940520763\nValidation loss decreased (10.212213 --> 10.196231).  Saving model ...\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 724  ;Total Train correct: 495  ;Train loss: 14.946590876206756\nTotal Validation correct: 88  ;Validation Loss: 10.233951315283775\n\n\nEpoch 725  ;Total Train correct: 496  ;Train loss: 14.993862930685282\nTotal Validation correct: 87  ;Validation Loss: 10.26928187161684\n\n\nEpoch 726  ;Total Train correct: 496  ;Train loss: 15.02093637175858\nTotal Validation correct: 88  ;Validation Loss: 10.23040296137333\n\n\nEpoch 727  ;Total Train correct: 496  ;Train loss: 15.033063016831875\nTotal Validation correct: 88  ;Validation Loss: 10.166222475469112\nValidation loss decreased (10.196231 --> 10.166222).  Saving model ...\n\n\nEpoch 728  ;Total Train correct: 496  ;Train loss: 15.000540617853403\nTotal Validation correct: 87  ;Validation Loss: 10.208924479782581\n\n\nEpoch 729  ;Total Train correct: 496  ;Train loss: 15.057686368003488\nTotal Validation correct: 88  ;Validation Loss: 10.143221721053123\nValidation loss decreased (10.166222 --> 10.143222).  Saving model ...\n\n\nEpoch 730  ;Total Train correct: 496  ;Train loss: 15.004898549988866\nTotal Validation correct: 88  ;Validation Loss: 10.131117105484009\nValidation loss decreased (10.143222 --> 10.131117).  Saving model ...\n\n\nEpoch 731  ;Total Train correct: 496  ;Train loss: 15.006110141053796\nTotal Validation correct: 88  ;Validation Loss: 10.103316850960255\nValidation loss decreased (10.131117 --> 10.103317).  Saving model ...\n\n\nEpoch 732  ;Total Train correct: 496  ;Train loss: 14.961312249302864\nTotal Validation correct: 88  ;Validation Loss: 10.157016031444073\n\n\nEpoch 733  ;Total Train correct: 497  ;Train loss: 14.91719645820558\nTotal Validation correct: 88  ;Validation Loss: 10.093241855502129\nValidation loss decreased (10.103317 --> 10.093242).  Saving model ...\n\n\nEpoch 734  ;Total Train correct: 495  ;Train loss: 14.992971539497375\nTotal Validation correct: 88  ;Validation Loss: 10.044525735080242\nValidation loss decreased (10.093242 --> 10.044526).  Saving model ...\n\n\nEpoch 735  ;Total Train correct: 495  ;Train loss: 14.944858849048615\nTotal Validation correct: 89  ;Validation Loss: 10.075387634336948\n\n\nEpoch 736  ;Total Train correct: 496  ;Train loss: 14.889870366081595\nTotal Validation correct: 89  ;Validation Loss: 10.025073744356632\nValidation loss decreased (10.044526 --> 10.025074).  Saving model ...\n\n\nEpoch 737  ;Total Train correct: 495  ;Train loss: 14.918637184426188\nTotal Validation correct: 89  ;Validation Loss: 10.038296096026897\n\n\nEpoch 738  ;Total Train correct: 496  ;Train loss: 14.853233192116022\nTotal Validation correct: 89  ;Validation Loss: 9.985969096422195\nValidation loss decreased (10.025074 --> 9.985969).  Saving model ...\n\n\nEpoch 739  ;Total Train correct: 495  ;Train loss: 14.928049569949508\nTotal Validation correct: 89  ;Validation Loss: 10.035449482500553\n\n\nEpoch 740  ;Total Train correct: 496  ;Train loss: 14.836816171184182\nTotal Validation correct: 89  ;Validation Loss: 9.936215490102768\nValidation loss decreased (9.985969 --> 9.936215).  Saving model ...\n\n\nEpoch 741  ;Total Train correct: 495  ;Train loss: 14.911277214065194\nTotal Validation correct: 89  ;Validation Loss: 9.977157928049564\n\n\nEpoch 742  ;Total Train correct: 495  ;Train loss: 14.855765998363495\nTotal Validation correct: 90  ;Validation Loss: 9.976263649761677\n\n\nEpoch 743  ;Total Train correct: 495  ;Train loss: 14.84558342024684\nTotal Validation correct: 89  ;Validation Loss: 9.913191452622414\nValidation loss decreased (9.936215 --> 9.913191).  Saving model ...\n\n\nEpoch 744  ;Total Train correct: 495  ;Train loss: 14.776875168085098\nTotal Validation correct: 91  ;Validation Loss: 9.87807947397232\nValidation loss decreased (9.913191 --> 9.878079).  Saving model ...\n\n\nEpoch 745  ;Total Train correct: 495  ;Train loss: 14.742630083113909\nTotal Validation correct: 89  ;Validation Loss: 9.897860825061798\n\n\nEpoch 746  ;Total Train correct: 496  ;Train loss: 14.654632970690727\nTotal Validation correct: 90  ;Validation Loss: 9.87140828371048\nValidation loss decreased (9.878079 --> 9.871408).  Saving model ...\n\n\nEpoch 747  ;Total Train correct: 495  ;Train loss: 14.640548078343272\nTotal Validation correct: 90  ;Validation Loss: 9.885536208748817\n\n\nEpoch 748  ;Total Train correct: 496  ;Train loss: 14.550624324008822\nTotal Validation correct: 92  ;Validation Loss: 9.814057476818562\nValidation loss decreased (9.871408 --> 9.814057).  Saving model ...\n\n\nEpoch 749  ;Total Train correct: 495  ;Train loss: 14.679924540221691\nTotal Validation correct: 90  ;Validation Loss: 9.811624698340893\nValidation loss decreased (9.814057 --> 9.811625).  Saving model ...\n\n\nEpoch 750  ;Total Train correct: 496  ;Train loss: 14.584358621388674\nTotal Validation correct: 90  ;Validation Loss: 9.755510337650776\nValidation loss decreased (9.811625 --> 9.755510).  Saving model ...\n\n\nEpoch 751  ;Total Train correct: 495  ;Train loss: 14.631291145458817\nTotal Validation correct: 91  ;Validation Loss: 9.720128275454044\nValidation loss decreased (9.755510 --> 9.720128).  Saving model ...\n\n\nEpoch 752  ;Total Train correct: 495  ;Train loss: 14.579142864793539\nTotal Validation correct: 91  ;Validation Loss: 9.724111780524254\n\n\nEpoch 753  ;Total Train correct: 495  ;Train loss: 14.574546257033944\nTotal Validation correct: 90  ;Validation Loss: 9.720507256686687\n\n\nEpoch 754  ;Total Train correct: 494  ;Train loss: 14.583934675902128\nTotal Validation correct: 90  ;Validation Loss: 9.703762724995613\nValidation loss decreased (9.720128 --> 9.703763).  Saving model ...\n\n\nEpoch 755  ;Total Train correct: 495  ;Train loss: 14.468147112056613\nTotal Validation correct: 91  ;Validation Loss: 9.587325885891914\nValidation loss decreased (9.703763 --> 9.587326).  Saving model ...\n\n\nEpoch 756  ;Total Train correct: 496  ;Train loss: 14.474679900333285\nTotal Validation correct: 90  ;Validation Loss: 9.603519454598427\n\n\nEpoch 757  ;Total Train correct: 496  ;Train loss: 14.492145951837301\nTotal Validation correct: 91  ;Validation Loss: 9.610755696892738\n\n\nEpoch 758  ;Total Train correct: 496  ;Train loss: 14.439965851604939\nTotal Validation correct: 90  ;Validation Loss: 9.607449769973755\n\n\nEpoch 759  ;Total Train correct: 496  ;Train loss: 14.486612414941192\nTotal Validation correct: 90  ;Validation Loss: 9.595851853489876\n\n\nEpoch 760  ;Total Train correct: 496  ;Train loss: 14.40148694626987\nTotal Validation correct: 91  ;Validation Loss: 9.54363326728344\nValidation loss decreased (9.587326 --> 9.543633).  Saving model ...\n\n\nEpoch 761  ;Total Train correct: 496  ;Train loss: 14.33778234384954\nTotal Validation correct: 90  ;Validation Loss: 9.482411339879036\nValidation loss decreased (9.543633 --> 9.482411).  Saving model ...\n\n\nEpoch 762  ;Total Train correct: 496  ;Train loss: 14.292940590530634\nTotal Validation correct: 90  ;Validation Loss: 9.53159100562334\n\n\nEpoch 763  ;Total Train correct: 496  ;Train loss: 14.229294059798121\nTotal Validation correct: 89  ;Validation Loss: 9.498260289430618\n\n\nEpoch 764  ;Total Train correct: 496  ;Train loss: 14.220474798232317\nTotal Validation correct: 90  ;Validation Loss: 9.525567561388016\n\n\nEpoch 765  ;Total Train correct: 497  ;Train loss: 14.134938802570105\nTotal Validation correct: 89  ;Validation Loss: 9.449253484606743\nValidation loss decreased (9.482411 --> 9.449253).  Saving model ...\n\n\nEpoch 766  ;Total Train correct: 497  ;Train loss: 14.127025447785854\nTotal Validation correct: 89  ;Validation Loss: 9.44641563296318\nValidation loss decreased (9.449253 --> 9.446416).  Saving model ...\n\n\nEpoch 767  ;Total Train correct: 497  ;Train loss: 14.094035906717181\nTotal Validation correct: 90  ;Validation Loss: 9.380419038236141\nValidation loss decreased (9.446416 --> 9.380419).  Saving model ...\n\n\nEpoch 768  ;Total Train correct: 497  ;Train loss: 14.05231224000454\nTotal Validation correct: 89  ;Validation Loss: 9.492867767810822\n\n\nEpoch 769  ;Total Train correct: 496  ;Train loss: 14.042004935443401\nTotal Validation correct: 89  ;Validation Loss: 9.4246671423316\n\n\nEpoch 770  ;Total Train correct: 497  ;Train loss: 13.959867430850863\nTotal Validation correct: 89  ;Validation Loss: 9.34872929006815\nValidation loss decreased (9.380419 --> 9.348729).  Saving model ...\n\n\nEpoch 771  ;Total Train correct: 497  ;Train loss: 13.965486362576485\nTotal Validation correct: 89  ;Validation Loss: 9.390456795692444\n\n\nEpoch 772  ;Total Train correct: 497  ;Train loss: 13.861033838242292\nTotal Validation correct: 90  ;Validation Loss: 9.299956135451794\nValidation loss decreased (9.348729 --> 9.299956).  Saving model ...\n\n\nEpoch 773  ;Total Train correct: 497  ;Train loss: 13.858540972694755\nTotal Validation correct: 89  ;Validation Loss: 9.423715993762016\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 774  ;Total Train correct: 497  ;Train loss: 13.881899733096361\nTotal Validation correct: 89  ;Validation Loss: 9.315326496958733\n\n\nEpoch 775  ;Total Train correct: 498  ;Train loss: 13.812099501490593\nTotal Validation correct: 89  ;Validation Loss: 9.310367465019226\n\n\nEpoch 776  ;Total Train correct: 498  ;Train loss: 13.746956279501319\nTotal Validation correct: 88  ;Validation Loss: 9.331431239843369\n\n\nEpoch 777  ;Total Train correct: 498  ;Train loss: 13.732299290597439\nTotal Validation correct: 89  ;Validation Loss: 9.2772346585989\nValidation loss decreased (9.299956 --> 9.277235).  Saving model ...\n\n\nEpoch 778  ;Total Train correct: 498  ;Train loss: 13.611349366605282\nTotal Validation correct: 89  ;Validation Loss: 9.259412579238415\nValidation loss decreased (9.277235 --> 9.259413).  Saving model ...\n\n\nEpoch 779  ;Total Train correct: 498  ;Train loss: 13.584416473284364\nTotal Validation correct: 91  ;Validation Loss: 9.133043617010117\nValidation loss decreased (9.259413 --> 9.133044).  Saving model ...\n\n\nEpoch 780  ;Total Train correct: 498  ;Train loss: 13.52655035071075\nTotal Validation correct: 90  ;Validation Loss: 9.205352514982224\n\n\nEpoch 781  ;Total Train correct: 497  ;Train loss: 13.452931962907314\nTotal Validation correct: 92  ;Validation Loss: 9.103933222591877\nValidation loss decreased (9.133044 --> 9.103933).  Saving model ...\n\n\nEpoch 782  ;Total Train correct: 499  ;Train loss: 13.462342862039804\nTotal Validation correct: 92  ;Validation Loss: 9.09777469187975\nValidation loss decreased (9.103933 --> 9.097775).  Saving model ...\n\n\nEpoch 783  ;Total Train correct: 499  ;Train loss: 13.381240673363209\nTotal Validation correct: 91  ;Validation Loss: 9.092058829963207\nValidation loss decreased (9.097775 --> 9.092059).  Saving model ...\n\n\nEpoch 784  ;Total Train correct: 499  ;Train loss: 13.393152372911572\nTotal Validation correct: 92  ;Validation Loss: 8.983491107821465\nValidation loss decreased (9.092059 --> 8.983491).  Saving model ...\n\n\nEpoch 785  ;Total Train correct: 499  ;Train loss: 13.374766383320093\nTotal Validation correct: 90  ;Validation Loss: 9.070429801940918\n\n\nEpoch 786  ;Total Train correct: 499  ;Train loss: 13.276507202535868\nTotal Validation correct: 90  ;Validation Loss: 9.045895785093307\n\n\nEpoch 787  ;Total Train correct: 499  ;Train loss: 13.370904611423612\nTotal Validation correct: 92  ;Validation Loss: 8.943947605788708\nValidation loss decreased (8.983491 --> 8.943948).  Saving model ...\n\n\nEpoch 788  ;Total Train correct: 499  ;Train loss: 13.312044691294432\nTotal Validation correct: 91  ;Validation Loss: 9.023161560297012\n\n\nEpoch 789  ;Total Train correct: 499  ;Train loss: 13.25092751160264\nTotal Validation correct: 90  ;Validation Loss: 8.993315316736698\n\n\nEpoch 790  ;Total Train correct: 499  ;Train loss: 13.152363296598196\nTotal Validation correct: 89  ;Validation Loss: 8.981836050748825\n\n\nEpoch 791  ;Total Train correct: 499  ;Train loss: 13.181187864392996\nTotal Validation correct: 91  ;Validation Loss: 8.92186251655221\nValidation loss decreased (8.943948 --> 8.921863).  Saving model ...\n\n\nEpoch 792  ;Total Train correct: 499  ;Train loss: 13.11762267537415\nTotal Validation correct: 90  ;Validation Loss: 8.913314808160067\nValidation loss decreased (8.921863 --> 8.913315).  Saving model ...\n\n\nEpoch 793  ;Total Train correct: 500  ;Train loss: 13.06996993906796\nTotal Validation correct: 90  ;Validation Loss: 8.907701715826988\nValidation loss decreased (8.913315 --> 8.907702).  Saving model ...\n\n\nEpoch 794  ;Total Train correct: 499  ;Train loss: 13.09767097979784\nTotal Validation correct: 90  ;Validation Loss: 8.855919901281595\nValidation loss decreased (8.907702 --> 8.855920).  Saving model ...\n\n\nEpoch 795  ;Total Train correct: 500  ;Train loss: 13.023936649784446\nTotal Validation correct: 90  ;Validation Loss: 8.869992088526487\n\n\nEpoch 796  ;Total Train correct: 500  ;Train loss: 13.001162331551313\nTotal Validation correct: 91  ;Validation Loss: 8.793898429721594\nValidation loss decreased (8.855920 --> 8.793898).  Saving model ...\n\n\nEpoch 797  ;Total Train correct: 500  ;Train loss: 12.976495634764433\nTotal Validation correct: 92  ;Validation Loss: 8.843157552182674\n\n\nEpoch 798  ;Total Train correct: 500  ;Train loss: 12.948527064174414\nTotal Validation correct: 91  ;Validation Loss: 8.742604814469814\nValidation loss decreased (8.793898 --> 8.742605).  Saving model ...\n\n\nEpoch 799  ;Total Train correct: 500  ;Train loss: 12.834745522588491\nTotal Validation correct: 91  ;Validation Loss: 8.761117581278086\n\n\nEpoch 800  ;Total Train correct: 499  ;Train loss: 12.901545148342848\nTotal Validation correct: 91  ;Validation Loss: 8.721610337495804\nValidation loss decreased (8.742605 --> 8.721610).  Saving model ...\n\n\nEpoch 801  ;Total Train correct: 500  ;Train loss: 12.840117541141808\nTotal Validation correct: 92  ;Validation Loss: 8.647491350769997\nValidation loss decreased (8.721610 --> 8.647491).  Saving model ...\n\n\nEpoch 802  ;Total Train correct: 502  ;Train loss: 12.656172193586826\nTotal Validation correct: 92  ;Validation Loss: 8.744272254407406\n\n\nEpoch 803  ;Total Train correct: 501  ;Train loss: 12.683207134716213\nTotal Validation correct: 90  ;Validation Loss: 8.695665512233973\n\n\nEpoch 804  ;Total Train correct: 502  ;Train loss: 12.689695042558014\nTotal Validation correct: 92  ;Validation Loss: 8.681241448968649\n\n\nEpoch 805  ;Total Train correct: 502  ;Train loss: 12.622630652971566\nTotal Validation correct: 91  ;Validation Loss: 8.599479995667934\nValidation loss decreased (8.647491 --> 8.599480).  Saving model ...\n\n\nEpoch 806  ;Total Train correct: 501  ;Train loss: 12.582221107557416\nTotal Validation correct: 90  ;Validation Loss: 8.591393414884806\nValidation loss decreased (8.599480 --> 8.591393).  Saving model ...\n\n\nEpoch 807  ;Total Train correct: 501  ;Train loss: 12.591540563851595\nTotal Validation correct: 92  ;Validation Loss: 8.54762752354145\nValidation loss decreased (8.591393 --> 8.547628).  Saving model ...\n\n\nEpoch 808  ;Total Train correct: 502  ;Train loss: 12.500455316156149\nTotal Validation correct: 90  ;Validation Loss: 8.626091551035643\n\n\nEpoch 809  ;Total Train correct: 503  ;Train loss: 12.507404290139675\nTotal Validation correct: 91  ;Validation Loss: 8.574105277657509\n\n\nEpoch 810  ;Total Train correct: 503  ;Train loss: 12.471218453720212\nTotal Validation correct: 91  ;Validation Loss: 8.536363448947668\nValidation loss decreased (8.547628 --> 8.536363).  Saving model ...\n\n\nEpoch 811  ;Total Train correct: 504  ;Train loss: 12.368616285733879\nTotal Validation correct: 92  ;Validation Loss: 8.569387685507536\n\n\nEpoch 812  ;Total Train correct: 502  ;Train loss: 12.332707913592458\nTotal Validation correct: 93  ;Validation Loss: 8.505750190466642\nValidation loss decreased (8.536363 --> 8.505750).  Saving model ...\n\n\nEpoch 813  ;Total Train correct: 502  ;Train loss: 12.35876667033881\nTotal Validation correct: 91  ;Validation Loss: 8.519439790397882\n\n\nEpoch 814  ;Total Train correct: 504  ;Train loss: 12.390355086885393\nTotal Validation correct: 91  ;Validation Loss: 8.451001446694136\nValidation loss decreased (8.505750 --> 8.451001).  Saving model ...\n\n\nEpoch 815  ;Total Train correct: 504  ;Train loss: 12.23770515806973\nTotal Validation correct: 93  ;Validation Loss: 8.521763753145933\n\n\nEpoch 816  ;Total Train correct: 502  ;Train loss: 12.269498752430081\nTotal Validation correct: 92  ;Validation Loss: 8.410784929990768\nValidation loss decreased (8.451001 --> 8.410785).  Saving model ...\n\n\nEpoch 817  ;Total Train correct: 504  ;Train loss: 12.233397020958364\nTotal Validation correct: 93  ;Validation Loss: 8.463262297213078\n\n\nEpoch 818  ;Total Train correct: 503  ;Train loss: 12.199569820426404\nTotal Validation correct: 93  ;Validation Loss: 8.395945202559233\nValidation loss decreased (8.410785 --> 8.395945).  Saving model ...\n\n\nEpoch 819  ;Total Train correct: 504  ;Train loss: 12.127379089593887\nTotal Validation correct: 93  ;Validation Loss: 8.45189518481493\n\n\nEpoch 820  ;Total Train correct: 503  ;Train loss: 12.179875861853361\nTotal Validation correct: 94  ;Validation Loss: 8.36439248174429\nValidation loss decreased (8.395945 --> 8.364392).  Saving model ...\n\n\nEpoch 821  ;Total Train correct: 504  ;Train loss: 12.08495780825615\nTotal Validation correct: 93  ;Validation Loss: 8.35467530041933\nValidation loss decreased (8.364392 --> 8.354675).  Saving model ...\n\n\nEpoch 822  ;Total Train correct: 504  ;Train loss: 12.104872427880764\nTotal Validation correct: 94  ;Validation Loss: 8.320689305663109\nValidation loss decreased (8.354675 --> 8.320689).  Saving model ...\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 823  ;Total Train correct: 504  ;Train loss: 12.007427714765072\nTotal Validation correct: 92  ;Validation Loss: 8.386543661355972\n\n\nEpoch 824  ;Total Train correct: 504  ;Train loss: 12.086666457355022\nTotal Validation correct: 91  ;Validation Loss: 8.296518575400114\nValidation loss decreased (8.320689 --> 8.296519).  Saving model ...\n\n\nEpoch 825  ;Total Train correct: 505  ;Train loss: 11.91169901471585\nTotal Validation correct: 92  ;Validation Loss: 8.354469873011112\n\n\nEpoch 826  ;Total Train correct: 505  ;Train loss: 12.05878538172692\nTotal Validation correct: 95  ;Validation Loss: 8.241284247487783\nValidation loss decreased (8.296519 --> 8.241284).  Saving model ...\n\n\nEpoch 827  ;Total Train correct: 505  ;Train loss: 11.863740088418126\nTotal Validation correct: 95  ;Validation Loss: 8.302402943372726\n\n\nEpoch 828  ;Total Train correct: 505  ;Train loss: 12.014068693853915\nTotal Validation correct: 94  ;Validation Loss: 8.244210567325354\n\n\nEpoch 829  ;Total Train correct: 505  ;Train loss: 11.896971032954752\nTotal Validation correct: 94  ;Validation Loss: 8.240077771246433\nValidation loss decreased (8.241284 --> 8.240078).  Saving model ...\n\n\nEpoch 830  ;Total Train correct: 506  ;Train loss: 11.809788888320327\nTotal Validation correct: 94  ;Validation Loss: 8.247193939983845\n\n\nEpoch 831  ;Total Train correct: 506  ;Train loss: 11.85124041326344\nTotal Validation correct: 91  ;Validation Loss: 8.254931468516588\n\n\nEpoch 832  ;Total Train correct: 505  ;Train loss: 11.809551188722253\nTotal Validation correct: 94  ;Validation Loss: 8.161018408834934\nValidation loss decreased (8.240078 --> 8.161018).  Saving model ...\n\n\nEpoch 833  ;Total Train correct: 505  ;Train loss: 11.787734729237854\nTotal Validation correct: 94  ;Validation Loss: 8.21073928102851\n\n\nEpoch 834  ;Total Train correct: 506  ;Train loss: 11.732329268939793\nTotal Validation correct: 91  ;Validation Loss: 8.234756242483854\n\n\nEpoch 835  ;Total Train correct: 505  ;Train loss: 11.684729960747063\nTotal Validation correct: 94  ;Validation Loss: 8.186917554587126\n\n\nEpoch 836  ;Total Train correct: 506  ;Train loss: 11.752169147133827\nTotal Validation correct: 95  ;Validation Loss: 8.161893032491207\n\n\nEpoch 837  ;Total Train correct: 506  ;Train loss: 11.742531859315932\nTotal Validation correct: 95  ;Validation Loss: 8.12328775972128\nValidation loss decreased (8.161018 --> 8.123288).  Saving model ...\n\n\nEpoch 838  ;Total Train correct: 507  ;Train loss: 11.641026518307626\nTotal Validation correct: 93  ;Validation Loss: 8.126161243766546\n\n\nEpoch 839  ;Total Train correct: 507  ;Train loss: 11.673514722846448\nTotal Validation correct: 96  ;Validation Loss: 8.106731049716473\nValidation loss decreased (8.123288 --> 8.106731).  Saving model ...\n\n\nEpoch 840  ;Total Train correct: 507  ;Train loss: 11.609124211594462\nTotal Validation correct: 94  ;Validation Loss: 8.13089755922556\n\n\nEpoch 841  ;Total Train correct: 507  ;Train loss: 11.63264232315123\nTotal Validation correct: 94  ;Validation Loss: 8.027014829218388\nValidation loss decreased (8.106731 --> 8.027015).  Saving model ...\n\n\nEpoch 842  ;Total Train correct: 507  ;Train loss: 11.603860905393958\nTotal Validation correct: 95  ;Validation Loss: 8.04408498108387\n\n\nEpoch 843  ;Total Train correct: 507  ;Train loss: 11.567465299740434\nTotal Validation correct: 94  ;Validation Loss: 8.057513177394867\n\n\nEpoch 844  ;Total Train correct: 507  ;Train loss: 11.554755695164204\nTotal Validation correct: 96  ;Validation Loss: 7.991101499646902\nValidation loss decreased (8.027015 --> 7.991101).  Saving model ...\n\n\nEpoch 845  ;Total Train correct: 507  ;Train loss: 11.473396932706237\nTotal Validation correct: 93  ;Validation Loss: 8.041838124394417\n\n\nEpoch 846  ;Total Train correct: 507  ;Train loss: 11.491528766229749\nTotal Validation correct: 95  ;Validation Loss: 7.986711975187063\nValidation loss decreased (7.991101 --> 7.986712).  Saving model ...\n\n\nEpoch 847  ;Total Train correct: 507  ;Train loss: 11.515812129713595\nTotal Validation correct: 96  ;Validation Loss: 7.960491847246885\nValidation loss decreased (7.986712 --> 7.960492).  Saving model ...\n\n\nEpoch 848  ;Total Train correct: 507  ;Train loss: 11.436292509548366\nTotal Validation correct: 92  ;Validation Loss: 7.9702492989599705\n\n\nEpoch 849  ;Total Train correct: 507  ;Train loss: 11.547188602387905\nTotal Validation correct: 96  ;Validation Loss: 7.925867240875959\nValidation loss decreased (7.960492 --> 7.925867).  Saving model ...\n\n\nEpoch 850  ;Total Train correct: 507  ;Train loss: 11.361789956688881\nTotal Validation correct: 94  ;Validation Loss: 7.959865044802427\n\n\nEpoch 851  ;Total Train correct: 508  ;Train loss: 11.461267969571054\nTotal Validation correct: 96  ;Validation Loss: 7.891146764159203\nValidation loss decreased (7.925867 --> 7.891147).  Saving model ...\n\n\nEpoch 852  ;Total Train correct: 507  ;Train loss: 11.386105467565358\nTotal Validation correct: 93  ;Validation Loss: 7.892166696488857\n\n\nEpoch 853  ;Total Train correct: 507  ;Train loss: 11.283708084374666\nTotal Validation correct: 95  ;Validation Loss: 7.928835283964872\n\n\nEpoch 854  ;Total Train correct: 507  ;Train loss: 11.388082183897495\nTotal Validation correct: 94  ;Validation Loss: 7.9094439670443535\n\n\nEpoch 855  ;Total Train correct: 508  ;Train loss: 11.319680714048445\nTotal Validation correct: 95  ;Validation Loss: 7.819999106228352\nValidation loss decreased (7.891147 --> 7.819999).  Saving model ...\n\n\nEpoch 856  ;Total Train correct: 507  ;Train loss: 11.268089635297656\nTotal Validation correct: 97  ;Validation Loss: 7.819633696228266\nValidation loss decreased (7.819999 --> 7.819634).  Saving model ...\n\n\nEpoch 857  ;Total Train correct: 507  ;Train loss: 11.266755456104875\nTotal Validation correct: 95  ;Validation Loss: 7.876315671950579\n\n\nEpoch 858  ;Total Train correct: 507  ;Train loss: 11.24427780881524\nTotal Validation correct: 94  ;Validation Loss: 7.815934956073761\nValidation loss decreased (7.819634 --> 7.815935).  Saving model ...\n\n\nEpoch 859  ;Total Train correct: 509  ;Train loss: 11.25718149356544\nTotal Validation correct: 96  ;Validation Loss: 7.768360707908869\nValidation loss decreased (7.815935 --> 7.768361).  Saving model ...\n\n\nEpoch 860  ;Total Train correct: 507  ;Train loss: 11.277511882595718\nTotal Validation correct: 94  ;Validation Loss: 7.792854465544224\n\n\nEpoch 861  ;Total Train correct: 507  ;Train loss: 11.232641888782382\nTotal Validation correct: 94  ;Validation Loss: 7.760000586509705\nValidation loss decreased (7.768361 --> 7.760001).  Saving model ...\n\n\nEpoch 862  ;Total Train correct: 508  ;Train loss: 11.086074623279274\nTotal Validation correct: 95  ;Validation Loss: 7.7392746694386005\nValidation loss decreased (7.760001 --> 7.739275).  Saving model ...\n\n\nEpoch 863  ;Total Train correct: 507  ;Train loss: 11.20657728239894\nTotal Validation correct: 94  ;Validation Loss: 7.859604619443417\n\n\nEpoch 864  ;Total Train correct: 508  ;Train loss: 11.070408974774182\nTotal Validation correct: 93  ;Validation Loss: 7.741739485412836\n\n\nEpoch 865  ;Total Train correct: 508  ;Train loss: 11.02288655936718\nTotal Validation correct: 97  ;Validation Loss: 7.678495284169912\nValidation loss decreased (7.739275 --> 7.678495).  Saving model ...\n\n\nEpoch 866  ;Total Train correct: 508  ;Train loss: 11.002664780244231\nTotal Validation correct: 93  ;Validation Loss: 7.896624639630318\n\n\nEpoch 867  ;Total Train correct: 508  ;Train loss: 11.173583794385195\nTotal Validation correct: 94  ;Validation Loss: 7.811911053955555\n\n\nEpoch 868  ;Total Train correct: 508  ;Train loss: 11.031223281286657\nTotal Validation correct: 95  ;Validation Loss: 7.653363838791847\nValidation loss decreased (7.678495 --> 7.653364).  Saving model ...\n\n\nEpoch 869  ;Total Train correct: 508  ;Train loss: 10.961535402573645\nTotal Validation correct: 94  ;Validation Loss: 7.8128695003688335\n\n\nEpoch 870  ;Total Train correct: 508  ;Train loss: 10.875476039014757\nTotal Validation correct: 94  ;Validation Loss: 7.780310310423374\n\n\nEpoch 871  ;Total Train correct: 508  ;Train loss: 10.835602381266654\nTotal Validation correct: 95  ;Validation Loss: 7.672162506729364\n\n\nEpoch 872  ;Total Train correct: 510  ;Train loss: 10.819796908646822\nTotal Validation correct: 95  ;Validation Loss: 7.689142383635044\n\n\nEpoch 873  ;Total Train correct: 509  ;Train loss: 10.99423436820507\nTotal Validation correct: 96  ;Validation Loss: 7.551597468554974\nValidation loss decreased (7.653364 --> 7.551597).  Saving model ...\n","name":"stdout"},{"output_type":"stream","text":"\n\nEpoch 874  ;Total Train correct: 510  ;Train loss: 10.84879086446017\nTotal Validation correct: 94  ;Validation Loss: 7.695985101163387\n\n\nEpoch 875  ;Total Train correct: 510  ;Train loss: 10.757409603334963\nTotal Validation correct: 95  ;Validation Loss: 7.637062877416611\n\n\nEpoch 876  ;Total Train correct: 510  ;Train loss: 10.89550537057221\nTotal Validation correct: 95  ;Validation Loss: 7.649054151028395\n\n\nEpoch 877  ;Total Train correct: 510  ;Train loss: 10.724280266091228\nTotal Validation correct: 95  ;Validation Loss: 7.546211827546358\nValidation loss decreased (7.551597 --> 7.546212).  Saving model ...\n\n\nEpoch 878  ;Total Train correct: 511  ;Train loss: 10.767732051201165\nTotal Validation correct: 94  ;Validation Loss: 7.620735507458448\n\n\nEpoch 879  ;Total Train correct: 508  ;Train loss: 10.687896903604269\nTotal Validation correct: 95  ;Validation Loss: 7.629140377044678\n\n\nEpoch 880  ;Total Train correct: 511  ;Train loss: 10.666541004553437\nTotal Validation correct: 95  ;Validation Loss: 7.559212610125542\n\n\nEpoch 881  ;Total Train correct: 510  ;Train loss: 10.596214985474944\nTotal Validation correct: 95  ;Validation Loss: 7.547746043652296\n\n\nEpoch 882  ;Total Train correct: 509  ;Train loss: 10.678874782286584\nTotal Validation correct: 94  ;Validation Loss: 7.53824158757925\nValidation loss decreased (7.546212 --> 7.538242).  Saving model ...\n\n\nEpoch 883  ;Total Train correct: 511  ;Train loss: 10.634717088192701\nTotal Validation correct: 95  ;Validation Loss: 7.558485172688961\n\n\nEpoch 884  ;Total Train correct: 511  ;Train loss: 10.554024279117584\nTotal Validation correct: 94  ;Validation Loss: 7.569026567041874\n\n\nEpoch 885  ;Total Train correct: 510  ;Train loss: 10.757560916244984\nTotal Validation correct: 95  ;Validation Loss: 7.562747225165367\n\n\nEpoch 886  ;Total Train correct: 511  ;Train loss: 10.589323239400983\nTotal Validation correct: 95  ;Validation Loss: 7.57139678299427\n\n\nEpoch 887  ;Total Train correct: 511  ;Train loss: 10.61992818210274\nTotal Validation correct: 95  ;Validation Loss: 7.595421817153692\n\n\nEpoch 888  ;Total Train correct: 510  ;Train loss: 10.532686940394342\nTotal Validation correct: 93  ;Validation Loss: 7.571420755237341\n\n\nEpoch 889  ;Total Train correct: 511  ;Train loss: 10.50634569209069\nTotal Validation correct: 95  ;Validation Loss: 7.424075655639172\nValidation loss decreased (7.538242 --> 7.424076).  Saving model ...\n\n\nEpoch 890  ;Total Train correct: 511  ;Train loss: 10.467565874569118\nTotal Validation correct: 94  ;Validation Loss: 7.533750876784325\n\n\nEpoch 891  ;Total Train correct: 511  ;Train loss: 10.483899336308241\nTotal Validation correct: 95  ;Validation Loss: 7.48185995221138\n\n\nEpoch 892  ;Total Train correct: 511  ;Train loss: 10.393954084254801\nTotal Validation correct: 95  ;Validation Loss: 7.51416490226984\n\n\nEpoch 893  ;Total Train correct: 512  ;Train loss: 10.39758050069213\nTotal Validation correct: 94  ;Validation Loss: 7.436134085059166\n\n\nEpoch 894  ;Total Train correct: 510  ;Train loss: 10.422816154547036\nTotal Validation correct: 96  ;Validation Loss: 7.352848470211029\nValidation loss decreased (7.424076 --> 7.352848).  Saving model ...\n\n\nEpoch 895  ;Total Train correct: 511  ;Train loss: 10.28355879150331\nTotal Validation correct: 94  ;Validation Loss: 7.487943593412638\n\n\nEpoch 896  ;Total Train correct: 511  ;Train loss: 10.43044083379209\nTotal Validation correct: 96  ;Validation Loss: 7.392416384071112\n\n\nEpoch 897  ;Total Train correct: 512  ;Train loss: 10.156190200708807\nTotal Validation correct: 96  ;Validation Loss: 7.371710732579231\n\n\nEpoch 898  ;Total Train correct: 511  ;Train loss: 10.237600464373827\nTotal Validation correct: 96  ;Validation Loss: 7.374858323484659\n\n\nEpoch 899  ;Total Train correct: 511  ;Train loss: 10.252630182541907\nTotal Validation correct: 95  ;Validation Loss: 7.4129359126091\n\n\nEpoch 900  ;Total Train correct: 511  ;Train loss: 10.096633359789848\nTotal Validation correct: 95  ;Validation Loss: 7.32909700460732\nValidation loss decreased (7.352848 --> 7.329097).  Saving model ...\n\n\nEpoch 901  ;Total Train correct: 510  ;Train loss: 10.173168151639402\nTotal Validation correct: 95  ;Validation Loss: 7.321900576353073\nValidation loss decreased (7.329097 --> 7.321901).  Saving model ...\n\n\nEpoch 902  ;Total Train correct: 511  ;Train loss: 10.124614754226059\nTotal Validation correct: 95  ;Validation Loss: 7.302287681028247\nValidation loss decreased (7.321901 --> 7.302288).  Saving model ...\n\n\nEpoch 903  ;Total Train correct: 511  ;Train loss: 10.169960699044168\nTotal Validation correct: 94  ;Validation Loss: 7.373950550332665\n\n\nEpoch 904  ;Total Train correct: 510  ;Train loss: 10.201990856789052\nTotal Validation correct: 95  ;Validation Loss: 7.292022682726383\nValidation loss decreased (7.302288 --> 7.292023).  Saving model ...\n\n\nEpoch 905  ;Total Train correct: 511  ;Train loss: 10.013835340738297\nTotal Validation correct: 95  ;Validation Loss: 7.258023105561733\nValidation loss decreased (7.292023 --> 7.258023).  Saving model ...\n\n\nEpoch 906  ;Total Train correct: 511  ;Train loss: 10.020379308611155\nTotal Validation correct: 94  ;Validation Loss: 7.336579512804747\n\n\nEpoch 907  ;Total Train correct: 512  ;Train loss: 9.892106263898313\nTotal Validation correct: 96  ;Validation Loss: 7.1613414995372295\nValidation loss decreased (7.258023 --> 7.161341).  Saving model ...\n\n\nEpoch 908  ;Total Train correct: 511  ;Train loss: 9.857280653901398\nTotal Validation correct: 96  ;Validation Loss: 7.250742068514228\n\n\nEpoch 909  ;Total Train correct: 511  ;Train loss: 9.91423912672326\nTotal Validation correct: 95  ;Validation Loss: 7.235460206866264\n\n\nEpoch 910  ;Total Train correct: 511  ;Train loss: 9.935009104665369\nTotal Validation correct: 95  ;Validation Loss: 7.2792006731033325\n\n\nEpoch 911  ;Total Train correct: 511  ;Train loss: 9.877499324269593\nTotal Validation correct: 97  ;Validation Loss: 7.168657250702381\n\n\nEpoch 912  ;Total Train correct: 511  ;Train loss: 9.990073575172573\nTotal Validation correct: 94  ;Validation Loss: 7.278130978345871\n\n\nEpoch 913  ;Total Train correct: 511  ;Train loss: 9.780931559856981\nTotal Validation correct: 97  ;Validation Loss: 7.205208506435156\n\n\nEpoch 914  ;Total Train correct: 512  ;Train loss: 9.903663780540228\nTotal Validation correct: 93  ;Validation Loss: 7.271601289510727\n\n\nEpoch 915  ;Total Train correct: 511  ;Train loss: 9.76292476290837\nTotal Validation correct: 95  ;Validation Loss: 7.181575018912554\n\n\nEpoch 916  ;Total Train correct: 512  ;Train loss: 9.818671957589686\nTotal Validation correct: 93  ;Validation Loss: 7.272629376500845\n\n\nEpoch 917  ;Total Train correct: 512  ;Train loss: 9.75975393038243\nTotal Validation correct: 96  ;Validation Loss: 7.167667945846915\n\n\nEpoch 918  ;Total Train correct: 512  ;Train loss: 9.89252115599811\nTotal Validation correct: 95  ;Validation Loss: 7.2082233391702175\n\n\nEpoch 919  ;Total Train correct: 511  ;Train loss: 9.73989330837503\nTotal Validation correct: 93  ;Validation Loss: 7.228643365204334\n\n\nEpoch 920  ;Total Train correct: 511  ;Train loss: 9.761548821814358\nTotal Validation correct: 95  ;Validation Loss: 7.167362572625279\n\n\nEpoch 921  ;Total Train correct: 511  ;Train loss: 9.720225650351495\nTotal Validation correct: 94  ;Validation Loss: 7.219579067081213\n\n\nEpoch 922  ;Total Train correct: 511  ;Train loss: 9.699904545675963\nTotal Validation correct: 95  ;Validation Loss: 7.12938642129302\nValidation loss decreased (7.161341 --> 7.129386).  Saving model ...\n\n\nEpoch 923  ;Total Train correct: 512  ;Train loss: 9.73996050748974\nTotal Validation correct: 95  ;Validation Loss: 7.280525362119079\n\n\nEpoch 924  ;Total Train correct: 512  ;Train loss: 9.61924045626074\nTotal Validation correct: 96  ;Validation Loss: 7.223654683679342\n\n\nEpoch 925  ;Total Train correct: 511  ;Train loss: 9.604070819914341\nTotal Validation correct: 94  ;Validation Loss: 7.125113353133202\nValidation loss decreased (7.129386 --> 7.125113).  Saving model ...\n\n\nEpoch 926  ;Total Train correct: 512  ;Train loss: 9.651729059405625\nTotal Validation correct: 94  ;Validation Loss: 7.1962011735886335\n\n\nEpoch 927  ;Total Train correct: 512  ;Train loss: 9.579323702957481\nTotal Validation correct: 95  ;Validation Loss: 7.172322142869234\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 928  ;Total Train correct: 511  ;Train loss: 9.647035500500351\nTotal Validation correct: 93  ;Validation Loss: 7.169074881821871\n\n\nEpoch 929  ;Total Train correct: 512  ;Train loss: 9.477027644403279\nTotal Validation correct: 95  ;Validation Loss: 7.186605375260115\n\n\nEpoch 930  ;Total Train correct: 512  ;Train loss: 9.498786301352084\nTotal Validation correct: 95  ;Validation Loss: 7.155451320111752\n\n\nEpoch 931  ;Total Train correct: 512  ;Train loss: 9.470146758016199\nTotal Validation correct: 94  ;Validation Loss: 7.127595495432615\n\n\nEpoch 932  ;Total Train correct: 512  ;Train loss: 9.492316279560328\nTotal Validation correct: 96  ;Validation Loss: 7.083491910248995\nValidation loss decreased (7.125113 --> 7.083492).  Saving model ...\n\n\nEpoch 933  ;Total Train correct: 513  ;Train loss: 9.336963743437082\nTotal Validation correct: 96  ;Validation Loss: 7.128488900139928\n\n\nEpoch 934  ;Total Train correct: 511  ;Train loss: 9.351190757472068\nTotal Validation correct: 96  ;Validation Loss: 7.109292451292276\n\n\nEpoch 935  ;Total Train correct: 512  ;Train loss: 9.368451436050236\nTotal Validation correct: 96  ;Validation Loss: 7.092661049216986\n\n\nEpoch 936  ;Total Train correct: 511  ;Train loss: 9.419290596619248\nTotal Validation correct: 95  ;Validation Loss: 7.107947129756212\n\n\nEpoch 937  ;Total Train correct: 514  ;Train loss: 9.375783903058618\nTotal Validation correct: 96  ;Validation Loss: 7.048221563920379\nValidation loss decreased (7.083492 --> 7.048222).  Saving model ...\n\n\nEpoch 938  ;Total Train correct: 513  ;Train loss: 9.366969575174153\nTotal Validation correct: 95  ;Validation Loss: 7.082141095772386\n\n\nEpoch 939  ;Total Train correct: 514  ;Train loss: 9.316345592029393\nTotal Validation correct: 96  ;Validation Loss: 7.0327749364078045\nValidation loss decreased (7.048222 --> 7.032775).  Saving model ...\n\n\nEpoch 940  ;Total Train correct: 514  ;Train loss: 9.261813919991255\nTotal Validation correct: 96  ;Validation Loss: 7.078296583145857\n\n\nEpoch 941  ;Total Train correct: 511  ;Train loss: 9.202853473369032\nTotal Validation correct: 97  ;Validation Loss: 6.962105041369796\nValidation loss decreased (7.032775 --> 6.962105).  Saving model ...\n\n\nEpoch 942  ;Total Train correct: 513  ;Train loss: 9.227463442832232\nTotal Validation correct: 95  ;Validation Loss: 7.013908991590142\n\n\nEpoch 943  ;Total Train correct: 514  ;Train loss: 9.182281695771962\nTotal Validation correct: 95  ;Validation Loss: 7.003949381411076\n\n\nEpoch 944  ;Total Train correct: 514  ;Train loss: 9.126988786738366\nTotal Validation correct: 97  ;Validation Loss: 6.940105054527521\nValidation loss decreased (6.962105 --> 6.940105).  Saving model ...\n\n\nEpoch 945  ;Total Train correct: 513  ;Train loss: 8.99151816777885\nTotal Validation correct: 96  ;Validation Loss: 6.947600955143571\n\n\nEpoch 946  ;Total Train correct: 516  ;Train loss: 9.093435039743781\nTotal Validation correct: 97  ;Validation Loss: 6.909643517807126\nValidation loss decreased (6.940105 --> 6.909644).  Saving model ...\n\n\nEpoch 947  ;Total Train correct: 515  ;Train loss: 9.029016803950071\nTotal Validation correct: 95  ;Validation Loss: 6.962161036208272\n\n\nEpoch 948  ;Total Train correct: 516  ;Train loss: 9.067865999415517\nTotal Validation correct: 97  ;Validation Loss: 6.914621751755476\n\n\nEpoch 949  ;Total Train correct: 515  ;Train loss: 8.967429217416793\nTotal Validation correct: 97  ;Validation Loss: 6.896007511764765\nValidation loss decreased (6.909644 --> 6.896008).  Saving model ...\n\n\nEpoch 950  ;Total Train correct: 516  ;Train loss: 9.02313340920955\nTotal Validation correct: 97  ;Validation Loss: 6.958687910810113\n\n\nEpoch 951  ;Total Train correct: 517  ;Train loss: 8.97511394135654\nTotal Validation correct: 97  ;Validation Loss: 6.898806340992451\n\n\nEpoch 952  ;Total Train correct: 516  ;Train loss: 8.913968035019934\nTotal Validation correct: 96  ;Validation Loss: 6.883599041029811\nValidation loss decreased (6.896008 --> 6.883599).  Saving model ...\n\n\nEpoch 953  ;Total Train correct: 518  ;Train loss: 8.959525079466403\nTotal Validation correct: 97  ;Validation Loss: 6.844275787472725\nValidation loss decreased (6.883599 --> 6.844276).  Saving model ...\n\n\nEpoch 954  ;Total Train correct: 516  ;Train loss: 9.009032116271555\nTotal Validation correct: 96  ;Validation Loss: 6.854699905961752\n\n\nEpoch 955  ;Total Train correct: 519  ;Train loss: 8.850814349018037\nTotal Validation correct: 97  ;Validation Loss: 6.769073564559221\nValidation loss decreased (6.844276 --> 6.769074).  Saving model ...\n\n\nEpoch 956  ;Total Train correct: 518  ;Train loss: 8.852559577208012\nTotal Validation correct: 96  ;Validation Loss: 6.786715665832162\n\n\nEpoch 957  ;Total Train correct: 517  ;Train loss: 8.95678457384929\nTotal Validation correct: 96  ;Validation Loss: 6.814364148303866\n\n\nEpoch 958  ;Total Train correct: 517  ;Train loss: 8.941272880882025\nTotal Validation correct: 96  ;Validation Loss: 6.867746261879802\n\n\nEpoch 959  ;Total Train correct: 518  ;Train loss: 8.750215497799218\nTotal Validation correct: 96  ;Validation Loss: 6.756255693733692\nValidation loss decreased (6.769074 --> 6.756256).  Saving model ...\n\n\nEpoch 960  ;Total Train correct: 518  ;Train loss: 8.820148131810129\nTotal Validation correct: 96  ;Validation Loss: 6.775083953514695\n\n\nEpoch 961  ;Total Train correct: 518  ;Train loss: 8.854350052773952\nTotal Validation correct: 96  ;Validation Loss: 6.839957104995847\n\n\nEpoch 962  ;Total Train correct: 518  ;Train loss: 8.792203565128148\nTotal Validation correct: 97  ;Validation Loss: 6.70972727611661\nValidation loss decreased (6.756256 --> 6.709727).  Saving model ...\n\n\nEpoch 963  ;Total Train correct: 517  ;Train loss: 8.825057818554342\nTotal Validation correct: 96  ;Validation Loss: 6.791926488280296\n\n\nEpoch 964  ;Total Train correct: 518  ;Train loss: 8.688707555178553\nTotal Validation correct: 96  ;Validation Loss: 6.68755280226469\nValidation loss decreased (6.709727 --> 6.687553).  Saving model ...\n\n\nEpoch 965  ;Total Train correct: 519  ;Train loss: 8.821823615580797\nTotal Validation correct: 96  ;Validation Loss: 6.686746548861265\nValidation loss decreased (6.687553 --> 6.686747).  Saving model ...\n\n\nEpoch 966  ;Total Train correct: 520  ;Train loss: 8.678257799707353\nTotal Validation correct: 96  ;Validation Loss: 6.695954639464617\n\n\nEpoch 967  ;Total Train correct: 520  ;Train loss: 8.678111652377993\nTotal Validation correct: 96  ;Validation Loss: 6.704428676515818\n\n\nEpoch 968  ;Total Train correct: 520  ;Train loss: 8.616788323502988\nTotal Validation correct: 96  ;Validation Loss: 6.704812604933977\n\n\nEpoch 969  ;Total Train correct: 519  ;Train loss: 8.620478481985629\nTotal Validation correct: 95  ;Validation Loss: 6.618772644549608\nValidation loss decreased (6.686747 --> 6.618773).  Saving model ...\n\n\nEpoch 970  ;Total Train correct: 519  ;Train loss: 8.591240959241986\nTotal Validation correct: 96  ;Validation Loss: 6.672759220004082\n\n\nEpoch 971  ;Total Train correct: 520  ;Train loss: 8.55559202330187\nTotal Validation correct: 96  ;Validation Loss: 6.6469050738960505\n\n\nEpoch 972  ;Total Train correct: 521  ;Train loss: 8.52300561312586\nTotal Validation correct: 96  ;Validation Loss: 6.606714440509677\nValidation loss decreased (6.618773 --> 6.606714).  Saving model ...\n\n\nEpoch 973  ;Total Train correct: 519  ;Train loss: 8.566246184986085\nTotal Validation correct: 96  ;Validation Loss: 6.553305167704821\nValidation loss decreased (6.606714 --> 6.553305).  Saving model ...\n\n\nEpoch 974  ;Total Train correct: 519  ;Train loss: 8.43113952735439\nTotal Validation correct: 97  ;Validation Loss: 6.5895654782652855\n\n\nEpoch 975  ;Total Train correct: 520  ;Train loss: 8.37437089998275\nTotal Validation correct: 97  ;Validation Loss: 6.494312075898051\nValidation loss decreased (6.553305 --> 6.494312).  Saving model ...\n\n\nEpoch 976  ;Total Train correct: 520  ;Train loss: 8.448336189147085\nTotal Validation correct: 96  ;Validation Loss: 6.534452401101589\n\n\nEpoch 977  ;Total Train correct: 520  ;Train loss: 8.422250264324248\nTotal Validation correct: 96  ;Validation Loss: 6.483679784461856\nValidation loss decreased (6.494312 --> 6.483680).  Saving model ...\n\n\nEpoch 978  ;Total Train correct: 521  ;Train loss: 8.323002360761166\nTotal Validation correct: 96  ;Validation Loss: 6.4692098163068295\nValidation loss decreased (6.483680 --> 6.469210).  Saving model ...\n\n\nEpoch 979  ;Total Train correct: 519  ;Train loss: 8.436180795077235\nTotal Validation correct: 96  ;Validation Loss: 6.47531408444047\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 980  ;Total Train correct: 519  ;Train loss: 8.289587303996086\nTotal Validation correct: 96  ;Validation Loss: 6.389095555990934\nValidation loss decreased (6.469210 --> 6.389096).  Saving model ...\n\n\nEpoch 981  ;Total Train correct: 521  ;Train loss: 8.383389975409955\nTotal Validation correct: 97  ;Validation Loss: 6.446049364283681\n\n\nEpoch 982  ;Total Train correct: 520  ;Train loss: 8.434131081216037\nTotal Validation correct: 96  ;Validation Loss: 6.417088208720088\n\n\nEpoch 983  ;Total Train correct: 519  ;Train loss: 8.341452103573829\nTotal Validation correct: 95  ;Validation Loss: 6.468612466007471\n\n\nEpoch 984  ;Total Train correct: 521  ;Train loss: 8.266867109574378\nTotal Validation correct: 96  ;Validation Loss: 6.436086103320122\n\n\nEpoch 985  ;Total Train correct: 520  ;Train loss: 8.29698536079377\nTotal Validation correct: 97  ;Validation Loss: 6.3741227351129055\nValidation loss decreased (6.389096 --> 6.374123).  Saving model ...\n\n\nEpoch 986  ;Total Train correct: 521  ;Train loss: 8.263404585421085\nTotal Validation correct: 96  ;Validation Loss: 6.395030722022057\n\n\nEpoch 987  ;Total Train correct: 521  ;Train loss: 8.392033237963915\nTotal Validation correct: 95  ;Validation Loss: 6.422649908810854\n\n\nEpoch 988  ;Total Train correct: 521  ;Train loss: 8.265988598112017\nTotal Validation correct: 96  ;Validation Loss: 6.3893170543015\n\n\nEpoch 989  ;Total Train correct: 519  ;Train loss: 8.324706112965941\nTotal Validation correct: 95  ;Validation Loss: 6.3154931999742985\nValidation loss decreased (6.374123 --> 6.315493).  Saving model ...\n\n\nEpoch 990  ;Total Train correct: 521  ;Train loss: 8.305307518690825\nTotal Validation correct: 97  ;Validation Loss: 6.319648375734687\n\n\nEpoch 991  ;Total Train correct: 518  ;Train loss: 8.275366375688463\nTotal Validation correct: 96  ;Validation Loss: 6.385392164811492\n\n\nEpoch 992  ;Total Train correct: 520  ;Train loss: 8.242925689555705\nTotal Validation correct: 96  ;Validation Loss: 6.2791645005345345\nValidation loss decreased (6.315493 --> 6.279165).  Saving model ...\n\n\nEpoch 993  ;Total Train correct: 520  ;Train loss: 8.244471058715135\nTotal Validation correct: 96  ;Validation Loss: 6.268767496570945\nValidation loss decreased (6.279165 --> 6.268767).  Saving model ...\n\n\nEpoch 994  ;Total Train correct: 520  ;Train loss: 8.118976485915482\nTotal Validation correct: 96  ;Validation Loss: 6.2438797717913985\nValidation loss decreased (6.268767 --> 6.243880).  Saving model ...\n\n\nEpoch 995  ;Total Train correct: 520  ;Train loss: 8.164420961402357\nTotal Validation correct: 97  ;Validation Loss: 6.184310894459486\nValidation loss decreased (6.243880 --> 6.184311).  Saving model ...\n\n\nEpoch 996  ;Total Train correct: 520  ;Train loss: 8.07574963197112\nTotal Validation correct: 97  ;Validation Loss: 6.147751145064831\nValidation loss decreased (6.184311 --> 6.147751).  Saving model ...\n\n\nEpoch 997  ;Total Train correct: 520  ;Train loss: 8.050135512836277\nTotal Validation correct: 97  ;Validation Loss: 6.170002589002252\n\n\nEpoch 998  ;Total Train correct: 520  ;Train loss: 8.123664082027972\nTotal Validation correct: 96  ;Validation Loss: 6.153952745720744\n\n\nEpoch 999  ;Total Train correct: 520  ;Train loss: 8.116029321681708\nTotal Validation correct: 97  ;Validation Loss: 6.146228634752333\nValidation loss decreased (6.147751 --> 6.146229).  Saving model ...\n\n\nEpoch 1000  ;Total Train correct: 520  ;Train loss: 8.070898749865592\nTotal Validation correct: 97  ;Validation Loss: 6.098652838729322\nValidation loss decreased (6.146229 --> 6.098653).  Saving model ...\n\n\nEpoch 1001  ;Total Train correct: 519  ;Train loss: 8.146125026512891\nTotal Validation correct: 96  ;Validation Loss: 6.173376329243183\n\n\nEpoch 1002  ;Total Train correct: 520  ;Train loss: 8.059436881449074\nTotal Validation correct: 96  ;Validation Loss: 6.128889826126397\n\n\nEpoch 1003  ;Total Train correct: 520  ;Train loss: 8.102284861728549\nTotal Validation correct: 95  ;Validation Loss: 6.154807761311531\n\n\nEpoch 1004  ;Total Train correct: 520  ;Train loss: 8.145536520052701\nTotal Validation correct: 96  ;Validation Loss: 6.09648949559778\nValidation loss decreased (6.098653 --> 6.096489).  Saving model ...\n\n\nEpoch 1005  ;Total Train correct: 521  ;Train loss: 8.057000217027962\nTotal Validation correct: 98  ;Validation Loss: 5.99085340090096\nValidation loss decreased (6.096489 --> 5.990853).  Saving model ...\n\n\nEpoch 1006  ;Total Train correct: 520  ;Train loss: 8.035125456750393\nTotal Validation correct: 97  ;Validation Loss: 6.119732925668359\n\n\nEpoch 1007  ;Total Train correct: 521  ;Train loss: 7.99142748164013\nTotal Validation correct: 95  ;Validation Loss: 6.049749795347452\n\n\nEpoch 1008  ;Total Train correct: 520  ;Train loss: 8.020655296277255\nTotal Validation correct: 95  ;Validation Loss: 6.020305620506406\n\n\nEpoch 1009  ;Total Train correct: 519  ;Train loss: 8.068393021356314\nTotal Validation correct: 96  ;Validation Loss: 6.063137742690742\n\n\nEpoch 1010  ;Total Train correct: 521  ;Train loss: 7.915764760691673\nTotal Validation correct: 99  ;Validation Loss: 6.051946121267974\n\n\nEpoch 1011  ;Total Train correct: 520  ;Train loss: 8.008098584134132\nTotal Validation correct: 96  ;Validation Loss: 5.990289739333093\nValidation loss decreased (5.990853 --> 5.990290).  Saving model ...\n\n\nEpoch 1012  ;Total Train correct: 521  ;Train loss: 8.05411187140271\nTotal Validation correct: 97  ;Validation Loss: 5.996620789170265\n\n\nEpoch 1013  ;Total Train correct: 520  ;Train loss: 7.94800124084577\nTotal Validation correct: 96  ;Validation Loss: 6.049219333566725\n\n\nEpoch 1014  ;Total Train correct: 520  ;Train loss: 8.01429907605052\nTotal Validation correct: 97  ;Validation Loss: 5.892373602837324\nValidation loss decreased (5.990290 --> 5.892374).  Saving model ...\n\n\nEpoch 1015  ;Total Train correct: 523  ;Train loss: 7.946574590634555\nTotal Validation correct: 95  ;Validation Loss: 5.954934703186154\n\n\nEpoch 1016  ;Total Train correct: 522  ;Train loss: 7.9252967201173306\nTotal Validation correct: 97  ;Validation Loss: 6.017014222219586\n\n\nEpoch 1017  ;Total Train correct: 521  ;Train loss: 7.885674305958673\nTotal Validation correct: 97  ;Validation Loss: 5.93245755136013\n\n\nEpoch 1018  ;Total Train correct: 520  ;Train loss: 7.904692383483052\nTotal Validation correct: 96  ;Validation Loss: 5.990390584804118\n\n\nEpoch 1019  ;Total Train correct: 522  ;Train loss: 7.870927130104974\nTotal Validation correct: 98  ;Validation Loss: 5.825848365202546\nValidation loss decreased (5.892374 --> 5.825848).  Saving model ...\n\n\nEpoch 1020  ;Total Train correct: 522  ;Train loss: 7.847527377074584\nTotal Validation correct: 96  ;Validation Loss: 5.9480890249833465\n\n\nEpoch 1021  ;Total Train correct: 519  ;Train loss: 7.903955721529201\nTotal Validation correct: 96  ;Validation Loss: 5.877854428254068\n\n\nEpoch 1022  ;Total Train correct: 520  ;Train loss: 7.830178134376183\nTotal Validation correct: 95  ;Validation Loss: 5.92813166975975\n\n\nEpoch 1023  ;Total Train correct: 520  ;Train loss: 7.9368608319200575\nTotal Validation correct: 97  ;Validation Loss: 5.808690244331956\nValidation loss decreased (5.825848 --> 5.808690).  Saving model ...\n\n\nEpoch 1024  ;Total Train correct: 521  ;Train loss: 7.845687836641446\nTotal Validation correct: 96  ;Validation Loss: 5.965683747082949\n\n\nEpoch 1025  ;Total Train correct: 518  ;Train loss: 7.829415611224249\nTotal Validation correct: 96  ;Validation Loss: 5.875416707247496\n\n\nEpoch 1026  ;Total Train correct: 522  ;Train loss: 7.817706759553403\nTotal Validation correct: 97  ;Validation Loss: 5.939730710349977\n\n\nEpoch 1027  ;Total Train correct: 519  ;Train loss: 7.792572285048664\nTotal Validation correct: 97  ;Validation Loss: 5.769829116761684\nValidation loss decreased (5.808690 --> 5.769829).  Saving model ...\n\n\nEpoch 1028  ;Total Train correct: 521  ;Train loss: 7.856909243622795\nTotal Validation correct: 97  ;Validation Loss: 5.906102110631764\n\n\nEpoch 1029  ;Total Train correct: 520  ;Train loss: 7.789153842488304\nTotal Validation correct: 97  ;Validation Loss: 5.914444727823138\n\n\nEpoch 1030  ;Total Train correct: 520  ;Train loss: 7.786431738175452\nTotal Validation correct: 98  ;Validation Loss: 5.918263725936413\n\n\nEpoch 1031  ;Total Train correct: 521  ;Train loss: 7.767054853029549\nTotal Validation correct: 97  ;Validation Loss: 5.8205584064126015\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 1032  ;Total Train correct: 521  ;Train loss: 7.7192793970461935\nTotal Validation correct: 96  ;Validation Loss: 5.747017468325794\nValidation loss decreased (5.769829 --> 5.747017).  Saving model ...\n\n\nEpoch 1033  ;Total Train correct: 520  ;Train loss: 7.80014885799028\nTotal Validation correct: 97  ;Validation Loss: 5.799023265019059\n\n\nEpoch 1034  ;Total Train correct: 520  ;Train loss: 7.748251487035304\nTotal Validation correct: 97  ;Validation Loss: 5.834713394753635\n\n\nEpoch 1035  ;Total Train correct: 522  ;Train loss: 7.7642569919116795\nTotal Validation correct: 97  ;Validation Loss: 5.822543159127235\n\n\nEpoch 1036  ;Total Train correct: 521  ;Train loss: 7.748677532188594\nTotal Validation correct: 98  ;Validation Loss: 5.737690255045891\nValidation loss decreased (5.747017 --> 5.737690).  Saving model ...\n\n\nEpoch 1037  ;Total Train correct: 521  ;Train loss: 7.759867822285742\nTotal Validation correct: 97  ;Validation Loss: 5.8237776551395655\n\n\nEpoch 1038  ;Total Train correct: 522  ;Train loss: 7.700069047044963\nTotal Validation correct: 97  ;Validation Loss: 5.74802434258163\n\n\nEpoch 1039  ;Total Train correct: 521  ;Train loss: 7.759603338548914\nTotal Validation correct: 95  ;Validation Loss: 5.772924726828933\n\n\nEpoch 1040  ;Total Train correct: 520  ;Train loss: 7.669841372873634\nTotal Validation correct: 96  ;Validation Loss: 5.749544502235949\n\n\nEpoch 1041  ;Total Train correct: 522  ;Train loss: 7.743734351824969\nTotal Validation correct: 99  ;Validation Loss: 5.6240277495235205\nValidation loss decreased (5.737690 --> 5.624028).  Saving model ...\n\n\nEpoch 1042  ;Total Train correct: 519  ;Train loss: 7.656495535979047\nTotal Validation correct: 97  ;Validation Loss: 5.6944794440642\n\n\nEpoch 1043  ;Total Train correct: 521  ;Train loss: 7.62563048209995\nTotal Validation correct: 96  ;Validation Loss: 5.69082129560411\n\n\nEpoch 1044  ;Total Train correct: 521  ;Train loss: 7.577105010626838\nTotal Validation correct: 96  ;Validation Loss: 5.681510344147682\n\n\nEpoch 1045  ;Total Train correct: 520  ;Train loss: 7.664809968788177\nTotal Validation correct: 97  ;Validation Loss: 5.591819375753403\nValidation loss decreased (5.624028 --> 5.591819).  Saving model ...\n\n\nEpoch 1046  ;Total Train correct: 519  ;Train loss: 7.651201967382804\nTotal Validation correct: 97  ;Validation Loss: 5.622241863980889\n\n\nEpoch 1047  ;Total Train correct: 519  ;Train loss: 7.707967079477385\nTotal Validation correct: 96  ;Validation Loss: 5.661010021343827\n\n\nEpoch 1048  ;Total Train correct: 521  ;Train loss: 7.624208164867014\nTotal Validation correct: 97  ;Validation Loss: 5.607370584271848\n\n\nEpoch 1049  ;Total Train correct: 520  ;Train loss: 7.645115106366575\nTotal Validation correct: 98  ;Validation Loss: 5.6050965851172805\n\n\nEpoch 1050  ;Total Train correct: 520  ;Train loss: 7.561975545715541\nTotal Validation correct: 98  ;Validation Loss: 5.609709678217769\n\n\nEpoch 1051  ;Total Train correct: 519  ;Train loss: 7.639904778683558\nTotal Validation correct: 98  ;Validation Loss: 5.5107574835419655\nValidation loss decreased (5.591819 --> 5.510757).  Saving model ...\n\n\nEpoch 1052  ;Total Train correct: 519  ;Train loss: 7.548857608111575\nTotal Validation correct: 98  ;Validation Loss: 5.573659894056618\n\n\nEpoch 1053  ;Total Train correct: 521  ;Train loss: 7.6844234662130475\nTotal Validation correct: 98  ;Validation Loss: 5.572203490883112\n\n\nEpoch 1054  ;Total Train correct: 519  ;Train loss: 7.632672298466787\nTotal Validation correct: 98  ;Validation Loss: 5.522639070637524\n\n\nEpoch 1055  ;Total Train correct: 520  ;Train loss: 7.520828207023442\nTotal Validation correct: 98  ;Validation Loss: 5.458313169889152\nValidation loss decreased (5.510757 --> 5.458313).  Saving model ...\n\n\nEpoch 1056  ;Total Train correct: 519  ;Train loss: 7.568448483012617\nTotal Validation correct: 98  ;Validation Loss: 5.509526517242193\n\n\nEpoch 1057  ;Total Train correct: 520  ;Train loss: 7.538429451873526\nTotal Validation correct: 99  ;Validation Loss: 5.470629413612187\n\n\nEpoch 1058  ;Total Train correct: 519  ;Train loss: 7.540505488868803\nTotal Validation correct: 98  ;Validation Loss: 5.497372391633689\n\n\nEpoch 1059  ;Total Train correct: 519  ;Train loss: 7.487914463039488\nTotal Validation correct: 98  ;Validation Loss: 5.413968428969383\nValidation loss decreased (5.458313 --> 5.413968).  Saving model ...\n\n\nEpoch 1060  ;Total Train correct: 520  ;Train loss: 7.471307791071013\nTotal Validation correct: 98  ;Validation Loss: 5.458025593310595\n\n\nEpoch 1061  ;Total Train correct: 519  ;Train loss: 7.493856842396781\nTotal Validation correct: 99  ;Validation Loss: 5.432319617830217\n\n\nEpoch 1062  ;Total Train correct: 520  ;Train loss: 7.522172496421263\nTotal Validation correct: 99  ;Validation Loss: 5.3709307750687\nValidation loss decreased (5.413968 --> 5.370931).  Saving model ...\n\n\nEpoch 1063  ;Total Train correct: 519  ;Train loss: 7.406956768594682\nTotal Validation correct: 98  ;Validation Loss: 5.43275074288249\n\n\nEpoch 1064  ;Total Train correct: 518  ;Train loss: 7.42945533269085\nTotal Validation correct: 98  ;Validation Loss: 5.4156274786219\n\n\nEpoch 1065  ;Total Train correct: 519  ;Train loss: 7.412316132336855\nTotal Validation correct: 98  ;Validation Loss: 5.3511014729738235\nValidation loss decreased (5.370931 --> 5.351101).  Saving model ...\n\n\nEpoch 1066  ;Total Train correct: 519  ;Train loss: 7.480364451184869\nTotal Validation correct: 98  ;Validation Loss: 5.357656307518482\n\n\nEpoch 1067  ;Total Train correct: 520  ;Train loss: 7.426846576156095\nTotal Validation correct: 99  ;Validation Loss: 5.3326064785942435\nValidation loss decreased (5.351101 --> 5.332606).  Saving model ...\n\n\nEpoch 1068  ;Total Train correct: 519  ;Train loss: 7.4380065822042525\nTotal Validation correct: 98  ;Validation Loss: 5.44206247292459\n\n\nEpoch 1069  ;Total Train correct: 519  ;Train loss: 7.357232035137713\nTotal Validation correct: 99  ;Validation Loss: 5.309429177083075\nValidation loss decreased (5.332606 --> 5.309429).  Saving model ...\n\n\nEpoch 1070  ;Total Train correct: 520  ;Train loss: 7.3676572614349425\nTotal Validation correct: 99  ;Validation Loss: 5.262792472727597\nValidation loss decreased (5.309429 --> 5.262792).  Saving model ...\n\n\nEpoch 1071  ;Total Train correct: 521  ;Train loss: 7.33893037866801\nTotal Validation correct: 99  ;Validation Loss: 5.344465160742402\n\n\nEpoch 1072  ;Total Train correct: 520  ;Train loss: 7.316492891404778\nTotal Validation correct: 99  ;Validation Loss: 5.314313838258386\n\n\nEpoch 1073  ;Total Train correct: 519  ;Train loss: 7.381656367331743\nTotal Validation correct: 98  ;Validation Loss: 5.325559502467513\n\n\nEpoch 1074  ;Total Train correct: 519  ;Train loss: 7.308534947223961\nTotal Validation correct: 99  ;Validation Loss: 5.298683854751289\n\n\nEpoch 1075  ;Total Train correct: 519  ;Train loss: 7.29519150708802\nTotal Validation correct: 99  ;Validation Loss: 5.3276641415432096\n\n\nEpoch 1076  ;Total Train correct: 520  ;Train loss: 7.316451373742893\nTotal Validation correct: 99  ;Validation Loss: 5.236603348515928\nValidation loss decreased (5.262792 --> 5.236603).  Saving model ...\n\n\nEpoch 1077  ;Total Train correct: 521  ;Train loss: 7.354087931569666\nTotal Validation correct: 99  ;Validation Loss: 5.234761177562177\nValidation loss decreased (5.236603 --> 5.234761).  Saving model ...\n\n\nEpoch 1078  ;Total Train correct: 520  ;Train loss: 7.222448532469571\nTotal Validation correct: 99  ;Validation Loss: 5.254025682806969\n\n\nEpoch 1079  ;Total Train correct: 521  ;Train loss: 7.232240044744685\nTotal Validation correct: 99  ;Validation Loss: 5.259514233097434\n\n\nEpoch 1080  ;Total Train correct: 520  ;Train loss: 7.185012317728251\nTotal Validation correct: 99  ;Validation Loss: 5.21182151325047\nValidation loss decreased (5.234761 --> 5.211822).  Saving model ...\n\n\nEpoch 1081  ;Total Train correct: 520  ;Train loss: 7.2194196484051645\nTotal Validation correct: 99  ;Validation Loss: 5.187113502062857\nValidation loss decreased (5.211822 --> 5.187114).  Saving model ...\n\n\nEpoch 1082  ;Total Train correct: 520  ;Train loss: 7.162354171741754\nTotal Validation correct: 99  ;Validation Loss: 5.149815810844302\nValidation loss decreased (5.187114 --> 5.149816).  Saving model ...\n\n\nEpoch 1083  ;Total Train correct: 520  ;Train loss: 7.1112825812306255\nTotal Validation correct: 99  ;Validation Loss: 5.152507651597261\n\n\nEpoch 1084  ;Total Train correct: 521  ;Train loss: 7.16179519565776\nTotal Validation correct: 98  ;Validation Loss: 5.153942623175681\n\n\nEpoch 1085  ;Total Train correct: 521  ;Train loss: 7.091592166107148\nTotal Validation correct: 99  ;Validation Loss: 5.085711924359202\nValidation loss decreased (5.149816 --> 5.085712).  Saving model ...\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 1086  ;Total Train correct: 520  ;Train loss: 7.137263581156731\nTotal Validation correct: 99  ;Validation Loss: 5.100067000836134\n\n\nEpoch 1087  ;Total Train correct: 521  ;Train loss: 7.0604217909276485\nTotal Validation correct: 100  ;Validation Loss: 5.142722359858453\n\n\nEpoch 1088  ;Total Train correct: 520  ;Train loss: 7.069850399857387\nTotal Validation correct: 99  ;Validation Loss: 5.045187037438154\nValidation loss decreased (5.085712 --> 5.045187).  Saving model ...\n\n\nEpoch 1089  ;Total Train correct: 522  ;Train loss: 7.12096312455833\nTotal Validation correct: 98  ;Validation Loss: 5.085913052782416\n\n\nEpoch 1090  ;Total Train correct: 521  ;Train loss: 6.969940724782646\nTotal Validation correct: 99  ;Validation Loss: 5.118790376931429\n\n\nEpoch 1091  ;Total Train correct: 520  ;Train loss: 6.995644165202975\nTotal Validation correct: 99  ;Validation Loss: 5.054009979590774\n\n\nEpoch 1092  ;Total Train correct: 521  ;Train loss: 6.975953478598967\nTotal Validation correct: 100  ;Validation Loss: 5.076610143296421\n\n\nEpoch 1093  ;Total Train correct: 521  ;Train loss: 7.033849568106234\nTotal Validation correct: 99  ;Validation Loss: 5.0564469788223505\n\n\nEpoch 1094  ;Total Train correct: 522  ;Train loss: 6.988621735945344\nTotal Validation correct: 99  ;Validation Loss: 5.033198105171323\nValidation loss decreased (5.045187 --> 5.033198).  Saving model ...\n\n\nEpoch 1095  ;Total Train correct: 520  ;Train loss: 6.992224242072552\nTotal Validation correct: 100  ;Validation Loss: 4.997156755998731\nValidation loss decreased (5.033198 --> 4.997157).  Saving model ...\n\n\nEpoch 1096  ;Total Train correct: 521  ;Train loss: 6.997382871573791\nTotal Validation correct: 100  ;Validation Loss: 5.095429248176515\n\n\nEpoch 1097  ;Total Train correct: 522  ;Train loss: 6.932954775635153\nTotal Validation correct: 98  ;Validation Loss: 4.961986865848303\nValidation loss decreased (4.997157 --> 4.961987).  Saving model ...\n\n\nEpoch 1098  ;Total Train correct: 520  ;Train loss: 6.915489820763469\nTotal Validation correct: 100  ;Validation Loss: 5.049058658070862\n\n\nEpoch 1099  ;Total Train correct: 522  ;Train loss: 6.947517039021477\nTotal Validation correct: 100  ;Validation Loss: 5.01158987171948\n\n\nEpoch 1100  ;Total Train correct: 521  ;Train loss: 6.9151257667690516\nTotal Validation correct: 99  ;Validation Loss: 4.99146321695298\n\n\nEpoch 1101  ;Total Train correct: 521  ;Train loss: 6.923672628356144\nTotal Validation correct: 100  ;Validation Loss: 4.977591846138239\n\n\nEpoch 1102  ;Total Train correct: 520  ;Train loss: 6.891340070636943\nTotal Validation correct: 100  ;Validation Loss: 4.940992768853903\nValidation loss decreased (4.961987 --> 4.940993).  Saving model ...\n\n\nEpoch 1103  ;Total Train correct: 524  ;Train loss: 6.983340029139072\nTotal Validation correct: 97  ;Validation Loss: 4.915523367002606\nValidation loss decreased (4.940993 --> 4.915523).  Saving model ...\n\n\nEpoch 1104  ;Total Train correct: 522  ;Train loss: 6.853898920118809\nTotal Validation correct: 100  ;Validation Loss: 4.942896681837738\n\n\nEpoch 1105  ;Total Train correct: 521  ;Train loss: 6.766630103578791\nTotal Validation correct: 100  ;Validation Loss: 4.964111533947289\n\n\nEpoch 1106  ;Total Train correct: 520  ;Train loss: 6.830068494891748\nTotal Validation correct: 98  ;Validation Loss: 4.891278268769383\nValidation loss decreased (4.915523 --> 4.891278).  Saving model ...\n\n\nEpoch 1107  ;Total Train correct: 521  ;Train loss: 6.81735006836243\nTotal Validation correct: 100  ;Validation Loss: 4.88520887773484\nValidation loss decreased (4.891278 --> 4.885209).  Saving model ...\n\n\nEpoch 1108  ;Total Train correct: 521  ;Train loss: 6.820741010829806\nTotal Validation correct: 99  ;Validation Loss: 4.9554546643048525\n\n\nEpoch 1109  ;Total Train correct: 522  ;Train loss: 6.819107832852751\nTotal Validation correct: 100  ;Validation Loss: 4.796303459443152\nValidation loss decreased (4.885209 --> 4.796303).  Saving model ...\n\n\nEpoch 1110  ;Total Train correct: 522  ;Train loss: 6.7457440411672\nTotal Validation correct: 100  ;Validation Loss: 4.964686359278858\n\n\nEpoch 1111  ;Total Train correct: 522  ;Train loss: 6.777412360301241\nTotal Validation correct: 100  ;Validation Loss: 4.927950759418309\n\n\nEpoch 1112  ;Total Train correct: 523  ;Train loss: 6.719634914537892\nTotal Validation correct: 100  ;Validation Loss: 4.880422845482826\n\n\nEpoch 1113  ;Total Train correct: 521  ;Train loss: 6.675650492310524\nTotal Validation correct: 100  ;Validation Loss: 4.8764604749158025\n\n\nEpoch 1114  ;Total Train correct: 523  ;Train loss: 6.819241668796167\nTotal Validation correct: 98  ;Validation Loss: 4.816201880574226\n\n\nEpoch 1115  ;Total Train correct: 521  ;Train loss: 6.614135911106132\nTotal Validation correct: 100  ;Validation Loss: 4.821798748336732\n\n\nEpoch 1116  ;Total Train correct: 521  ;Train loss: 6.69455754221417\nTotal Validation correct: 100  ;Validation Loss: 4.84411792177707\n\n\nEpoch 1117  ;Total Train correct: 522  ;Train loss: 6.687210223870352\nTotal Validation correct: 100  ;Validation Loss: 4.882015900686383\n\n\nEpoch 1118  ;Total Train correct: 521  ;Train loss: 6.607633890816942\nTotal Validation correct: 100  ;Validation Loss: 4.7872650837525725\nValidation loss decreased (4.796303 --> 4.787265).  Saving model ...\n\n\nEpoch 1119  ;Total Train correct: 523  ;Train loss: 6.607190241804346\nTotal Validation correct: 100  ;Validation Loss: 4.92443089466542\n\n\nEpoch 1120  ;Total Train correct: 523  ;Train loss: 6.588706439593807\nTotal Validation correct: 101  ;Validation Loss: 4.8105424446985126\n\n\nEpoch 1121  ;Total Train correct: 522  ;Train loss: 6.451606009155512\nTotal Validation correct: 101  ;Validation Loss: 4.752674023620784\nValidation loss decreased (4.787265 --> 4.752674).  Saving model ...\n\n\nEpoch 1122  ;Total Train correct: 522  ;Train loss: 6.560177304549143\nTotal Validation correct: 99  ;Validation Loss: 4.761977545917034\n\n\nEpoch 1123  ;Total Train correct: 523  ;Train loss: 6.521370579954237\nTotal Validation correct: 101  ;Validation Loss: 4.7996623776853085\n\n\nEpoch 1124  ;Total Train correct: 524  ;Train loss: 6.504107034648769\nTotal Validation correct: 101  ;Validation Loss: 4.777261516079307\n\n\nEpoch 1125  ;Total Train correct: 523  ;Train loss: 6.457524907425977\nTotal Validation correct: 101  ;Validation Loss: 4.847124150022864\n\n\nEpoch 1126  ;Total Train correct: 522  ;Train loss: 6.478076966013759\nTotal Validation correct: 99  ;Validation Loss: 4.814268480986357\n\n\nEpoch 1127  ;Total Train correct: 524  ;Train loss: 6.321638572844677\nTotal Validation correct: 101  ;Validation Loss: 4.76403849106282\n\n\nEpoch 1128  ;Total Train correct: 524  ;Train loss: 6.471870259498246\nTotal Validation correct: 101  ;Validation Loss: 4.701625727117062\nValidation loss decreased (4.752674 --> 4.701626).  Saving model ...\n\n\nEpoch 1129  ;Total Train correct: 522  ;Train loss: 6.454832864459604\nTotal Validation correct: 101  ;Validation Loss: 4.756463849917054\n\n\nEpoch 1130  ;Total Train correct: 524  ;Train loss: 6.388972620596178\nTotal Validation correct: 99  ;Validation Loss: 4.74829716142267\n\n\nEpoch 1131  ;Total Train correct: 524  ;Train loss: 6.3091279863147065\nTotal Validation correct: 101  ;Validation Loss: 4.788768175989389\n\n\nEpoch 1132  ;Total Train correct: 524  ;Train loss: 6.367974159074947\nTotal Validation correct: 101  ;Validation Loss: 4.77441038377583\n\n\nEpoch 1133  ;Total Train correct: 523  ;Train loss: 6.364393753930926\nTotal Validation correct: 101  ;Validation Loss: 4.651406695134938\nValidation loss decreased (4.701626 --> 4.651407).  Saving model ...\n\n\nEpoch 1134  ;Total Train correct: 526  ;Train loss: 6.267592040472664\nTotal Validation correct: 101  ;Validation Loss: 4.654271831735969\n\n\nEpoch 1135  ;Total Train correct: 524  ;Train loss: 6.224509587045759\nTotal Validation correct: 101  ;Validation Loss: 4.651701492257416\n\n\nEpoch 1136  ;Total Train correct: 523  ;Train loss: 6.336793631431647\nTotal Validation correct: 101  ;Validation Loss: 4.660093349404633\n\n\nEpoch 1137  ;Total Train correct: 524  ;Train loss: 6.213892900384963\nTotal Validation correct: 101  ;Validation Loss: 4.666294077411294\n\n\nEpoch 1138  ;Total Train correct: 524  ;Train loss: 6.153786430251785\nTotal Validation correct: 101  ;Validation Loss: 4.739505513571203\n\n\nEpoch 1139  ;Total Train correct: 524  ;Train loss: 6.255327658029273\nTotal Validation correct: 101  ;Validation Loss: 4.6287241810932755\nValidation loss decreased (4.651407 --> 4.628724).  Saving model ...\n\n\nEpoch 1140  ;Total Train correct: 523  ;Train loss: 6.190707585774362\nTotal Validation correct: 99  ;Validation Loss: 4.717948137782514\n","name":"stdout"},{"output_type":"stream","text":"\n\nEpoch 1141  ;Total Train correct: 525  ;Train loss: 6.0516641666181386\nTotal Validation correct: 101  ;Validation Loss: 4.6663967510685325\n\n\nEpoch 1142  ;Total Train correct: 522  ;Train loss: 6.195504103205167\nTotal Validation correct: 101  ;Validation Loss: 4.621475073508918\nValidation loss decreased (4.628724 --> 4.621475).  Saving model ...\n\n\nEpoch 1143  ;Total Train correct: 524  ;Train loss: 6.0980546668870375\nTotal Validation correct: 100  ;Validation Loss: 4.60965683311224\nValidation loss decreased (4.621475 --> 4.609657).  Saving model ...\n\n\nEpoch 1144  ;Total Train correct: 523  ;Train loss: 6.038037302671\nTotal Validation correct: 100  ;Validation Loss: 4.568554216995835\nValidation loss decreased (4.609657 --> 4.568554).  Saving model ...\n\n\nEpoch 1145  ;Total Train correct: 525  ;Train loss: 6.034317700075917\nTotal Validation correct: 101  ;Validation Loss: 4.615409009158611\n\n\nEpoch 1146  ;Total Train correct: 521  ;Train loss: 6.169619578402489\nTotal Validation correct: 101  ;Validation Loss: 4.464352747425437\nValidation loss decreased (4.568554 --> 4.464353).  Saving model ...\n\n\nEpoch 1147  ;Total Train correct: 525  ;Train loss: 5.95169047312811\nTotal Validation correct: 101  ;Validation Loss: 4.604845596477389\n\n\nEpoch 1148  ;Total Train correct: 523  ;Train loss: 6.113055827678181\nTotal Validation correct: 100  ;Validation Loss: 4.561466347426176\n\n\nEpoch 1149  ;Total Train correct: 525  ;Train loss: 5.95083340909332\nTotal Validation correct: 101  ;Validation Loss: 4.571343615651131\n\n\nEpoch 1150  ;Total Train correct: 523  ;Train loss: 5.969521278864704\nTotal Validation correct: 101  ;Validation Loss: 4.594772009178996\n\n\nEpoch 1151  ;Total Train correct: 524  ;Train loss: 6.034999863128178\nTotal Validation correct: 101  ;Validation Loss: 4.481569539755583\n\n\nEpoch 1152  ;Total Train correct: 525  ;Train loss: 5.9024302730103955\nTotal Validation correct: 101  ;Validation Loss: 4.427950581535697\nValidation loss decreased (4.464353 --> 4.427951).  Saving model ...\n\n\nEpoch 1153  ;Total Train correct: 523  ;Train loss: 6.039967693621293\nTotal Validation correct: 101  ;Validation Loss: 4.4333590650931\n\n\nEpoch 1154  ;Total Train correct: 525  ;Train loss: 5.927216638461687\nTotal Validation correct: 101  ;Validation Loss: 4.535810591652989\n\n\nEpoch 1155  ;Total Train correct: 526  ;Train loss: 5.798843038734049\nTotal Validation correct: 102  ;Validation Loss: 4.412273713387549\nValidation loss decreased (4.427951 --> 4.412274).  Saving model ...\n\n\nEpoch 1156  ;Total Train correct: 528  ;Train loss: 5.850009589456022\nTotal Validation correct: 101  ;Validation Loss: 4.4258567579090595\n\n\nEpoch 1157  ;Total Train correct: 524  ;Train loss: 5.819799374556169\nTotal Validation correct: 101  ;Validation Loss: 4.358301333151758\nValidation loss decreased (4.412274 --> 4.358301).  Saving model ...\n\n\nEpoch 1158  ;Total Train correct: 526  ;Train loss: 5.769842633395456\nTotal Validation correct: 101  ;Validation Loss: 4.406782913021743\n\n\nEpoch 1159  ;Total Train correct: 526  ;Train loss: 5.74460134038236\nTotal Validation correct: 101  ;Validation Loss: 4.385568335652351\n\n\nEpoch 1160  ;Total Train correct: 521  ;Train loss: 5.79822922393214\nTotal Validation correct: 101  ;Validation Loss: 4.410424331203103\n\n\nEpoch 1161  ;Total Train correct: 525  ;Train loss: 5.812863123253919\nTotal Validation correct: 101  ;Validation Loss: 4.366676472127438\n\n\nEpoch 1162  ;Total Train correct: 527  ;Train loss: 5.653517190366983\nTotal Validation correct: 101  ;Validation Loss: 4.436684310436249\n\n\nEpoch 1163  ;Total Train correct: 523  ;Train loss: 5.697585916030221\nTotal Validation correct: 100  ;Validation Loss: 4.399602686055005\n\n\nEpoch 1164  ;Total Train correct: 528  ;Train loss: 5.6368864114629105\nTotal Validation correct: 101  ;Validation Loss: 4.362858277745545\n\n\nEpoch 1165  ;Total Train correct: 522  ;Train loss: 5.808327923994511\nTotal Validation correct: 100  ;Validation Loss: 4.3216702518984675\nValidation loss decreased (4.358301 --> 4.321670).  Saving model ...\n\n\nEpoch 1166  ;Total Train correct: 525  ;Train loss: 5.666111061000265\nTotal Validation correct: 101  ;Validation Loss: 4.345368223264813\n\n\nEpoch 1167  ;Total Train correct: 525  ;Train loss: 5.713908190489747\nTotal Validation correct: 101  ;Validation Loss: 4.328846928663552\n\n\nEpoch 1168  ;Total Train correct: 527  ;Train loss: 5.614325191127136\nTotal Validation correct: 101  ;Validation Loss: 4.363778907805681\n\n\nEpoch 1169  ;Total Train correct: 525  ;Train loss: 5.632928255130537\nTotal Validation correct: 101  ;Validation Loss: 4.24176081456244\nValidation loss decreased (4.321670 --> 4.241761).  Saving model ...\n\n\nEpoch 1170  ;Total Train correct: 526  ;Train loss: 5.592923532356508\nTotal Validation correct: 101  ;Validation Loss: 4.300193439237773\n\n\nEpoch 1171  ;Total Train correct: 528  ;Train loss: 5.643410942400806\nTotal Validation correct: 101  ;Validation Loss: 4.239827271550894\nValidation loss decreased (4.241761 --> 4.239827).  Saving model ...\n\n\nEpoch 1172  ;Total Train correct: 525  ;Train loss: 5.524938151240349\nTotal Validation correct: 102  ;Validation Loss: 4.165621438995004\nValidation loss decreased (4.239827 --> 4.165621).  Saving model ...\n\n\nEpoch 1173  ;Total Train correct: 526  ;Train loss: 5.563170801033266\nTotal Validation correct: 101  ;Validation Loss: 4.395248772576451\n\n\nEpoch 1174  ;Total Train correct: 526  ;Train loss: 5.60539590055123\nTotal Validation correct: 101  ;Validation Loss: 4.210755618289113\n\n\nEpoch 1175  ;Total Train correct: 528  ;Train loss: 5.453571495367214\nTotal Validation correct: 102  ;Validation Loss: 4.226305214688182\n\n\nEpoch 1176  ;Total Train correct: 523  ;Train loss: 5.63816319743637\nTotal Validation correct: 102  ;Validation Loss: 4.193718654103577\n\n\nEpoch 1177  ;Total Train correct: 528  ;Train loss: 5.501810546964407\nTotal Validation correct: 101  ;Validation Loss: 4.283182562328875\n\n\nEpoch 1178  ;Total Train correct: 523  ;Train loss: 5.62433709949255\nTotal Validation correct: 102  ;Validation Loss: 4.144841331988573\nValidation loss decreased (4.165621 --> 4.144841).  Saving model ...\n\n\nEpoch 1179  ;Total Train correct: 528  ;Train loss: 5.407922755694017\nTotal Validation correct: 101  ;Validation Loss: 4.183267096988857\n\n\nEpoch 1180  ;Total Train correct: 526  ;Train loss: 5.435598692856729\nTotal Validation correct: 101  ;Validation Loss: 4.2667671255767345\n\n\nEpoch 1181  ;Total Train correct: 527  ;Train loss: 5.468216169625521\nTotal Validation correct: 100  ;Validation Loss: 4.146972828544676\n\n\nEpoch 1182  ;Total Train correct: 528  ;Train loss: 5.362796816858463\nTotal Validation correct: 101  ;Validation Loss: 4.135532510466874\nValidation loss decreased (4.144841 --> 4.135533).  Saving model ...\n\n\nEpoch 1183  ;Total Train correct: 527  ;Train loss: 5.351711988681927\nTotal Validation correct: 101  ;Validation Loss: 4.176252061501145\n\n\nEpoch 1184  ;Total Train correct: 527  ;Train loss: 5.396348957903683\nTotal Validation correct: 101  ;Validation Loss: 4.217444633133709\n\n\nEpoch 1185  ;Total Train correct: 523  ;Train loss: 5.446326516219415\nTotal Validation correct: 101  ;Validation Loss: 4.026121042668819\nValidation loss decreased (4.135533 --> 4.026121).  Saving model ...\n\n\nEpoch 1186  ;Total Train correct: 526  ;Train loss: 5.358477456495166\nTotal Validation correct: 101  ;Validation Loss: 4.28389466740191\n\n\nEpoch 1187  ;Total Train correct: 528  ;Train loss: 5.353894745232537\nTotal Validation correct: 101  ;Validation Loss: 4.117309980094433\n\n\nEpoch 1188  ;Total Train correct: 529  ;Train loss: 5.237487308913842\nTotal Validation correct: 102  ;Validation Loss: 4.168457193300128\n\n\nEpoch 1189  ;Total Train correct: 523  ;Train loss: 5.4452246758155525\nTotal Validation correct: 102  ;Validation Loss: 4.047963107936084\n\n\nEpoch 1190  ;Total Train correct: 526  ;Train loss: 5.324155303183943\nTotal Validation correct: 102  ;Validation Loss: 4.086572493426502\n\n\nEpoch 1191  ;Total Train correct: 527  ;Train loss: 5.291868884814903\nTotal Validation correct: 101  ;Validation Loss: 4.131678259000182\n\n\nEpoch 1192  ;Total Train correct: 526  ;Train loss: 5.312336192466319\nTotal Validation correct: 101  ;Validation Loss: 4.008637007325888\nValidation loss decreased (4.026121 --> 4.008637).  Saving model ...\n\n\n","name":"stdout"},{"output_type":"stream","text":"Epoch 1193  ;Total Train correct: 525  ;Train loss: 5.271245332551189\nTotal Validation correct: 101  ;Validation Loss: 4.144899820908904\n\n\nEpoch 1194  ;Total Train correct: 529  ;Train loss: 5.245904063107446\nTotal Validation correct: 101  ;Validation Loss: 4.056864550337195\n\n\nEpoch 1195  ;Total Train correct: 529  ;Train loss: 5.172479222295806\nTotal Validation correct: 101  ;Validation Loss: 4.032330833375454\n\n\nEpoch 1196  ;Total Train correct: 527  ;Train loss: 5.239259417634457\nTotal Validation correct: 101  ;Validation Loss: 4.059458080679178\n\n\nEpoch 1197  ;Total Train correct: 529  ;Train loss: 5.099326286232099\nTotal Validation correct: 102  ;Validation Loss: 4.019084611907601\n\n\nEpoch 1198  ;Total Train correct: 529  ;Train loss: 5.029658391722478\nTotal Validation correct: 101  ;Validation Loss: 4.110411571338773\n\n\nEpoch 1199  ;Total Train correct: 528  ;Train loss: 5.174598450423218\nTotal Validation correct: 101  ;Validation Loss: 3.9536720272153616\nValidation loss decreased (4.008637 --> 3.953672).  Saving model ...\n\n\nEpoch 1200  ;Total Train correct: 526  ;Train loss: 5.1641297253081575\nTotal Validation correct: 102  ;Validation Loss: 3.9782075360417366\n\n\nEpoch 1201  ;Total Train correct: 526  ;Train loss: 5.21909546724055\nTotal Validation correct: 101  ;Validation Loss: 3.996803064830601\n\n\nEpoch 1202  ;Total Train correct: 527  ;Train loss: 5.038621484534815\nTotal Validation correct: 101  ;Validation Loss: 3.958543042652309\n\n\nEpoch 1203  ;Total Train correct: 527  ;Train loss: 5.062381369411014\nTotal Validation correct: 101  ;Validation Loss: 4.070435576140881\n\n\nEpoch 1204  ;Total Train correct: 526  ;Train loss: 5.1639544907957315\nTotal Validation correct: 101  ;Validation Loss: 3.920640771277249\nValidation loss decreased (3.953672 --> 3.920641).  Saving model ...\n\n\nEpoch 1205  ;Total Train correct: 528  ;Train loss: 4.9871195402229205\nTotal Validation correct: 102  ;Validation Loss: 3.9117587516084313\nValidation loss decreased (3.920641 --> 3.911759).  Saving model ...\n\n\nEpoch 1206  ;Total Train correct: 528  ;Train loss: 4.975350960157812\nTotal Validation correct: 101  ;Validation Loss: 3.9955135602504015\n\n\nEpoch 1207  ;Total Train correct: 528  ;Train loss: 4.980636024614796\nTotal Validation correct: 101  ;Validation Loss: 4.03081230353564\n\n\nEpoch 1208  ;Total Train correct: 525  ;Train loss: 5.026900949189439\nTotal Validation correct: 101  ;Validation Loss: 3.9781175954267383\n\n\nEpoch 1209  ;Total Train correct: 529  ;Train loss: 4.993004525778815\nTotal Validation correct: 101  ;Validation Loss: 4.029701877385378\n\n\nEpoch 1210  ;Total Train correct: 526  ;Train loss: 5.107116469647735\nTotal Validation correct: 101  ;Validation Loss: 3.921591163612902\n\n\nEpoch 1211  ;Total Train correct: 528  ;Train loss: 4.962932839407586\nTotal Validation correct: 101  ;Validation Loss: 3.840288204140961\nValidation loss decreased (3.911759 --> 3.840288).  Saving model ...\n\n\nEpoch 1212  ;Total Train correct: 531  ;Train loss: 4.861446955939755\nTotal Validation correct: 102  ;Validation Loss: 3.830199746415019\nValidation loss decreased (3.840288 --> 3.830200).  Saving model ...\n\n\nEpoch 1213  ;Total Train correct: 528  ;Train loss: 4.9070506719872355\nTotal Validation correct: 102  ;Validation Loss: 3.8265004931017756\nValidation loss decreased (3.830200 --> 3.826500).  Saving model ...\n\n\nEpoch 1214  ;Total Train correct: 526  ;Train loss: 4.948228953173384\nTotal Validation correct: 101  ;Validation Loss: 3.985190716572106\n\n\nEpoch 1215  ;Total Train correct: 526  ;Train loss: 4.948826095322147\nTotal Validation correct: 102  ;Validation Loss: 3.777958274818957\nValidation loss decreased (3.826500 --> 3.777958).  Saving model ...\n\n\nEpoch 1216  ;Total Train correct: 529  ;Train loss: 4.8419341704575345\nTotal Validation correct: 101  ;Validation Loss: 3.862568376585841\n\n\nEpoch 1217  ;Total Train correct: 526  ;Train loss: 4.948756962548941\nTotal Validation correct: 101  ;Validation Loss: 3.9008313436061144\n\n\nEpoch 1218  ;Total Train correct: 530  ;Train loss: 4.84072008531075\nTotal Validation correct: 101  ;Validation Loss: 3.9450725531205535\n\n\nEpoch 1219  ;Total Train correct: 530  ;Train loss: 4.772735196747817\nTotal Validation correct: 102  ;Validation Loss: 3.7906303042545915\n\n\nEpoch 1220  ;Total Train correct: 527  ;Train loss: 4.82162696053274\nTotal Validation correct: 103  ;Validation Loss: 3.7282741274684668\nValidation loss decreased (3.777958 --> 3.728274).  Saving model ...\n\n\nEpoch 1221  ;Total Train correct: 527  ;Train loss: 4.819892479223199\nTotal Validation correct: 101  ;Validation Loss: 3.8549797842279077\n\n\nEpoch 1222  ;Total Train correct: 526  ;Train loss: 4.8628222399856895\nTotal Validation correct: 101  ;Validation Loss: 3.8623629454523325\n\n\nEpoch 1223  ;Total Train correct: 529  ;Train loss: 4.733571850461885\nTotal Validation correct: 102  ;Validation Loss: 3.788715599104762\n\n\nEpoch 1224  ;Total Train correct: 531  ;Train loss: 4.746234047226608\nTotal Validation correct: 101  ;Validation Loss: 3.8369496632367373\n\n\nEpoch 1225  ;Total Train correct: 528  ;Train loss: 4.7803904979955405\nTotal Validation correct: 102  ;Validation Loss: 3.687149938195944\nValidation loss decreased (3.728274 --> 3.687150).  Saving model ...\n\n\nEpoch 1226  ;Total Train correct: 529  ;Train loss: 4.84640098689124\nTotal Validation correct: 101  ;Validation Loss: 3.9006790593266487\n\n\nEpoch 1227  ;Total Train correct: 528  ;Train loss: 4.789707996882498\nTotal Validation correct: 101  ;Validation Loss: 3.798407672904432\n\n\nEpoch 1228  ;Total Train correct: 529  ;Train loss: 4.709153827861883\nTotal Validation correct: 101  ;Validation Loss: 3.8241931293159723\n\n\nEpoch 1229  ;Total Train correct: 528  ;Train loss: 4.765023300657049\nTotal Validation correct: 102  ;Validation Loss: 3.8083912394940853\n\n\nEpoch 1230  ;Total Train correct: 526  ;Train loss: 4.75842744554393\nTotal Validation correct: 100  ;Validation Loss: 3.7735777674242854\n\n\nEpoch 1231  ;Total Train correct: 527  ;Train loss: 4.799264735775068\nTotal Validation correct: 102  ;Validation Loss: 3.8472040481865406\n\n\nEpoch 1232  ;Total Train correct: 526  ;Train loss: 4.782642554491758\nTotal Validation correct: 103  ;Validation Loss: 3.761187725700438\n\n\nEpoch 1233  ;Total Train correct: 529  ;Train loss: 4.84017313120421\nTotal Validation correct: 102  ;Validation Loss: 3.759096436202526\n\n\nEpoch 1234  ;Total Train correct: 528  ;Train loss: 4.693151759332977\nTotal Validation correct: 101  ;Validation Loss: 3.698291172273457\n\n\nEpoch 1235  ;Total Train correct: 528  ;Train loss: 4.6629694944713265\nTotal Validation correct: 101  ;Validation Loss: 3.7485684445127845\n\n\nEpoch 1236  ;Total Train correct: 529  ;Train loss: 4.638139077229425\nTotal Validation correct: 102  ;Validation Loss: 3.7733624754473567\n\n\nEpoch 1237  ;Total Train correct: 529  ;Train loss: 4.5663801280315965\nTotal Validation correct: 101  ;Validation Loss: 3.7928882045671344\n\n\nEpoch 1238  ;Total Train correct: 527  ;Train loss: 4.600486404728144\nTotal Validation correct: 102  ;Validation Loss: 3.5584007520228624\nValidation loss decreased (3.687150 --> 3.558401).  Saving model ...\n\n\nEpoch 1239  ;Total Train correct: 530  ;Train loss: 4.600489168427885\nTotal Validation correct: 101  ;Validation Loss: 3.7906702598556876\n\n\nEpoch 1240  ;Total Train correct: 528  ;Train loss: 4.610321066575125\nTotal Validation correct: 101  ;Validation Loss: 3.672670458443463\n\n\nEpoch 1241  ;Total Train correct: 530  ;Train loss: 4.6454709901008755\nTotal Validation correct: 102  ;Validation Loss: 3.6032638656906784\n\n\nEpoch 1242  ;Total Train correct: 528  ;Train loss: 4.702208017988596\nTotal Validation correct: 101  ;Validation Loss: 3.755214875563979\n\n\nEpoch 1243  ;Total Train correct: 527  ;Train loss: 4.64535338350106\nTotal Validation correct: 101  ;Validation Loss: 3.6051604878157377\n\n\nEpoch 1244  ;Total Train correct: 531  ;Train loss: 4.561205817852169\nTotal Validation correct: 101  ;Validation Loss: 3.64661758299917\n\n\nEpoch 1245  ;Total Train correct: 527  ;Train loss: 4.509792149416171\nTotal Validation correct: 102  ;Validation Loss: 3.566517561674118\n\n\nEpoch 1246  ;Total Train correct: 529  ;Train loss: 4.594950769096613\nTotal Validation correct: 102  ;Validation Loss: 3.6121670370921493\n\n\nEpoch 1247  ;Total Train correct: 532  ;Train loss: 4.537100136862136\nTotal Validation correct: 100  ;Validation Loss: 3.7327755177393556\n\n\nEpoch 1248  ;Total Train correct: 531  ;Train loss: 4.450828842585906\nTotal Validation correct: 102  ;Validation Loss: 3.626683537848294\n\n\nEpoch 1249  ;Total Train correct: 530  ;Train loss: 4.472013098944444\nTotal Validation correct: 101  ;Validation Loss: 3.6729972483590245\n\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Load the best model(with minimum validation loss):"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_checkpoint(filepath):\n    checkpoint = torch.load(filepath)\n    model = checkpoint['model']\n    model.load_state_dict(checkpoint['state_dict'])\n    train_loss= checkpoint['train_loss']\n    for parameter in model.parameters():\n        parameter.requires_grad = False\n    \n    model.eval()\n    \n    return model, train_loss","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network_best, train_loss = load_checkpoint('checkpoint.pth')\nnetwork_best= network_best\ntrain_loss= train_loss\nprint(network_best)","execution_count":27,"outputs":[{"output_type":"stream","text":"Network(\n  (fc1): Linear(in_features=6, out_features=40, bias=True)\n  (fc2): Linear(in_features=40, out_features=81, bias=True)\n  (fc3): Linear(in_features=81, out_features=36, bias=True)\n  (fc4): Linear(in_features=36, out_features=19, bias=True)\n  (out): Linear(in_features=19, out_features=2, bias=True)\n)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Checking Accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy_train= (train_correct/len(train))*100\nprint('Train Accuracy=' + str(accuracy_train) + '%')","execution_count":28,"outputs":[{"output_type":"stream","text":"Train Accuracy=96.36363636363636%\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Checking on Testing Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"# initialize lists to monitor test loss and accuracy\ntest_loss = 0.0\nclass_correct = list(0. for i in range(10))\nclass_total = list(0. for i in range(10))\n\nnetwork_best.eval() # prep model for evaluation\n\nfor data, target in test_loader:\n    # forward pass: compute predicted outputs by passing inputs to the model\n    output = network_best(data.float())\n    \n    # calculate the loss\n    loss = F.cross_entropy(output, target)\n    # update test loss \n    test_loss += loss.item()*data.size(0)\n    \n    # convert output probabilities to predicted class\n    _, pred = torch.max(output, 1)\n    \n    # compare predictions to true label\n    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n    \n    # calculate test accuracy for each object class\n    for i in range(len(target)):\n        label = target.data[i]\n        class_correct[label] += correct[i].item()\n        class_total[label] += 1\n\n# calculate and print avg test loss\ntest_loss = test_loss/len(test_loader.sampler)\nprint('Test Loss: {:.6f}\\n'.format(test_loss))\n\nfor i in range(10):\n    if class_total[i] > 0:\n        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n            str(i), 100 * class_correct[i] / class_total[i],\n            np.sum(class_correct[i]), np.sum(class_total[i])))\n    else:\n        continue\n\nprint('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n    100. * np.sum(class_correct) / np.sum(class_total),\n    np.sum(class_correct), np.sum(class_total)))","execution_count":29,"outputs":[{"output_type":"stream","text":"Test Loss: 0.658432\n\nTest Accuracy of     0: 90% (90/99)\nTest Accuracy of     1: 30% ( 3/10)\n\nTest Accuracy (Overall): 85% (93/109)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the model as a pickle in a file \njoblib.dump(network_best, 'FeCare.pkl') ","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"['FeCare.pkl']"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}